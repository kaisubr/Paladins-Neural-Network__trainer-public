{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"BYOtaJgny6zg","colab_type":"code","outputId":"b3bfdba7-3d1c-4032-aa94-8a1d758fb501","executionInfo":{"status":"ok","timestamp":1579500588681,"user_tz":360,"elapsed":21013,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# !pip install protobuf\n","# !pip install pillow\n","# !pip install lxml\n","# !pip install Cython\n","# !pip install jupyter\n","# !pip install matplotlib\n","# !pip install pandas\n","# !pip install opencv-python \n","# !pip install tensorflow\n","!apt-get install protobuf-compiler python-pil python-lxml python-tk\n","!pip install Cython"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n","python-tk is already the newest version (2.7.17-1~18.04).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-430\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  python-bs4 python-chardet python-html5lib python-olefile\n","  python-pkg-resources python-six python-webencodings\n","Suggested packages:\n","  python-genshi python-lxml-dbg python-lxml-doc python-pil-doc python-pil-dbg\n","  python-setuptools\n","The following NEW packages will be installed:\n","  python-bs4 python-chardet python-html5lib python-lxml python-olefile\n","  python-pil python-pkg-resources python-six python-webencodings\n","0 upgraded, 9 newly installed, 0 to remove and 7 not upgraded.\n","Need to get 1,818 kB of archives.\n","After this operation, 7,688 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-bs4 all 4.6.0-1 [67.9 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-chardet all 3.0.4-1 [80.3 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-webencodings all 0.5-2 [10.3 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-html5lib all 0.999999999-1 [83.6 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-lxml amd64 4.2.1-1ubuntu0.1 [1,075 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-olefile all 0.45.1-1 [33.2 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pil amd64 5.1.0-1 [328 kB]\n","Fetched 1,818 kB in 3s (553 kB/s)\n","Selecting previously unselected package python-bs4.\n","(Reading database ... 145674 files and directories currently installed.)\n","Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n","Unpacking python-bs4 (4.6.0-1) ...\n","Selecting previously unselected package python-pkg-resources.\n","Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n","Unpacking python-pkg-resources (39.0.1-2) ...\n","Selecting previously unselected package python-chardet.\n","Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n","Unpacking python-chardet (3.0.4-1) ...\n","Selecting previously unselected package python-six.\n","Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n","Unpacking python-six (1.11.0-2) ...\n","Selecting previously unselected package python-webencodings.\n","Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n","Unpacking python-webencodings (0.5-2) ...\n","Selecting previously unselected package python-html5lib.\n","Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n","Unpacking python-html5lib (0.999999999-1) ...\n","Selecting previously unselected package python-lxml:amd64.\n","Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n","Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Selecting previously unselected package python-olefile.\n","Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n","Unpacking python-olefile (0.45.1-1) ...\n","Selecting previously unselected package python-pil:amd64.\n","Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n","Unpacking python-pil:amd64 (5.1.0-1) ...\n","Setting up python-pkg-resources (39.0.1-2) ...\n","Setting up python-six (1.11.0-2) ...\n","Setting up python-bs4 (4.6.0-1) ...\n","Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n","Setting up python-olefile (0.45.1-1) ...\n","Setting up python-pil:amd64 (5.1.0-1) ...\n","Setting up python-webencodings (0.5-2) ...\n","Setting up python-chardet (3.0.4-1) ...\n","Setting up python-html5lib (0.999999999-1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.14)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xxa7s9yC0T5N","colab_type":"code","outputId":"e3e8ffe0-1188-4e39-dcf3-e807e5aff3da","executionInfo":{"status":"ok","timestamp":1579504320374,"user_tz":360,"elapsed":89742,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# https://github.com/tensorflow/models/tree/master/official\n","# First we clone the repository. It's cloned into /content/models/\n","%cd /content/\n","!git clone https://github.com/tensorflow/models.git\n","!git clone https://github.com/tensorflow/tensorflow.git"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/content\n","fatal: destination path 'models' already exists and is not an empty directory.\n","Cloning into 'tensorflow'...\n","remote: Enumerating objects: 8, done.\u001b[K\n","remote: Counting objects: 100% (8/8), done.\u001b[K\n","remote: Compressing objects: 100% (8/8), done.\u001b[K\n","remote: Total 808306 (delta 0), reused 8 (delta 0), pack-reused 808298\u001b[K\n","Receiving objects: 100% (808306/808306), 463.76 MiB | 12.20 MiB/s, done.\n","Resolving deltas: 100% (653782/653782), done.\n","Checking out files: 100% (19193/19193), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mWY_S6SDYGeB","colab_type":"code","outputId":"aa81d1e3-e100-4d26-f9d2-995980ff17aa","executionInfo":{"status":"ok","timestamp":1579503510598,"user_tz":360,"elapsed":3446,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","\n","# and import it.\n","%cd /content/models/research/\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","os.environ['PYTHONPATH'] += \":/content/models:/content/models/research:/content/models/research/slim\""],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/models/research\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I6s9p1RwabuN","colab_type":"code","outputId":"87867648-2b43-421a-9213-1a7dba3cef6a","executionInfo":{"status":"ok","timestamp":1579500654595,"user_tz":360,"elapsed":76756,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python setup.py build\n","!python setup.py install\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["running build\n","running build_py\n","creating build\n","creating build/lib\n","creating build/lib/object_detection\n","copying object_detection/model_lib_v2.py -> build/lib/object_detection\n","copying object_detection/model_main.py -> build/lib/object_detection\n","copying object_detection/exporter_test.py -> build/lib/object_detection\n","copying object_detection/inputs_test.py -> build/lib/object_detection\n","copying object_detection/__init__.py -> build/lib/object_detection\n","copying object_detection/export_inference_graph.py -> build/lib/object_detection\n","copying object_detection/export_tflite_ssd_graph_lib.py -> build/lib/object_detection\n","copying object_detection/model_tpu_main.py -> build/lib/object_detection\n","copying object_detection/exporter.py -> build/lib/object_detection\n","copying object_detection/model_hparams.py -> build/lib/object_detection\n","copying object_detection/export_tflite_ssd_graph.py -> build/lib/object_detection\n","copying object_detection/model_lib_v2_test.py -> build/lib/object_detection\n","copying object_detection/inputs.py -> build/lib/object_detection\n","copying object_detection/export_tflite_ssd_graph_lib_test.py -> build/lib/object_detection\n","copying object_detection/model_lib_test.py -> build/lib/object_detection\n","copying object_detection/model_lib.py -> build/lib/object_detection\n","copying object_detection/eval_util_test.py -> build/lib/object_detection\n","copying object_detection/eval_util.py -> build/lib/object_detection\n","creating build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v2_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v3_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v3_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v3_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/feature_map_generators_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/__init__.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_nas_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_pnasnet_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_pnasnet_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_nas_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_pnas_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/feature_map_generators.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v3_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_inception_v2_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/faster_rcnn_pnas_feature_extractor_test.py -> build/lib/object_detection/models\n","copying object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py -> build/lib/object_detection/models\n","creating build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/tf_example_decoder_test.py -> build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/__init__.py -> build/lib/object_detection/data_decoders\n","copying object_detection/data_decoders/tf_example_decoder.py -> build/lib/object_detection/data_decoders\n","creating build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/tf_example_parser.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_vrd_challenge_evaluation_utils.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_tools_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/tf_example_parser_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/offline_eval_map_corloc_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/__init__.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_tools.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_evaluation_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_challenge_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_challenge_evaluation_utils_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_metrics.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/io_utils.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_vrd_challenge_evaluation.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/calibration_metrics_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/oid_challenge_evaluation_utils.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/coco_evaluation_test.py -> build/lib/object_detection/metrics\n","copying object_detection/metrics/offline_eval_map_corloc.py -> build/lib/object_detection/metrics\n","creating build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/ssd_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/ssd_meta_arch_test_lib.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/rfcn_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/ssd_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/__init__.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/faster_rcnn_meta_arch_test.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/rfcn_meta_arch.py -> build/lib/object_detection/meta_architectures\n","copying object_detection/meta_architectures/faster_rcnn_meta_arch.py -> build/lib/object_detection/meta_architectures\n","creating build/lib/object_detection/inference\n","copying object_detection/inference/detection_inference_test.py -> build/lib/object_detection/inference\n","copying object_detection/inference/__init__.py -> build/lib/object_detection/inference\n","copying object_detection/inference/infer_detections.py -> build/lib/object_detection/inference\n","copying object_detection/inference/detection_inference.py -> build/lib/object_detection/inference\n","creating build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_keras_box_predictor_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_keras_box_predictor_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_keras_box_predictor_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_box_predictor_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_box_predictor_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/__init__.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_keras_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_keras_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/mask_rcnn_box_predictor_test.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/rfcn_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_keras_box_predictor.py -> build/lib/object_detection/predictors\n","copying object_detection/predictors/convolutional_box_predictor.py -> build/lib/object_detection/predictors\n","creating build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_mask_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list.py -> build/lib/object_detection/utils\n","copying object_detection/utils/static_shape_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/learning_schedules.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_mask_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/json_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/model_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_vrd_evaluation_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/metrics_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/spatial_transform_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/patch_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/learning_schedules_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/object_detection_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/test_case.py -> build/lib/object_detection/utils\n","copying object_detection/utils/__init__.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_vrd_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/category_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/autoaugment_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/shape_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/context_manager_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/variables_helper.py -> build/lib/object_detection/utils\n","copying object_detection/utils/shape_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/vrd_evaluation_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/config_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_mask_list_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/dataset_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list_ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/vrd_evaluation.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list.py -> build/lib/object_detection/utils\n","copying object_detection/utils/static_shape.py -> build/lib/object_detection/utils\n","copying object_detection/utils/per_image_evaluation_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/spatial_transform_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/json_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/variables_helper_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/visualization_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/dataset_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/metrics.py -> build/lib/object_detection/utils\n","copying object_detection/utils/test_utils.py -> build/lib/object_detection/utils\n","copying object_detection/utils/ops_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/patch_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/visualization_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/label_map_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/context_manager.py -> build/lib/object_detection/utils\n","copying object_detection/utils/test_utils_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/category_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/object_detection_evaluation_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/config_util.py -> build/lib/object_detection/utils\n","copying object_detection/utils/np_box_list_ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/ops.py -> build/lib/object_detection/utils\n","copying object_detection/utils/label_map_util_test.py -> build/lib/object_detection/utils\n","copying object_detection/utils/model_util_test.py -> build/lib/object_detection/utils\n","creating build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/flexible_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiple_grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/__init__.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiple_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/flexible_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/grid_anchor_generator_test.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/multiscale_grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","copying object_detection/anchor_generators/grid_anchor_generator.py -> build/lib/object_detection/anchor_generators\n","creating build/lib/object_detection/core\n","copying object_detection/core/multiclass_nms_test.py -> build/lib/object_detection/core\n","copying object_detection/core/post_processing.py -> build/lib/object_detection/core\n","copying object_detection/core/box_coder.py -> build/lib/object_detection/core\n","copying object_detection/core/prefetcher.py -> build/lib/object_detection/core\n","copying object_detection/core/data_parser.py -> build/lib/object_detection/core\n","copying object_detection/core/matcher_test.py -> build/lib/object_detection/core\n","copying object_detection/core/keypoint_ops.py -> build/lib/object_detection/core\n","copying object_detection/core/data_decoder.py -> build/lib/object_detection/core\n","copying object_detection/core/minibatch_sampler_test.py -> build/lib/object_detection/core\n","copying object_detection/core/balanced_positive_negative_sampler.py -> build/lib/object_detection/core\n","copying object_detection/core/box_coder_test.py -> build/lib/object_detection/core\n","copying object_detection/core/freezable_batch_norm.py -> build/lib/object_detection/core\n","copying object_detection/core/__init__.py -> build/lib/object_detection/core\n","copying object_detection/core/preprocessor_test.py -> build/lib/object_detection/core\n","copying object_detection/core/batcher.py -> build/lib/object_detection/core\n","copying object_detection/core/target_assigner.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list_ops_test.py -> build/lib/object_detection/core\n","copying object_detection/core/losses_test.py -> build/lib/object_detection/core\n","copying object_detection/core/batcher_test.py -> build/lib/object_detection/core\n","copying object_detection/core/keypoint_ops_test.py -> build/lib/object_detection/core\n","copying object_detection/core/preprocessor_cache.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list.py -> build/lib/object_detection/core\n","copying object_detection/core/region_similarity_calculator_test.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list_test.py -> build/lib/object_detection/core\n","copying object_detection/core/prefetcher_test.py -> build/lib/object_detection/core\n","copying object_detection/core/target_assigner_test.py -> build/lib/object_detection/core\n","copying object_detection/core/losses.py -> build/lib/object_detection/core\n","copying object_detection/core/model.py -> build/lib/object_detection/core\n","copying object_detection/core/freezable_batch_norm_test.py -> build/lib/object_detection/core\n","copying object_detection/core/preprocessor.py -> build/lib/object_detection/core\n","copying object_detection/core/anchor_generator.py -> build/lib/object_detection/core\n","copying object_detection/core/balanced_positive_negative_sampler_test.py -> build/lib/object_detection/core\n","copying object_detection/core/class_agnostic_nms_test.py -> build/lib/object_detection/core\n","copying object_detection/core/region_similarity_calculator.py -> build/lib/object_detection/core\n","copying object_detection/core/minibatch_sampler.py -> build/lib/object_detection/core\n","copying object_detection/core/box_list_ops.py -> build/lib/object_detection/core\n","copying object_detection/core/batch_multiclass_nms_test.py -> build/lib/object_detection/core\n","copying object_detection/core/standard_fields.py -> build/lib/object_detection/core\n","copying object_detection/core/box_predictor.py -> build/lib/object_detection/core\n","copying object_detection/core/matcher.py -> build/lib/object_detection/core\n","creating build/lib/object_detection/matchers\n","copying object_detection/matchers/argmax_matcher_test.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/bipartite_matcher.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/__init__.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/argmax_matcher.py -> build/lib/object_detection/matchers\n","copying object_detection/matchers/bipartite_matcher_test.py -> build/lib/object_detection/matchers\n","creating build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_tfrecord_creation_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_coco_tf_record_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_pascal_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/tf_record_creation_util.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_oid_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/__init__.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_kitti_tf_record_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_kitti_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_hierarchical_labels_expansion.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_pascal_tf_record_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/oid_tfrecord_creation.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_pet_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/create_coco_tf_record.py -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/tf_record_creation_util_test.py -> build/lib/object_detection/dataset_tools\n","creating build/lib/object_detection/box_coders\n","copying object_detection/box_coders/mean_stddev_box_coder_test.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/keypoint_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/__init__.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/faster_rcnn_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/square_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/mean_stddev_box_coder.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/keypoint_box_coder_test.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/square_box_coder_test.py -> build/lib/object_detection/box_coders\n","copying object_detection/box_coders/faster_rcnn_box_coder_test.py -> build/lib/object_detection/box_coders\n","creating build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/utils_test.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/export_saved_model_tpu_lib_test.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/ssd.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/__init__.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/faster_rcnn.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/export_saved_model_tpu_lib.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/export_saved_model_tpu.py -> build/lib/object_detection/tpu_exporters\n","copying object_detection/tpu_exporters/utils.py -> build/lib/object_detection/tpu_exporters\n","creating build/lib/object_detection/legacy\n","copying object_detection/legacy/evaluator.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/__init__.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/trainer.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/eval.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/train.py -> build/lib/object_detection/legacy\n","copying object_detection/legacy/trainer_test.py -> build/lib/object_detection/legacy\n","creating build/lib/object_detection/builders\n","copying object_detection/builders/dataset_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/post_processing_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/anchor_generator_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/model_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/calibration_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/region_similarity_calculator_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/hyperparams_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/optimizer_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/region_similarity_calculator_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/__init__.py -> build/lib/object_detection/builders\n","copying object_detection/builders/matcher_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/input_reader_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/optimizer_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/target_assigner_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/post_processing_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/matcher_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_predictor_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/input_reader_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/losses_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/anchor_generator_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/losses_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/preprocessor_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/graph_rewriter_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_predictor_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/target_assigner_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/image_resizer_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/image_resizer_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/model_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/hyperparams_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/preprocessor_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/calibration_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/graph_rewriter_builder_test.py -> build/lib/object_detection/builders\n","copying object_detection/builders/dataset_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_coder_builder.py -> build/lib/object_detection/builders\n","copying object_detection/builders/box_coder_builder_test.py -> build/lib/object_detection/builders\n","creating build/lib/object_detection/protos\n","copying object_detection/protos/region_similarity_calculator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/multiscale_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/preprocessor_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/mean_stddev_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/target_assigner_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/graph_rewriter_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/model_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/input_reader_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/losses_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/string_int_label_map_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/image_resizer_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/pipeline_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/__init__.py -> build/lib/object_detection/protos\n","copying object_detection/protos/bipartite_matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/post_processing_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/train_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/calibration_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/grid_anchor_generator_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/square_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/keypoint_box_coder_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/hyperparams_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/argmax_matcher_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/optimizer_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/eval_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/box_predictor_pb2.py -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/lib/object_detection/protos\n","creating build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v2.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/resnet_v1.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/__init__.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v1.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/inception_resnet_v2_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v1_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/model_utils.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/test_utils.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/resnet_v1_test.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/inception_resnet_v2.py -> build/lib/object_detection/models/keras_models\n","copying object_detection/models/keras_models/mobilenet_v2_test.py -> build/lib/object_detection/models/keras_models\n","creating build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/class_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/box_head_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/mask_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/__init__.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_class_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_mask_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/box_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_class_head_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_mask_head_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/class_head_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keypoint_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_box_head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keras_box_head_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/head.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/mask_head_test.py -> build/lib/object_detection/predictors/heads\n","copying object_detection/predictors/heads/keypoint_head_test.py -> build/lib/object_detection/predictors/heads\n","creating build/lib/object_detection/tpu_exporters/testdata\n","copying object_detection/tpu_exporters/testdata/__init__.py -> build/lib/object_detection/tpu_exporters/testdata\n","running egg_info\n","creating object_detection.egg-info\n","writing object_detection.egg-info/PKG-INFO\n","writing dependency_links to object_detection.egg-info/dependency_links.txt\n","writing requirements to object_detection.egg-info/requires.txt\n","writing top-level names to object_detection.egg-info/top_level.txt\n","writing manifest file 'object_detection.egg-info/SOURCES.txt'\n","writing manifest file 'object_detection.egg-info/SOURCES.txt'\n","copying object_detection/CONTRIBUTING.md -> build/lib/object_detection\n","copying object_detection/README.md -> build/lib/object_detection\n","copying object_detection/object_detection_tutorial.ipynb -> build/lib/object_detection\n","creating build/lib/object_detection/data\n","copying object_detection/data/ava_label_map_v2.1.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/face_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/fgvc_2854_classes_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/kitti_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/mscoco_complete_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/mscoco_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/mscoco_minival_ids.txt -> build/lib/object_detection/data\n","copying object_detection/data/oid_bbox_trainable_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/oid_v4_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/pascal_label_map.pbtxt -> build/lib/object_detection/data\n","copying object_detection/data/pet_label_map.pbtxt -> build/lib/object_detection/data\n","creating build/lib/object_detection/dockerfiles\n","creating build/lib/object_detection/dockerfiles/android\n","copying object_detection/dockerfiles/android/Dockerfile -> build/lib/object_detection/dockerfiles/android\n","copying object_detection/dockerfiles/android/README.md -> build/lib/object_detection/dockerfiles/android\n","creating build/lib/object_detection/g3doc\n","copying object_detection/g3doc/challenge_evaluation.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/configuring_jobs.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/defining_your_own_model.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/detection_model_zoo.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/evaluation_protocols.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/exporting_models.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/faq.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/installation.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/instance_segmentation.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/oid_inference_and_evaluation.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/preparing_inputs.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/running_locally.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/running_notebook.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/running_on_cloud.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/running_on_mobile_tensorflowlite.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/running_pets.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/tpu_compatibility.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/tpu_exporters.md -> build/lib/object_detection/g3doc\n","copying object_detection/g3doc/using_your_own_dataset.md -> build/lib/object_detection/g3doc\n","creating build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/dataset_explorer.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/dogs_detections_output.jpg -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/example_cat.jpg -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/groupof_case_eval.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/kites_detections_output.jpg -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/kites_with_segment_overlay.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/nongroupof_case_eval.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/oid_bus_72e19c28aac34ed8.jpg -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/oid_monkey_3b4168c89cecbc5b.jpg -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/oxford_pet.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/tensorboard.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/tensorboard2.png -> build/lib/object_detection/g3doc/img\n","copying object_detection/g3doc/img/tf-od-api-logo.png -> build/lib/object_detection/g3doc/img\n","creating build/lib/object_detection/samples\n","creating build/lib/object_detection/samples/cloud\n","copying object_detection/samples/cloud/cloud.yml -> build/lib/object_detection/samples/cloud\n","creating build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid_v4.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_v2_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_inception_v2_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_nas_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_atrous_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_ava_v2.1.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_kitti.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet101_voc07.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet152_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet152_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet50_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/faster_rcnn_resnet50_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/mask_rcnn_inception_v2_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/mask_rcnn_resnet101_atrous_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/mask_rcnn_resnet101_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/rfcn_resnet101_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/rfcn_resnet101_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_inception_v2_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_inception_v2_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_inception_v3_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets_inference.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_pets.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_fullyconv_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_oid_v4.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_pets_keras.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco_quant.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_v1_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_v3_large_320x320_coco.config -> build/lib/object_detection/samples/configs\n","copying object_detection/samples/configs/ssdlite_mobilenet_v3_small_320x320_coco.config -> build/lib/object_detection/samples/configs\n","creating build/lib/object_detection/test_ckpt\n","copying object_detection/test_ckpt/ssd_inception_v2.pb -> build/lib/object_detection/test_ckpt\n","creating build/lib/object_detection/test_data\n","copying object_detection/test_data/pets_examples.record -> build/lib/object_detection/test_data\n","creating build/lib/object_detection/test_images\n","copying object_detection/test_images/image1.jpg -> build/lib/object_detection/test_images\n","copying object_detection/test_images/image2.jpg -> build/lib/object_detection/test_images\n","copying object_detection/test_images/image_info.txt -> build/lib/object_detection/test_images\n","copying object_detection/dataset_tools/create_pycocotools_package.sh -> build/lib/object_detection/dataset_tools\n","copying object_detection/dataset_tools/download_and_preprocess_mscoco.sh -> build/lib/object_detection/dataset_tools\n","copying object_detection/protos/anchor_generator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/argmax_matcher.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/bipartite_matcher.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/box_coder.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/box_predictor.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/calibration.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/eval.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/faster_rcnn_box_coder.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/flexible_grid_anchor_generator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/graph_rewriter.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/grid_anchor_generator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/hyperparams.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/image_resizer.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/input_reader.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/keypoint_box_coder.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/losses.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/matcher.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/mean_stddev_box_coder.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/model.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/multiscale_anchor_generator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/optimizer.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/pipeline.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/post_processing.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/preprocessor.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/region_similarity_calculator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/square_box_coder.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/ssd_anchor_generator.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/string_int_label_map.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/target_assigner.proto -> build/lib/object_detection/protos\n","copying object_detection/protos/train.proto -> build/lib/object_detection/protos\n","creating build/lib/object_detection/models/keras_models/base_models\n","copying object_detection/models/keras_models/base_models/original_mobilenet_v2.py -> build/lib/object_detection/models/keras_models/base_models\n","creating build/lib/object_detection/tpu_exporters/testdata/faster_rcnn\n","copying object_detection/tpu_exporters/testdata/faster_rcnn/faster_rcnn_resnet101_atrous_coco.config -> build/lib/object_detection/tpu_exporters/testdata/faster_rcnn\n","creating build/lib/object_detection/tpu_exporters/testdata/ssd\n","copying object_detection/tpu_exporters/testdata/ssd/ssd_pipeline.config -> build/lib/object_detection/tpu_exporters/testdata/ssd\n","running install\n","running bdist_egg\n","running egg_info\n","writing object_detection.egg-info/PKG-INFO\n","writing dependency_links to object_detection.egg-info/dependency_links.txt\n","writing requirements to object_detection.egg-info/requires.txt\n","writing top-level names to object_detection.egg-info/top_level.txt\n","writing manifest file 'object_detection.egg-info/SOURCES.txt'\n","installing library code to build/bdist.linux-x86_64/egg\n","running install_lib\n","running build_py\n","creating build/bdist.linux-x86_64\n","creating build/bdist.linux-x86_64/egg\n","creating build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib_v2.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v3_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/feature_map_generators_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","creating build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/resnet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v1.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/inception_resnet_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","creating build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models\n","copying build/lib/object_detection/models/keras_models/base_models/original_mobilenet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/model_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/resnet_v1_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/inception_resnet_v2.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/keras_models/mobilenet_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection/models/keras_models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_pnasnet_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_nas_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/feature_map_generators.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_inception_v2_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/faster_rcnn_pnas_feature_extractor_test.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","copying build/lib/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py -> build/bdist.linux-x86_64/egg/object_detection/models\n","creating build/bdist.linux-x86_64/egg/object_detection/test_data\n","copying build/lib/object_detection/test_data/pets_examples.record -> build/bdist.linux-x86_64/egg/object_detection/test_data\n","creating build/bdist.linux-x86_64/egg/object_detection/dockerfiles\n","creating build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n","copying build/lib/object_detection/dockerfiles/android/README.md -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n","copying build/lib/object_detection/dockerfiles/android/Dockerfile -> build/bdist.linux-x86_64/egg/object_detection/dockerfiles/android\n","copying build/lib/object_detection/model_main.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/installation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/running_on_mobile_tensorflowlite.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/using_your_own_dataset.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/tpu_compatibility.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/evaluation_protocols.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/running_locally.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/instance_segmentation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/running_pets.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/challenge_evaluation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/preparing_inputs.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/exporting_models.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/running_on_cloud.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","creating build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/example_cat.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/oxford_pet.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/kites_detections_output.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/tensorboard.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/tensorboard2.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/nongroupof_case_eval.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/oid_monkey_3b4168c89cecbc5b.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/tf-od-api-logo.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/groupof_case_eval.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/dogs_detections_output.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/oid_bus_72e19c28aac34ed8.jpg -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/dataset_explorer.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/img/kites_with_segment_overlay.png -> build/bdist.linux-x86_64/egg/object_detection/g3doc/img\n","copying build/lib/object_detection/g3doc/tpu_exporters.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/configuring_jobs.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/detection_model_zoo.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/oid_inference_and_evaluation.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/defining_your_own_model.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/faq.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/g3doc/running_notebook.md -> build/bdist.linux-x86_64/egg/object_detection/g3doc\n","copying build/lib/object_detection/exporter_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/inputs_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_example_decoder_test.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","copying build/lib/object_detection/data_decoders/tf_example_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/data_decoders\n","creating build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/tf_example_parser.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_tools_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/tf_example_parser_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/offline_eval_map_corloc_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_tools.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_metrics.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/io_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_vrd_challenge_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/calibration_metrics_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/oid_challenge_evaluation_utils.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/coco_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","copying build/lib/object_detection/metrics/offline_eval_map_corloc.py -> build/bdist.linux-x86_64/egg/object_detection/metrics\n","creating build/bdist.linux-x86_64/egg/object_detection/test_images\n","copying build/lib/object_detection/test_images/image1.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images\n","copying build/lib/object_detection/test_images/image2.jpg -> build/bdist.linux-x86_64/egg/object_detection/test_images\n","copying build/lib/object_detection/test_images/image_info.txt -> build/bdist.linux-x86_64/egg/object_detection/test_images\n","creating build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch_test_lib.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/rfcn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/ssd_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/rfcn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","copying build/lib/object_detection/meta_architectures/faster_rcnn_meta_arch.py -> build/bdist.linux-x86_64/egg/object_detection/meta_architectures\n","creating build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/detection_inference_test.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/infer_detections.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","copying build/lib/object_detection/inference/detection_inference.py -> build/bdist.linux-x86_64/egg/object_detection/inference\n","creating build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","creating build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/box_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_class_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_mask_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_class_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_mask_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/class_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keypoint_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_box_head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keras_box_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/head.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/mask_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/heads/keypoint_head_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors/heads\n","copying build/lib/object_detection/predictors/convolutional_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/mask_rcnn_box_predictor_test.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/rfcn_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_keras_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","copying build/lib/object_detection/predictors/convolutional_box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/predictors\n","creating build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_mask_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/static_shape_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/learning_schedules.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_mask_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/json_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/model_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/metrics_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/spatial_transform_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/patch_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/learning_schedules_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/object_detection_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_case.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/category_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/autoaugment_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/shape_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/context_manager_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/variables_helper.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/shape_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/vrd_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/config_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_mask_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/dataset_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/vrd_evaluation.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/static_shape.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/per_image_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/spatial_transform_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/json_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/variables_helper_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/visualization_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/dataset_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/metrics.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_utils.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/patch_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/visualization_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/label_map_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/context_manager.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/test_utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/category_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/object_detection_evaluation_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/config_util.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/np_box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/ops.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/label_map_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/utils/model_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/utils\n","copying build/lib/object_detection/__init__.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/README.md -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiple_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/flexible_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/grid_anchor_generator_test.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/multiscale_grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/anchor_generators/grid_anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/anchor_generators\n","copying build/lib/object_detection/CONTRIBUTING.md -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_inference_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/post_processing.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/prefetcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/data_parser.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/keypoint_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/data_decoder.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/minibatch_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/balanced_positive_negative_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/freezable_batch_norm.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/target_assigner.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/losses_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/keypoint_ops_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor_cache.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/region_similarity_calculator_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/prefetcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/target_assigner_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/losses.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/model.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/freezable_batch_norm_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/preprocessor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/anchor_generator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/balanced_positive_negative_sampler_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/class_agnostic_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/region_similarity_calculator.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/minibatch_sampler.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_list_ops.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/batch_multiclass_nms_test.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/standard_fields.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/box_predictor.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/core/matcher.py -> build/bdist.linux-x86_64/egg/object_detection/core\n","copying build/lib/object_detection/export_tflite_ssd_graph_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/argmax_matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/bipartite_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/argmax_matcher.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","copying build/lib/object_detection/matchers/bipartite_matcher_test.py -> build/bdist.linux-x86_64/egg/object_detection/matchers\n","creating build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/kitti_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/pascal_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/ava_label_map_v2.1.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/mscoco_minival_ids.txt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/oid_bbox_trainable_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/oid_v4_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/mscoco_complete_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/fgvc_2854_classes_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/oid_object_detection_challenge_500_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/face_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/pet_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/data/mscoco_label_map.pbtxt -> build/bdist.linux-x86_64/egg/object_detection/data\n","copying build/lib/object_detection/object_detection_tutorial.ipynb -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_tpu_main.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/test_ckpt\n","copying build/lib/object_detection/test_ckpt/ssd_inception_v2.pb -> build/bdist.linux-x86_64/egg/object_detection/test_ckpt\n","copying build/lib/object_detection/exporter.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_hparams.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_ssd_graph.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib_v2_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/inputs.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/export_tflite_ssd_graph_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","copying build/lib/object_detection/model_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/samples\n","creating build/bdist.linux-x86_64/egg/object_detection/samples/cloud\n","copying build/lib/object_detection/samples/cloud/cloud.yml -> build/bdist.linux-x86_64/egg/object_detection/samples/cloud\n","creating build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_oid_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_nas_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/mask_rcnn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet152_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/mask_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/mask_rcnn_inception_resnet_v2_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco_quant.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_edgetpu_320x320_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_oid_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_ava_v2.1.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_v2_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_pets_keras.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_focal_loss_pets_inference.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v3_small_320x320_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/facessd_mobilenet_v2_quantized_320x320_open_image_v4.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_pets_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_inception_v2_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/mask_rcnn_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_quantized_300x300_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v2_fullyconv_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/rfcn_resnet101_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_inception_v2_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet152_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_inception_v3_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_fgvc.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_0.75_depth_quantized_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_voc07.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet50_fgvc.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v3_large_320x320_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_quantized_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_resnet101_v1_fpn_shared_box_predictor_oid_512x512_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/rfcn_resnet101_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_kitti.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssdlite_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_300x300_coco14_sync.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_cosine_lr_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/mask_rcnn_resnet50_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/embedded_ssd_mobilenet_v1_coco.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","copying build/lib/object_detection/samples/configs/ssd_mobilenet_v1_pets.config -> build/bdist.linux-x86_64/egg/object_detection/samples/configs\n","creating build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_coco_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pascal_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/tf_record_creation_util.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_oid_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_kitti_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/download_and_preprocess_mscoco.sh -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_kitti_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pascal_tf_record_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/oid_tfrecord_creation.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pet_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_pycocotools_package.sh -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/create_coco_tf_record.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","copying build/lib/object_detection/dataset_tools/tf_record_creation_util_test.py -> build/bdist.linux-x86_64/egg/object_detection/dataset_tools\n","creating build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/mean_stddev_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/keypoint_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/faster_rcnn_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/square_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/mean_stddev_box_coder.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/keypoint_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/square_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/box_coders/faster_rcnn_box_coder_test.py -> build/bdist.linux-x86_64/egg/object_detection/box_coders\n","copying build/lib/object_detection/model_lib.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/faster_rcnn\n","copying build/lib/object_detection/tpu_exporters/testdata/faster_rcnn/faster_rcnn_resnet101_atrous_coco.config -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/faster_rcnn\n","creating build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/ssd\n","copying build/lib/object_detection/tpu_exporters/testdata/ssd/ssd_pipeline.config -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/ssd\n","copying build/lib/object_detection/tpu_exporters/testdata/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata\n","copying build/lib/object_detection/tpu_exporters/utils_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib_test.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/ssd.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/faster_rcnn.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu_lib.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/export_saved_model_tpu.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/tpu_exporters/utils.py -> build/bdist.linux-x86_64/egg/object_detection/tpu_exporters\n","copying build/lib/object_detection/eval_util_test.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/evaluator.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/trainer.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/eval.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/train.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/legacy/trainer_test.py -> build/bdist.linux-x86_64/egg/object_detection/legacy\n","copying build/lib/object_detection/eval_util.py -> build/bdist.linux-x86_64/egg/object_detection\n","creating build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/dataset_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/post_processing_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/anchor_generator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/calibration_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/region_similarity_calculator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/hyperparams_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/optimizer_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/region_similarity_calculator_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/matcher_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/input_reader_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/optimizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/target_assigner_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/post_processing_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/matcher_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_predictor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/input_reader_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/losses_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/anchor_generator_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/losses_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/preprocessor_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/graph_rewriter_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_predictor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/target_assigner_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/image_resizer_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/image_resizer_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/model_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/hyperparams_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/preprocessor_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/calibration_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/graph_rewriter_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/dataset_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_coder_builder.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","copying build/lib/object_detection/builders/box_coder_builder_test.py -> build/bdist.linux-x86_64/egg/object_detection/builders\n","creating build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/region_similarity_calculator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/square_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/multiscale_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/preprocessor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/argmax_matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/mean_stddev_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/target_assigner_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/keypoint_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/graph_rewriter_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/flexible_grid_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/model_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/calibration.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/hyperparams.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/input_reader_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/losses_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/string_int_label_map_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/image_resizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/pipeline_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/preprocessor.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/__init__.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/model.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/bipartite_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/train.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/post_processing_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/image_resizer.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/optimizer.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/train_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/region_similarity_calculator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_predictor.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/grid_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/multiscale_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/flexible_grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/calibration_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/grid_anchor_generator_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/square_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/string_int_label_map.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/post_processing.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/keypoint_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd_anchor_generator.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/hyperparams_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/argmax_matcher_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/optimizer_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/bipartite_matcher.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/eval_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/ssd_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/input_reader.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/eval.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/pipeline.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/box_predictor_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/mean_stddev_box_coder.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/faster_rcnn_box_coder_pb2.py -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/target_assigner.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/losses.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","copying build/lib/object_detection/protos/graph_rewriter.proto -> build/bdist.linux-x86_64/egg/object_detection/protos\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_v2.py to model_lib_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_keras_feature_extractor.py to ssd_mobilenet_v2_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor_test.py to ssd_mobilenet_v1_ppn_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor.py to ssd_mobilenet_v2_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_keras_feature_extractor.py to ssd_resnet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor_test.py to faster_rcnn_resnet_v1_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor.py to ssd_mobilenet_v1_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor.py to ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_feature_extractor_test.py to ssd_mobilenet_v2_fpn_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_test.py to ssd_mobilenet_edgetpu_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor_test.py to ssd_inception_v2_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_keras_feature_extractor.py to faster_rcnn_inception_resnet_v2_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor_test.py to embedded_ssd_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor.py to ssd_inception_v3_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor.py to faster_rcnn_inception_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/embedded_ssd_mobilenet_v1_feature_extractor.py to embedded_ssd_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor.py to ssd_resnet_v1_fpn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v3_feature_extractor_test.py to ssd_inception_v3_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor_test.py to ssd_mobilenet_v3_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor_test.py to ssd_mobilenet_v2_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_keras_feature_extractor.py to ssd_mobilenet_v1_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators_test.py to feature_map_generators_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor.py to ssd_mobilenet_edgetpu_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2.py to mobilenet_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1.py to resnet_v1.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1.py to mobilenet_v1.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2_test.py to inception_resnet_v2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/base_models/original_mobilenet_v2.py to original_mobilenet_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v1_test.py to mobilenet_v1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/model_utils.py to model_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/test_utils.py to test_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/resnet_v1_test.py to resnet_v1_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/inception_resnet_v2.py to inception_resnet_v2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/keras_models/mobilenet_v2_test.py to mobilenet_v2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_feature_extractor_test.py to ssd_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_test.py to ssd_resnet_v1_fpn_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_v2_feature_extractor_test.py to faster_rcnn_inception_v2_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor.py to faster_rcnn_nas_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_feature_extractor.py to ssd_mobilenet_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor_test.py to ssd_pnasnet_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_feature_extractor_test.py to ssd_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_fpn_feature_extractor_testbase.py to ssd_resnet_v1_fpn_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor.py to faster_rcnn_mobilenet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_keras_feature_extractor.py to ssd_mobilenet_v1_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_testbase.py to ssd_resnet_v1_ppn_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor.py to ssd_resnet_v1_ppn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_pnasnet_feature_extractor.py to ssd_pnasnet_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_nas_feature_extractor_test.py to faster_rcnn_nas_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor.py to faster_rcnn_pnas_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/feature_map_generators.py to feature_map_generators.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v2_fpn_keras_feature_extractor.py to ssd_mobilenet_v2_fpn_keras_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_resnet_v1_feature_extractor.py to faster_rcnn_resnet_v1_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor.py to faster_rcnn_inception_resnet_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor.py to ssd_mobilenet_v3_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_edgetpu_feature_extractor_testbase.py to ssd_mobilenet_edgetpu_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_inception_resnet_v2_feature_extractor_test.py to faster_rcnn_inception_resnet_v2_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_inception_v2_feature_extractor.py to ssd_inception_v2_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_resnet_v1_ppn_feature_extractor_test.py to ssd_resnet_v1_ppn_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_ppn_feature_extractor.py to ssd_mobilenet_v1_ppn_feature_extractor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v1_fpn_feature_extractor_test.py to ssd_mobilenet_v1_fpn_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_mobilenet_v1_feature_extractor_test.py to faster_rcnn_mobilenet_v1_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/faster_rcnn_pnas_feature_extractor_test.py to faster_rcnn_pnas_feature_extractor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/models/ssd_mobilenet_v3_feature_extractor_testbase.py to ssd_mobilenet_v3_feature_extractor_testbase.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_main.py to model_main.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter_test.py to exporter_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs_test.py to inputs_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder_test.py to tf_example_decoder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/data_decoders/tf_example_decoder.py to tf_example_decoder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation.py to coco_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser.py to tf_example_parser.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils.py to oid_vrd_challenge_evaluation_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools_test.py to coco_tools_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/tf_example_parser_test.py to tf_example_parser_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc_test.py to offline_eval_map_corloc_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation_utils_test.py to oid_vrd_challenge_evaluation_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_tools.py to coco_tools.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation_test.py to calibration_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation.py to oid_challenge_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils_test.py to oid_challenge_evaluation_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics.py to calibration_metrics.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_evaluation.py to calibration_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/io_utils.py to io_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_vrd_challenge_evaluation.py to oid_vrd_challenge_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/calibration_metrics_test.py to calibration_metrics_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/oid_challenge_evaluation_utils.py to oid_challenge_evaluation_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/coco_evaluation_test.py to coco_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/metrics/offline_eval_map_corloc.py to offline_eval_map_corloc.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test.py to ssd_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test_lib.py to faster_rcnn_meta_arch_test_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch_test_lib.py to ssd_meta_arch_test_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch_test.py to rfcn_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/ssd_meta_arch.py to ssd_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch_test.py to faster_rcnn_meta_arch_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/rfcn_meta_arch.py to rfcn_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/meta_architectures/faster_rcnn_meta_arch.py to faster_rcnn_meta_arch.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference_test.py to detection_inference_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/infer_detections.py to infer_detections.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inference/detection_inference.py to detection_inference.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor_test.py to convolutional_keras_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor.py to mask_rcnn_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor_test.py to rfcn_keras_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor_test.py to mask_rcnn_keras_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor_test.py to rfcn_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head.py to class_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head_test.py to box_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head.py to mask_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head.py to keras_class_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head.py to keras_mask_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/box_head.py to box_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_class_head_test.py to keras_class_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_mask_head_test.py to keras_mask_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/class_head_test.py to class_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head.py to keypoint_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head.py to keras_box_head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keras_box_head_test.py to keras_box_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/head.py to head.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/mask_head_test.py to mask_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/heads/keypoint_head_test.py to keypoint_head_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor_test.py to convolutional_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_keras_box_predictor.py to mask_rcnn_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_keras_box_predictor.py to rfcn_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/mask_rcnn_box_predictor_test.py to mask_rcnn_box_predictor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/rfcn_box_predictor.py to rfcn_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_keras_box_predictor.py to convolutional_keras_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/predictors/convolutional_box_predictor.py to convolutional_box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops.py to np_box_mask_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops_test.py to np_box_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops.py to np_mask_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list.py to np_box_mask_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape_test.py to static_shape_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules.py to learning_schedules.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_mask_ops_test.py to np_mask_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils.py to json_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_ops_test.py to np_box_mask_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util.py to model_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation_test.py to per_image_vrd_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics_test.py to metrics_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_test.py to np_box_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops_test.py to spatial_transform_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/patch_ops_test.py to patch_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/learning_schedules_test.py to learning_schedules_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation.py to object_detection_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_case.py to test_case.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_vrd_evaluation.py to per_image_vrd_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util_test.py to category_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/autoaugment_utils.py to autoaugment_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils_test.py to shape_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager_test.py to context_manager_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper.py to variables_helper.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/shape_utils.py to shape_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation_test.py to vrd_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util_test.py to config_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_mask_list_test.py to np_box_mask_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util_test.py to dataset_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation.py to per_image_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops_test.py to np_box_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/vrd_evaluation.py to vrd_evaluation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list.py to np_box_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/static_shape.py to static_shape.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/per_image_evaluation_test.py to per_image_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/spatial_transform_ops.py to spatial_transform_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/json_utils_test.py to json_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/variables_helper_test.py to variables_helper_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils.py to visualization_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/dataset_util.py to dataset_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/metrics.py to metrics.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils.py to test_utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops_test.py to ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/patch_ops.py to patch_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_ops.py to np_box_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/visualization_utils_test.py to visualization_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util.py to label_map_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/context_manager.py to context_manager.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/test_utils_test.py to test_utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/category_util.py to category_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/object_detection_evaluation_test.py to object_detection_evaluation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/config_util.py to config_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/np_box_list_ops.py to np_box_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/ops.py to ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/label_map_util_test.py to label_map_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/utils/model_util_test.py to model_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator_test.py to flexible_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator_test.py to multiscale_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator_test.py to multiple_grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiple_grid_anchor_generator.py to multiple_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/flexible_grid_anchor_generator.py to flexible_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator_test.py to grid_anchor_generator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/multiscale_grid_anchor_generator.py to multiscale_grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/anchor_generators/grid_anchor_generator.py to grid_anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_inference_graph.py to export_inference_graph.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/multiclass_nms_test.py to multiclass_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/post_processing.py to post_processing.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder.py to box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher.py to prefetcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_parser.py to data_parser.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher_test.py to matcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops.py to keypoint_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/data_decoder.py to data_decoder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler_test.py to minibatch_sampler_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler.py to balanced_positive_negative_sampler.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_coder_test.py to box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm.py to freezable_batch_norm.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_test.py to preprocessor_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher.py to batcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner.py to target_assigner.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops_test.py to box_list_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses_test.py to losses_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batcher_test.py to batcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/keypoint_ops_test.py to keypoint_ops_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor_cache.py to preprocessor_cache.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list.py to box_list.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator_test.py to region_similarity_calculator_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_test.py to box_list_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/prefetcher_test.py to prefetcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/target_assigner_test.py to target_assigner_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/losses.py to losses.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/model.py to model.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/freezable_batch_norm_test.py to freezable_batch_norm_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/preprocessor.py to preprocessor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/anchor_generator.py to anchor_generator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/balanced_positive_negative_sampler_test.py to balanced_positive_negative_sampler_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/class_agnostic_nms_test.py to class_agnostic_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/region_similarity_calculator.py to region_similarity_calculator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/minibatch_sampler.py to minibatch_sampler.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_list_ops.py to box_list_ops.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/batch_multiclass_nms_test.py to batch_multiclass_nms_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/standard_fields.py to standard_fields.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/box_predictor.py to box_predictor.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/core/matcher.py to matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib.py to export_tflite_ssd_graph_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher_test.py to argmax_matcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher.py to bipartite_matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/argmax_matcher.py to argmax_matcher.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/matchers/bipartite_matcher_test.py to bipartite_matcher_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_tpu_main.py to model_tpu_main.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/exporter.py to exporter.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_hparams.py to model_hparams.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph.py to export_tflite_ssd_graph.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_v2_test.py to model_lib_v2_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/inputs.py to inputs.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/export_tflite_ssd_graph_lib_test.py to export_tflite_ssd_graph_lib_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib_test.py to model_lib_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation_test.py to oid_tfrecord_creation_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record_test.py to create_coco_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record.py to create_pascal_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util.py to tf_record_creation_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_oid_tf_record.py to create_oid_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record_test.py to create_kitti_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_kitti_tf_record.py to create_kitti_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion.py to oid_hierarchical_labels_expansion.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pascal_tf_record_test.py to create_pascal_tf_record_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_hierarchical_labels_expansion_test.py to oid_hierarchical_labels_expansion_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/oid_tfrecord_creation.py to oid_tfrecord_creation.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_pet_tf_record.py to create_pet_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/create_coco_tf_record.py to create_coco_tf_record.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/dataset_tools/tf_record_creation_util_test.py to tf_record_creation_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder_test.py to mean_stddev_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder.py to keypoint_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder.py to faster_rcnn_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder.py to square_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/mean_stddev_box_coder.py to mean_stddev_box_coder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/keypoint_box_coder_test.py to keypoint_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/square_box_coder_test.py to square_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/box_coders/faster_rcnn_box_coder_test.py to faster_rcnn_box_coder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/model_lib.py to model_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/testdata/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils_test.py to utils_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib_test.py to export_saved_model_tpu_lib_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/ssd.py to ssd.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/faster_rcnn.py to faster_rcnn.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu_lib.py to export_saved_model_tpu_lib.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/export_saved_model_tpu.py to export_saved_model_tpu.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/tpu_exporters/utils.py to utils.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util_test.py to eval_util_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/evaluator.py to evaluator.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer.py to trainer.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/eval.py to eval.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/train.py to train.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/legacy/trainer_test.py to trainer_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/eval_util.py to eval_util.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder_test.py to dataset_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder.py to post_processing_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder.py to anchor_generator_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder_test.py to model_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder_test.py to calibration_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder_test.py to region_similarity_calculator_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder.py to hyperparams_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder_test.py to optimizer_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/region_similarity_calculator_builder.py to region_similarity_calculator_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder_test.py to matcher_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder.py to input_reader_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/optimizer_builder.py to optimizer_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/target_assigner_builder_test.py to target_assigner_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/post_processing_builder_test.py to post_processing_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/matcher_builder.py to matcher_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder.py to box_predictor_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/input_reader_builder_test.py to input_reader_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder.py to losses_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/anchor_generator_builder_test.py to anchor_generator_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/losses_builder_test.py to losses_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder.py to preprocessor_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder.py to graph_rewriter_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_predictor_builder_test.py to box_predictor_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/target_assigner_builder.py to target_assigner_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder.py to image_resizer_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/image_resizer_builder_test.py to image_resizer_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/model_builder.py to model_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/hyperparams_builder_test.py to hyperparams_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/preprocessor_builder_test.py to preprocessor_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/calibration_builder.py to calibration_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/graph_rewriter_builder_test.py to graph_rewriter_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/dataset_builder.py to dataset_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder.py to box_coder_builder.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/builders/box_coder_builder_test.py to box_coder_builder_test.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/region_similarity_calculator_pb2.py to region_similarity_calculator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/multiscale_anchor_generator_pb2.py to multiscale_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/preprocessor_pb2.py to preprocessor_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/mean_stddev_box_coder_pb2.py to mean_stddev_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/target_assigner_pb2.py to target_assigner_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/graph_rewriter_pb2.py to graph_rewriter_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/model_pb2.py to model_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/input_reader_pb2.py to input_reader_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/losses_pb2.py to losses_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/string_int_label_map_pb2.py to string_int_label_map_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_coder_pb2.py to box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/image_resizer_pb2.py to image_resizer_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/pipeline_pb2.py to pipeline_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/__init__.py to __init__.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/bipartite_matcher_pb2.py to bipartite_matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/post_processing_pb2.py to post_processing_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/train_pb2.py to train_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/anchor_generator_pb2.py to anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_anchor_generator_pb2.py to ssd_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/flexible_grid_anchor_generator_pb2.py to flexible_grid_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/calibration_pb2.py to calibration_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/grid_anchor_generator_pb2.py to grid_anchor_generator_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/square_box_coder_pb2.py to square_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/matcher_pb2.py to matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/keypoint_box_coder_pb2.py to keypoint_box_coder_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_pb2.py to faster_rcnn_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/hyperparams_pb2.py to hyperparams_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/argmax_matcher_pb2.py to argmax_matcher_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/optimizer_pb2.py to optimizer_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/eval_pb2.py to eval_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/ssd_pb2.py to ssd_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/box_predictor_pb2.py to box_predictor_pb2.cpython-36.pyc\n","byte-compiling build/bdist.linux-x86_64/egg/object_detection/protos/faster_rcnn_box_coder_pb2.py to faster_rcnn_box_coder_pb2.cpython-36.pyc\n","creating build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","copying object_detection.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n","zip_safe flag not set; analyzing archive contents...\n","object_detection.core.__pycache__.preprocessor.cpython-36: module MAY be using inspect.stack\n","object_detection.utils.__pycache__.autoaugment_utils.cpython-36: module MAY be using inspect.stack\n","creating dist\n","creating 'dist/object_detection-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n","removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n","Processing object_detection-0.1-py3.6.egg\n","creating /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n","Extracting object_detection-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n","Adding object-detection 0.1 to easy-install.pth file\n","\n","Installed /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n","Processing dependencies for object-detection==0.1\n","Searching for Cython==0.29.14\n","Best match: Cython 0.29.14\n","Adding Cython 0.29.14 to easy-install.pth file\n","Installing cygdb script to /usr/local/bin\n","Installing cython script to /usr/local/bin\n","Installing cythonize script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for matplotlib==3.1.2\n","Best match: matplotlib 3.1.2\n","Adding matplotlib 3.1.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for Pillow==6.2.2\n","Best match: Pillow 6.2.2\n","Adding Pillow 6.2.2 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for cycler==0.10.0\n","Best match: cycler 0.10.0\n","Adding cycler 0.10.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for pyparsing==2.4.6\n","Best match: pyparsing 2.4.6\n","Adding pyparsing 2.4.6 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for python-dateutil==2.6.1\n","Best match: python-dateutil 2.6.1\n","Adding python-dateutil 2.6.1 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for kiwisolver==1.1.0\n","Best match: kiwisolver 1.1.0\n","Adding kiwisolver 1.1.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for numpy==1.17.5\n","Best match: numpy 1.17.5\n","Adding numpy 1.17.5 to easy-install.pth file\n","Installing f2py script to /usr/local/bin\n","Installing f2py3 script to /usr/local/bin\n","Installing f2py3.6 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for six==1.12.0\n","Best match: six 1.12.0\n","Adding six 1.12.0 to easy-install.pth file\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Searching for setuptools==42.0.2\n","Best match: setuptools 42.0.2\n","Adding setuptools 42.0.2 to easy-install.pth file\n","Installing easy_install script to /usr/local/bin\n","Installing easy_install-3.8 script to /usr/local/bin\n","\n","Using /usr/local/lib/python3.6/dist-packages\n","Finished processing dependencies for object-detection==0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ODMDm6Nvafv_","colab_type":"code","outputId":"806c1f7e-8e1d-420c-f2db-1582bc57d776","executionInfo":{"status":"ok","timestamp":1579503514607,"user_tz":360,"elapsed":1623,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import time, psutil\n","Start = time.time()- psutil.boot_time()\n","Left= 12*3600 - Start\n","print('Time remaining for this session is: ', Left/3600, \" hrs\")\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Time remaining for this session is:  10.890620882577366  hrs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QnTe_7Kwblj2","colab_type":"code","outputId":"976730d8-6ce1-463e-ef34-6fb5f861a855","executionInfo":{"status":"ok","timestamp":1579500659046,"user_tz":360,"elapsed":74647,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":884}},"source":["# Finally, we check if everything works. Download and run object_detection/object_detection_tutorial.ipynb if you need more help.\n","%%bash\n","python object_detection/builders/model_builder_test.py\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","Running tests under Python 3.6.9: /usr/bin/python3\n","[ RUN      ] ModelBuilderTest.test_create_experimental_model\n","[       OK ] ModelBuilderTest.test_create_experimental_model\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n","[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n","[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n","[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n","[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n","[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTest.test_session\n","[  SKIPPED ] ModelBuilderTest.test_session\n","[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n","[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n","[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n","[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 17 tests in 0.164s\n","\n","OK (skipped=1)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"IinsYj_VMKJr","colab_type":"code","outputId":"5502a641-df3e-472c-b92b-fcbe08cfdc1e","executionInfo":{"status":"ok","timestamp":1579500681972,"user_tz":360,"elapsed":95153,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["# We are currently in content/models/research (verify with os.getcwd()) \n","# We need to access some local (on our Drive) files.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# you may unmount with drive.flush_and_unmount(), then remount with drive.mount('content/drive')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QQoRRfJcMt8U","colab_type":"code","outputId":"eb464df6-c792-43ba-f00d-fdc6df41a4a8","executionInfo":{"status":"ok","timestamp":1579459343722,"user_tz":360,"elapsed":2435,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%cd /content/drive\n","# Note:\n","# Before we run xml_to_csv, we will need to change the directory to /content/drive/My Drive/Colab Notebooks/EnemyDetection/\n","# while the images are stored in \n","#   /content/drive/My Drive/Colab Notebooks/EnemyDetection/images/train     ...and...\n","#   /content/drive/My Drive/Colab Notebooks/EnemyDetection/images/test\n","\n","# But first, we prepare our dataset. Use LabelImg to save .xml for every single image\n","# Convert them to CSV files\n","%cd \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/\"\n","%ls\n","!python xml_to_csv.py\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive\n","/content/drive/My Drive/Colab Notebooks/EnemyDetection\n","eval.py\n","export_inference_graph.py\n","\u001b[0m\u001b[01;34mfaster_rcnn_inception_v2_coco_2018_01_28\u001b[0m/\n","faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\n","generate_tfrecord.py\n","\u001b[01;34mimages\u001b[0m/\n","\u001b[01;34minference_graph\u001b[0m/\n","LaunchTB.ipynb\n","model_main.py\n","object_detection_tutorial.ipynb\n","\u001b[01;34mssdlite_mobilenet_v2_coco_2018_05_09\u001b[0m/\n","ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz\n","\u001b[01;34mssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03\u001b[0m/\n","ssd_mobilenet_v1_ppn_shared_box_predictor_300x300_coco14_sync_2018_07_03.tar.gz\n","\u001b[01;34mtraining\u001b[0m/\n","train.py\n","Untitled0.ipynb\n","xml_to_csv.py\n","Working... this might take a moment.\n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Successfully converted train xml to csv. Check the images/ folder.\n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Parsing... \n","Successfully converted test xml to csv. Check the images/ folder.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"45wIvkOcp95j","colab_type":"code","outputId":"9eb3f815-0a2d-4103-f804-599eeca1e5f9","executionInfo":{"status":"ok","timestamp":1579459467779,"user_tz":360,"elapsed":79206,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Edit the generate_tfrecord.py :: class_text_to_int method.\n","\n","# Now use the CSV to generate the TFRecord file, and save them under training/\n","!python generate_tfrecord.py --csv_input=images/train_labels.csv --image_dir=images/train --output_path=training/train.record\n","!python generate_tfrecord.py --csv_input=images/test_labels.csv --image_dir=images/test --output_path=training/test.record\n","\n","print (\"Working directory: \" + os.getcwd() + \". \\nSaved .record file\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From generate_tfrecord.py:100: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:86: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0119 18:43:10.971299 139932316686208 module_wrapper.py:139] From generate_tfrecord.py:86: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:44: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0119 18:43:11.091238 139932316686208 module_wrapper.py:139] From generate_tfrecord.py:44: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Successfully created the TFRecords: /content/drive/My Drive/Colab Notebooks/EnemyDetection/training/train.record\n","WARNING:tensorflow:From generate_tfrecord.py:100: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:86: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","W0119 18:44:27.064172 140685195052928 module_wrapper.py:139] From generate_tfrecord.py:86: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n","WARNING:tensorflow:From generate_tfrecord.py:44: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0119 18:44:27.093922 140685195052928 module_wrapper.py:139] From generate_tfrecord.py:44: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Parsing file... \n","Successfully created the TFRecords: /content/drive/My Drive/Colab Notebooks/EnemyDetection/training/test.record\n","Working directory: /content/drive/My Drive/Colab Notebooks/EnemyDetection. \n","Saved .record file\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g7e7G6-0uP1S","colab_type":"code","outputId":"3d19f851-2def-43a6-8b2f-d8da9f740a61","executionInfo":{"status":"ok","timestamp":1579396051976,"user_tz":360,"elapsed":1562,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["### THE NEXT FEW STEPS ONLY NEED TO BE DOWNLOADED/COMPLETED/CREATED/SAVED ONCE! ###\n","%cd /content/drive/My Drive/Colab Notebooks/EnemyDetection\n","\n","# Create the pbtxt file (label map), and save it under training/\n","\n","# Download a model checkpoint (using https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md) > save it to a file\n","# !curl http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz > faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\n","!curl http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz > ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/EnemyDetection\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 48.6M  100 48.6M    0     0  65.0M      0 --:--:-- --:--:-- --:--:-- 65.1M\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yqKrx_p06kQG","colab_type":"code","outputId":"e3a750ed-5624-4f48-c178-9f84d8f1d1ec","executionInfo":{"status":"ok","timestamp":1579396075302,"user_tz":360,"elapsed":1672,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# and untar it\n","# !tar -xvf faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\n","!tar -xvf ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["ssdlite_mobilenet_v2_coco_2018_05_09/checkpoint\n","ssdlite_mobilenet_v2_coco_2018_05_09/model.ckpt.data-00000-of-00001\n","ssdlite_mobilenet_v2_coco_2018_05_09/model.ckpt.meta\n","ssdlite_mobilenet_v2_coco_2018_05_09/model.ckpt.index\n","ssdlite_mobilenet_v2_coco_2018_05_09/saved_model/saved_model.pb\n","ssdlite_mobilenet_v2_coco_2018_05_09/pipeline.config\n","ssdlite_mobilenet_v2_coco_2018_05_09/frozen_inference_graph.pb\n","ssdlite_mobilenet_v2_coco_2018_05_09/\n","ssdlite_mobilenet_v2_coco_2018_05_09/saved_model/variables/\n","ssdlite_mobilenet_v2_coco_2018_05_09/saved_model/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yw8d5oD3719u","colab_type":"code","outputId":"8b87b2c2-a59d-4df2-8299-51b8fb25e05d","executionInfo":{"status":"ok","timestamp":1579396108082,"user_tz":360,"elapsed":952,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Download the associated configuration from https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs . \n","# You'll need the Raw file for this! > save it to the training directory.\n","# !curl https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/samples/configs/faster_rcnn_inception_v2_coco.config > training/faster_rcnn_inception_v2_coco.config\n","!curl https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/samples/configs/ssdlite_mobilenet_v2_coco.config > training/ssdlite_mobilenet_v2_coco.config\n","\n","# Open the training/{xxx}.config file, and replace all instances of PATH_TO_BE_CONFIGURED appropriately\n","    # fine tune checkpoint: model.ckpt is in faster_rcnn_inception_v2_coco_2018_01_28...\n","                            # /content/drive/My Drive/Colab Notebooks/EnemyDetection/faster_rcnn_inception_v2_coco_2018_01_28/model.ckpt\n","                            ## OR... if resuming:\n","                            # /content/drive/My Drive/Colab Notebooks/EnemyDetection/training/log/model.ckpt\n","    # TRAIN: tf record input reader: .record is in training...\n","                            # /content/drive/My Drive/Colab Notebooks/EnemyDetection/training/train.record\n","    # TRAIN: label map path: .pbtxt is in training...\n","                            # /content/drive/My Drive/Colab Notebooks/EnemyDetection/training/labelmap.pbtxt\n","    # EVAL: tf record input reader: .record is in training\n","                            # /content/drive/My Drive/Colab Notebooks/EnemyDetection/training/test.record\n","    # EVAL: label map path: uses the same .pbtxt\n","                            # /content/drive/My Drive/Colab Notebooks/EnemyDetection/training/labelmap.pbtxt\n","\n","# Since the working directory is EnemyDetection/ you can probably shorten the paths, but being clear helps avoid error messages"],"execution_count":0,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  4778  100  4778    0     0  13346      0 --:--:-- --:--:-- --:--:-- 13309\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bCKLb-QV9K4X","colab_type":"code","outputId":"e0e1d580-17f9-4fea-d5c4-94fbe0729d73","executionInfo":{"status":"ok","timestamp":1579297840432,"user_tz":360,"elapsed":197165,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Launch Tensorboard (https://www.dlology.com/blog/quick-guide-to-run-tensorboard-in-google-colab/)\n","\n","print(\"Launching TensorBoard...\")\n","\n","LOG_DIR = 'training/log'\n","%load_ext tensorboard\n","%tensorboard --logdir 'training/log'\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Launching TensorBoard...\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","    <div id=\"root\"></div>\n","    <script>\n","      (function() {\n","        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n","        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n","        document.querySelector(\"base\").href = \"https://localhost:6006\";\n","        function fixUpTensorboard(root) {\n","          const tftb = root.querySelector(\"tf-tensorboard\");\n","          // Disable the fragment manipulation behavior in Colab. Not\n","          // only is the behavior not useful (as the iframe's location\n","          // is not visible to the user), it causes TensorBoard's usage\n","          // of `window.replace` to navigate away from the page and to\n","          // the `localhost:<port>` URL specified by the base URI, which\n","          // in turn causes the frame to (likely) crash.\n","          tftb.removeAttribute(\"use-hash\");\n","        }\n","        function executeAllScripts(root) {\n","          // When `script` elements are inserted into the DOM by\n","          // assigning to an element's `innerHTML`, the scripts are not\n","          // executed. Thus, we manually re-insert these scripts so that\n","          // TensorBoard can initialize itself.\n","          for (const script of root.querySelectorAll(\"script\")) {\n","            const newScript = document.createElement(\"script\");\n","            newScript.type = script.type;\n","            newScript.textContent = script.textContent;\n","            root.appendChild(newScript);\n","            script.remove();\n","          }\n","        }\n","        function setHeight(root, height) {\n","          // We set the height dynamically after the TensorBoard UI has\n","          // been initialized. This avoids an intermediate state in\n","          // which the container plus the UI become taller than the\n","          // final width and cause the Colab output frame to be\n","          // permanently resized, eventually leading to an empty\n","          // vertical gap below the TensorBoard UI. It's not clear\n","          // exactly what causes this problematic intermediate state,\n","          // but setting the height late seems to fix it.\n","          root.style.height = `${height}px`;\n","        }\n","        const root = document.getElementById(\"root\");\n","        fetch(\".\")\n","          .then((x) => x.text())\n","          .then((html) => void (root.innerHTML = html))\n","          .then(() => fixUpTensorboard(root))\n","          .then(() => executeAllScripts(root))\n","          .then(() => setHeight(root, 800));\n","      })();\n","    </script>\n","  "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Pu8rhuyIA5Yf","colab_type":"code","outputId":"f5f974b4-8ab2-477e-d4e4-e9b1ce0ecf18","executionInfo":{"status":"ok","timestamp":1579459484929,"user_tz":360,"elapsed":614,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Copy train.py from /content/models/research/object_detection/legacy into your EnemyDetection folder\n","import shutil\n","\n","# shutil.copyfile(\"/content/models/research/object_detection/legacy/train.py\", \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/train.py\")\n","# shutil.copyfile(\"/content/models/research/object_detection/legacy/eval.py\", \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/eval.py\")\n","shutil.copyfile(\"/content/models/research/object_detection/model_main.py\", \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/model_main.py\")"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Colab Notebooks/EnemyDetection/model_main.py'"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"R856gcZ3BpWX","colab_type":"code","outputId":"0fe46c46-5ab5-4eaa-a17b-162a5638cd40","executionInfo":{"status":"ok","timestamp":1579491600963,"user_tz":360,"elapsed":13096519,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["## CHANGELOG\n","# v0: Initial training with 250 ish images. Default configuration, stopped after 12k steps.\n","# v1: Added 300 images, CSV ended up with about 1000 in training. Used train.py. Configuration steps 25000.\n","# v2: Split images with train/test, so 800 training and about 50 in testing. Also changed to model_main.py, and configuration classes = 1, regularization = 0.01, batch size = 3, eval_config num_examples = 33 images in the testing directory.\n","#       This is working well. I'm worried about prediction times (https://stackoverflow.com/questions/46839073/tensorflow-object-detection-api-rcnn-is-slow-on-cpu-1-frame-per-min)\n","#       Perhaps I might try to train using mobilenet (ssd_mobilenet)\n","#       Other notes: eval.py might force drive update for Tensorboard?\n","#       average_precision: 0.612540 for 23143 steps, very good! Freezing now.\n","\n","#       Compiling on my laptop took ~ 1 minute :(\n","#       Yeah, we need another model.\n","# v3: Changed model to ssdlite_mobilenet_v2_coco_2018_05_09 in an attempt to improve speed, regularization = 0.004, image resize to 300x300. Cut after 5k steps since mAP was stuck at zero, loss decreasing slowly.\n","# v4: And that's when I got this genius idea: running mss with a 300x300 window in the middle of the 720p game running! \n","#       We need MORE DATA! So, now I have deprecated train to images/train_dep3; new and selected images moved to images/train and updated images/test!\n","#       v4.0: Trained to 17k steps using 720p & 300x300 in testing. \n","#       v4.1: Removed all 720p images from testing. Added 150 more images to test, 50 more images to train.\n","#       v4.2: Continue training to 60k steps. Edit config to 62 images. Enabled shuffling.\n","#       v4.3: I tried to export using Open CV DNN. This revealed errors importing the model with batch norm layers.\n","#       v4.4: I realized I had to export as a TFLite graph instead.\n","\n","# Then we run it. Change pipeline config path to your ssd_mobilenet_... model config.\n","# Remember, the train_dir must be the same as the Tensorboard LOG_DIR that it's watching\n","# Remember, Tensorflow will resume training at the checkpoint in training/log\n","# To start training all over again, MOVE or DELETE everything in training/log before you run the command. Personally, I append \"_dep\" for deprecated.\n","# Note that train.py and eval.py are copied from legacy, since they are depreacated. Use model_main.py !\n","%cd \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/\"\n","\n","#!python train.py --logtostderr --train_dir=training/log  --pipeline_config_path=training/faster_rcnn_inception_v2_coco.config\n","!python  model_main.py          --model_dir=training/log  --pipeline_config_path=training/ssdlite_mobilenet_v2_coco.config --alsologtostderr # --num_train_steps=80000 --num_eval_steps=1000"],"execution_count":72,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 2.26171\n","I0120 00:01:44.354454 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.26171\n","INFO:tensorflow:loss = 1.7343168, step = 30500 (44.215 sec)\n","I0120 00:01:44.355800 140441056839552 basic_session_run_hooks.py:260] loss = 1.7343168, step = 30500 (44.215 sec)\n","INFO:tensorflow:global_step/sec: 2.2806\n","I0120 00:02:28.202629 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2806\n","INFO:tensorflow:loss = 1.8041542, step = 30600 (43.848 sec)\n","I0120 00:02:28.203699 140441056839552 basic_session_run_hooks.py:260] loss = 1.8041542, step = 30600 (43.848 sec)\n","INFO:tensorflow:global_step/sec: 2.26228\n","I0120 00:03:12.405798 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.26228\n","INFO:tensorflow:loss = 3.0411854, step = 30700 (44.203 sec)\n","I0120 00:03:12.406804 140441056839552 basic_session_run_hooks.py:260] loss = 3.0411854, step = 30700 (44.203 sec)\n","INFO:tensorflow:global_step/sec: 2.27109\n","I0120 00:03:56.437439 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.27109\n","INFO:tensorflow:loss = 1.797482, step = 30800 (44.032 sec)\n","I0120 00:03:56.438769 140441056839552 basic_session_run_hooks.py:260] loss = 1.797482, step = 30800 (44.032 sec)\n","INFO:tensorflow:global_step/sec: 2.28518\n","I0120 00:04:40.197589 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28518\n","INFO:tensorflow:loss = 2.0331583, step = 30900 (43.760 sec)\n","I0120 00:04:40.198592 140441056839552 basic_session_run_hooks.py:260] loss = 2.0331583, step = 30900 (43.760 sec)\n","INFO:tensorflow:global_step/sec: 2.27004\n","I0120 00:05:24.249732 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.27004\n","INFO:tensorflow:loss = 1.6976749, step = 31000 (44.052 sec)\n","I0120 00:05:24.250752 140441056839552 basic_session_run_hooks.py:260] loss = 1.6976749, step = 31000 (44.052 sec)\n","INFO:tensorflow:global_step/sec: 2.26935\n","I0120 00:06:08.315240 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.26935\n","INFO:tensorflow:loss = 3.0929034, step = 31100 (44.066 sec)\n","I0120 00:06:08.316741 140441056839552 basic_session_run_hooks.py:260] loss = 3.0929034, step = 31100 (44.066 sec)\n","INFO:tensorflow:global_step/sec: 2.26321\n","I0120 00:06:52.500252 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.26321\n","INFO:tensorflow:loss = 2.364858, step = 31200 (44.185 sec)\n","I0120 00:06:52.501321 140441056839552 basic_session_run_hooks.py:260] loss = 2.364858, step = 31200 (44.185 sec)\n","INFO:tensorflow:global_step/sec: 2.2762\n","I0120 00:07:36.433188 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2762\n","INFO:tensorflow:loss = 1.6618155, step = 31300 (43.933 sec)\n","I0120 00:07:36.434256 140441056839552 basic_session_run_hooks.py:260] loss = 1.6618155, step = 31300 (43.933 sec)\n","INFO:tensorflow:Saving checkpoints for 31322 into training/log/model.ckpt.\n","I0120 00:07:45.933828 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 31322 into training/log/model.ckpt.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","W0120 00:07:46.113723 140441056839552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 00:07:48.680049 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:07:50.854485 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:07:50.931135 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:07:51.016672 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:07:51.098204 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:07:51.183108 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:07:51.260283 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0120 00:07:51.974192 140441056839552 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","Loading...\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0120 00:07:52.171847 140441056839552 deprecation.py:323] From /content/models/research/object_detection/utils/visualization_utils.py:498: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","WARNING:tensorflow:From /content/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","W0120 00:07:52.316213 140441056839552 module_wrapper.py:139] From /content/models/research/object_detection/utils/visualization_utils.py:1044: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","W0120 00:07:52.394675 140441056839552 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:484: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0120 00:07:52.758128 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T00:07:52Z\n","I0120 00:07:52.774895 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T00:07:52Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 00:07:53.263514 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 00:07:53.265003: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:07:53.265325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 00:07:53.265421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 00:07:53.265438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 00:07:53.265451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 00:07:53.265467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 00:07:53.265479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 00:07:53.265492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 00:07:53.265506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 00:07:53.265601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:07:53.265877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:07:53.266128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 00:07:53.266361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 00:07:53.266374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 00:07:53.266382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 00:07:53.266571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:07:53.266879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:07:53.267113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-31322\n","I0120 00:07:53.269217 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-31322\n","INFO:tensorflow:Running local_init_op.\n","I0120 00:07:54.482756 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 00:07:54.651073 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 00:07:58.899402 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 00:07:58.900982 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 00:07:58.905632 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.58s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.282\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.755\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.142\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.124\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.351\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.256\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.371\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.221\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.468\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n","INFO:tensorflow:Finished evaluation at 2020-01-20-00:07:59\n","I0120 00:07:59.633403 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-00:07:59\n","INFO:tensorflow:Saving dict for global step 31322: DetectionBoxes_Precision/mAP = 0.28241867, DetectionBoxes_Precision/mAP (large) = 0.35148516, DetectionBoxes_Precision/mAP (medium) = 0.3746006, DetectionBoxes_Precision/mAP (small) = 0.124001525, DetectionBoxes_Precision/mAP@.50IOU = 0.7550637, DetectionBoxes_Precision/mAP@.75IOU = 0.14154844, DetectionBoxes_Recall/AR@1 = 0.25619048, DetectionBoxes_Recall/AR@10 = 0.37142858, DetectionBoxes_Recall/AR@100 = 0.38666666, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = 0.46811596, DetectionBoxes_Recall/AR@100 (small) = 0.22058824, Loss/classification_loss = 7.394893, Loss/localization_loss = 1.4493057, Loss/regularization_loss = 0.3110377, Loss/total_loss = 9.155236, global_step = 31322, learning_rate = 0.004, loss = 9.155236\n","I0120 00:07:59.633670 140441056839552 estimator.py:2049] Saving dict for global step 31322: DetectionBoxes_Precision/mAP = 0.28241867, DetectionBoxes_Precision/mAP (large) = 0.35148516, DetectionBoxes_Precision/mAP (medium) = 0.3746006, DetectionBoxes_Precision/mAP (small) = 0.124001525, DetectionBoxes_Precision/mAP@.50IOU = 0.7550637, DetectionBoxes_Precision/mAP@.75IOU = 0.14154844, DetectionBoxes_Recall/AR@1 = 0.25619048, DetectionBoxes_Recall/AR@10 = 0.37142858, DetectionBoxes_Recall/AR@100 = 0.38666666, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = 0.46811596, DetectionBoxes_Recall/AR@100 (small) = 0.22058824, Loss/classification_loss = 7.394893, Loss/localization_loss = 1.4493057, Loss/regularization_loss = 0.3110377, Loss/total_loss = 9.155236, global_step = 31322, learning_rate = 0.004, loss = 9.155236\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 31322: training/log/model.ckpt-31322\n","I0120 00:08:00.435424 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 31322: training/log/model.ckpt-31322\n","INFO:tensorflow:global_step/sec: 1.69671\n","I0120 00:08:35.370743 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.69671\n","INFO:tensorflow:loss = 2.2156997, step = 31400 (58.938 sec)\n","I0120 00:08:35.372280 140441056839552 basic_session_run_hooks.py:260] loss = 2.2156997, step = 31400 (58.938 sec)\n","INFO:tensorflow:global_step/sec: 2.28243\n","I0120 00:09:19.183631 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28243\n","INFO:tensorflow:loss = 2.8383694, step = 31500 (43.812 sec)\n","I0120 00:09:19.184675 140441056839552 basic_session_run_hooks.py:260] loss = 2.8383694, step = 31500 (43.812 sec)\n","INFO:tensorflow:global_step/sec: 2.26189\n","I0120 00:10:03.394380 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.26189\n","INFO:tensorflow:loss = 1.7662418, step = 31600 (44.211 sec)\n","I0120 00:10:03.395398 140441056839552 basic_session_run_hooks.py:260] loss = 1.7662418, step = 31600 (44.211 sec)\n","INFO:tensorflow:global_step/sec: 2.28401\n","I0120 00:10:47.177018 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28401\n","INFO:tensorflow:loss = 2.3185253, step = 31700 (43.783 sec)\n","I0120 00:10:47.178694 140441056839552 basic_session_run_hooks.py:260] loss = 2.3185253, step = 31700 (43.783 sec)\n","INFO:tensorflow:global_step/sec: 2.26879\n","I0120 00:11:31.253322 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.26879\n","INFO:tensorflow:loss = 1.5319625, step = 31800 (44.076 sec)\n","I0120 00:11:31.254421 140441056839552 basic_session_run_hooks.py:260] loss = 1.5319625, step = 31800 (44.076 sec)\n","INFO:tensorflow:global_step/sec: 2.2726\n","I0120 00:12:15.255727 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2726\n","INFO:tensorflow:loss = 1.7037184, step = 31900 (44.002 sec)\n","I0120 00:12:15.256820 140441056839552 basic_session_run_hooks.py:260] loss = 1.7037184, step = 31900 (44.002 sec)\n","INFO:tensorflow:global_step/sec: 2.25061\n","I0120 00:12:59.688210 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.25061\n","INFO:tensorflow:loss = 2.4106798, step = 32000 (44.433 sec)\n","I0120 00:12:59.689648 140441056839552 basic_session_run_hooks.py:260] loss = 2.4106798, step = 32000 (44.433 sec)\n","INFO:tensorflow:global_step/sec: 2.25851\n","I0120 00:13:43.965238 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.25851\n","INFO:tensorflow:loss = 2.2154157, step = 32100 (44.277 sec)\n","I0120 00:13:43.966460 140441056839552 basic_session_run_hooks.py:260] loss = 2.2154157, step = 32100 (44.277 sec)\n","INFO:tensorflow:global_step/sec: 2.2723\n","I0120 00:14:27.973500 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2723\n","INFO:tensorflow:loss = 1.8899677, step = 32200 (44.008 sec)\n","I0120 00:14:27.974525 140441056839552 basic_session_run_hooks.py:260] loss = 1.8899677, step = 32200 (44.008 sec)\n","INFO:tensorflow:global_step/sec: 2.2718\n","I0120 00:15:11.991448 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2718\n","INFO:tensorflow:loss = 2.375655, step = 32300 (44.018 sec)\n","I0120 00:15:11.992736 140441056839552 basic_session_run_hooks.py:260] loss = 2.375655, step = 32300 (44.018 sec)\n","INFO:tensorflow:global_step/sec: 2.29644\n","I0120 00:15:55.537191 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29644\n","INFO:tensorflow:loss = 1.7075727, step = 32400 (43.546 sec)\n","I0120 00:15:55.538304 140441056839552 basic_session_run_hooks.py:260] loss = 1.7075727, step = 32400 (43.546 sec)\n","INFO:tensorflow:global_step/sec: 2.2492\n","I0120 00:16:39.997410 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2492\n","INFO:tensorflow:loss = 1.7373037, step = 32500 (44.460 sec)\n","I0120 00:16:39.998311 140441056839552 basic_session_run_hooks.py:260] loss = 1.7373037, step = 32500 (44.460 sec)\n","INFO:tensorflow:global_step/sec: 2.29132\n","I0120 00:17:23.640411 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29132\n","INFO:tensorflow:loss = 2.3220398, step = 32600 (43.644 sec)\n","I0120 00:17:23.641992 140441056839552 basic_session_run_hooks.py:260] loss = 2.3220398, step = 32600 (43.644 sec)\n","INFO:tensorflow:Saving checkpoints for 32652 into training/log/model.ckpt.\n","I0120 00:17:45.991322 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 32652 into training/log/model.ckpt.\n","INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n","I0120 00:17:47.760907 140441056839552 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n","INFO:tensorflow:global_step/sec: 2.18415\n","I0120 00:18:09.425098 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.18415\n","INFO:tensorflow:loss = 3.056131, step = 32700 (45.784 sec)\n","I0120 00:18:09.426194 140441056839552 basic_session_run_hooks.py:260] loss = 3.056131, step = 32700 (45.784 sec)\n","INFO:tensorflow:global_step/sec: 2.27226\n","I0120 00:18:53.433855 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.27226\n","INFO:tensorflow:loss = 1.8876796, step = 32800 (44.010 sec)\n","I0120 00:18:53.435828 140441056839552 basic_session_run_hooks.py:260] loss = 1.8876796, step = 32800 (44.010 sec)\n","INFO:tensorflow:global_step/sec: 2.2802\n","I0120 00:19:37.289665 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2802\n","INFO:tensorflow:loss = 2.3640366, step = 32900 (43.855 sec)\n","I0120 00:19:37.291105 140441056839552 basic_session_run_hooks.py:260] loss = 2.3640366, step = 32900 (43.855 sec)\n","INFO:tensorflow:global_step/sec: 2.2773\n","I0120 00:20:21.201322 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2773\n","INFO:tensorflow:loss = 2.0063543, step = 33000 (43.911 sec)\n","I0120 00:20:21.202350 140441056839552 basic_session_run_hooks.py:260] loss = 2.0063543, step = 33000 (43.911 sec)\n","INFO:tensorflow:global_step/sec: 2.27265\n","I0120 00:21:05.202821 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.27265\n","INFO:tensorflow:loss = 2.17295, step = 33100 (44.002 sec)\n","I0120 00:21:05.203909 140441056839552 basic_session_run_hooks.py:260] loss = 2.17295, step = 33100 (44.002 sec)\n","INFO:tensorflow:global_step/sec: 2.30135\n","I0120 00:21:48.655497 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30135\n","INFO:tensorflow:loss = 2.0773861, step = 33200 (43.453 sec)\n","I0120 00:21:48.657199 140441056839552 basic_session_run_hooks.py:260] loss = 2.0773861, step = 33200 (43.453 sec)\n","INFO:tensorflow:global_step/sec: 2.28033\n","I0120 00:22:32.508777 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28033\n","INFO:tensorflow:loss = 1.984193, step = 33300 (43.853 sec)\n","I0120 00:22:32.509909 140441056839552 basic_session_run_hooks.py:260] loss = 1.984193, step = 33300 (43.853 sec)\n","INFO:tensorflow:global_step/sec: 2.29553\n","I0120 00:23:16.071794 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29553\n","INFO:tensorflow:loss = 2.2616668, step = 33400 (43.563 sec)\n","I0120 00:23:16.072806 140441056839552 basic_session_run_hooks.py:260] loss = 2.2616668, step = 33400 (43.563 sec)\n","INFO:tensorflow:global_step/sec: 2.27507\n","I0120 00:24:00.026397 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.27507\n","INFO:tensorflow:loss = 2.6460197, step = 33500 (43.955 sec)\n","I0120 00:24:00.027648 140441056839552 basic_session_run_hooks.py:260] loss = 2.6460197, step = 33500 (43.955 sec)\n","INFO:tensorflow:global_step/sec: 2.28121\n","I0120 00:24:43.862726 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28121\n","INFO:tensorflow:loss = 1.616775, step = 33600 (43.836 sec)\n","I0120 00:24:43.863894 140441056839552 basic_session_run_hooks.py:260] loss = 1.616775, step = 33600 (43.836 sec)\n","INFO:tensorflow:global_step/sec: 2.29108\n","I0120 00:25:27.510270 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29108\n","INFO:tensorflow:loss = 2.2234435, step = 33700 (43.648 sec)\n","I0120 00:25:27.511550 140441056839552 basic_session_run_hooks.py:260] loss = 2.2234435, step = 33700 (43.648 sec)\n","INFO:tensorflow:global_step/sec: 2.2805\n","I0120 00:26:11.360344 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2805\n","INFO:tensorflow:loss = 2.1246147, step = 33800 (43.850 sec)\n","I0120 00:26:11.361780 140441056839552 basic_session_run_hooks.py:260] loss = 2.1246147, step = 33800 (43.850 sec)\n","INFO:tensorflow:global_step/sec: 2.28679\n","I0120 00:26:55.089796 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28679\n","INFO:tensorflow:loss = 1.7674549, step = 33900 (43.729 sec)\n","I0120 00:26:55.090846 140441056839552 basic_session_run_hooks.py:260] loss = 1.7674549, step = 33900 (43.729 sec)\n","INFO:tensorflow:global_step/sec: 2.28851\n","I0120 00:27:38.786408 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28851\n","INFO:tensorflow:loss = 2.1453013, step = 34000 (43.697 sec)\n","I0120 00:27:38.787446 140441056839552 basic_session_run_hooks.py:260] loss = 2.1453013, step = 34000 (43.697 sec)\n","INFO:tensorflow:Saving checkpoints for 34018 into training/log/model.ckpt.\n","I0120 00:27:46.212690 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 34018 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 00:27:48.618080 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:27:51.073420 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:27:51.149837 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:27:51.234487 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:27:51.314705 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:27:51.394680 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:27:51.485942 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 00:27:52.916460 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T00:27:52Z\n","I0120 00:27:52.932185 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T00:27:52Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 00:27:53.404325 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 00:27:53.405049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:27:53.405362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 00:27:53.405464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 00:27:53.405490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 00:27:53.405512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 00:27:53.405536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 00:27:53.405562: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 00:27:53.405599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 00:27:53.405622: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 00:27:53.405741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:27:53.406071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:27:53.406312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 00:27:53.406355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 00:27:53.406369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 00:27:53.406379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 00:27:53.406515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:27:53.406816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:27:53.407067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-34018\n","I0120 00:27:53.409162 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-34018\n","INFO:tensorflow:Running local_init_op.\n","I0120 00:27:54.493939 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 00:27:54.639353 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 00:27:58.539033 140437385447168 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 00:27:58.539784 140437385447168 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 00:27:58.544593 140437385447168 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.57s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.749\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.209\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.163\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.402\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.402\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.265\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.399\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.426\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.265\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.506\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n","INFO:tensorflow:Finished evaluation at 2020-01-20-00:27:59\n","I0120 00:27:59.264045 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-00:27:59\n","INFO:tensorflow:Saving dict for global step 34018: DetectionBoxes_Precision/mAP = 0.3160509, DetectionBoxes_Precision/mAP (large) = 0.4019802, DetectionBoxes_Precision/mAP (medium) = 0.40169898, DetectionBoxes_Precision/mAP (small) = 0.16297309, DetectionBoxes_Precision/mAP@.50IOU = 0.7490885, DetectionBoxes_Precision/mAP@.75IOU = 0.20874283, DetectionBoxes_Recall/AR@1 = 0.2647619, DetectionBoxes_Recall/AR@10 = 0.3990476, DetectionBoxes_Recall/AR@100 = 0.42571428, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = 0.5057971, DetectionBoxes_Recall/AR@100 (small) = 0.2647059, Loss/classification_loss = 7.204881, Loss/localization_loss = 1.4819179, Loss/regularization_loss = 0.31245807, Loss/total_loss = 8.999255, global_step = 34018, learning_rate = 0.004, loss = 8.999255\n","I0120 00:27:59.264353 140441056839552 estimator.py:2049] Saving dict for global step 34018: DetectionBoxes_Precision/mAP = 0.3160509, DetectionBoxes_Precision/mAP (large) = 0.4019802, DetectionBoxes_Precision/mAP (medium) = 0.40169898, DetectionBoxes_Precision/mAP (small) = 0.16297309, DetectionBoxes_Precision/mAP@.50IOU = 0.7490885, DetectionBoxes_Precision/mAP@.75IOU = 0.20874283, DetectionBoxes_Recall/AR@1 = 0.2647619, DetectionBoxes_Recall/AR@10 = 0.3990476, DetectionBoxes_Recall/AR@100 = 0.42571428, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = 0.5057971, DetectionBoxes_Recall/AR@100 (small) = 0.2647059, Loss/classification_loss = 7.204881, Loss/localization_loss = 1.4819179, Loss/regularization_loss = 0.31245807, Loss/total_loss = 8.999255, global_step = 34018, learning_rate = 0.004, loss = 8.999255\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 34018: training/log/model.ckpt-34018\n","I0120 00:27:59.267101 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 34018: training/log/model.ckpt-34018\n","INFO:tensorflow:global_step/sec: 1.7504\n","I0120 00:28:35.916313 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.7504\n","INFO:tensorflow:loss = 1.6822107, step = 34100 (57.130 sec)\n","I0120 00:28:35.917499 140441056839552 basic_session_run_hooks.py:260] loss = 1.6822107, step = 34100 (57.130 sec)\n","INFO:tensorflow:global_step/sec: 2.28849\n","I0120 00:29:19.613403 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28849\n","INFO:tensorflow:loss = 1.726611, step = 34200 (43.697 sec)\n","I0120 00:29:19.614389 140441056839552 basic_session_run_hooks.py:260] loss = 1.726611, step = 34200 (43.697 sec)\n","INFO:tensorflow:global_step/sec: 2.29179\n","I0120 00:30:03.247359 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29179\n","INFO:tensorflow:loss = 1.5551045, step = 34300 (43.634 sec)\n","I0120 00:30:03.248234 140441056839552 basic_session_run_hooks.py:260] loss = 1.5551045, step = 34300 (43.634 sec)\n","INFO:tensorflow:global_step/sec: 2.29529\n","I0120 00:30:46.814903 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29529\n","INFO:tensorflow:loss = 1.9501936, step = 34400 (43.568 sec)\n","I0120 00:30:46.816406 140441056839552 basic_session_run_hooks.py:260] loss = 1.9501936, step = 34400 (43.568 sec)\n","INFO:tensorflow:global_step/sec: 2.29001\n","I0120 00:31:30.482808 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29001\n","INFO:tensorflow:loss = 1.4458396, step = 34500 (43.668 sec)\n","I0120 00:31:30.484159 140441056839552 basic_session_run_hooks.py:260] loss = 1.4458396, step = 34500 (43.668 sec)\n","INFO:tensorflow:global_step/sec: 2.30168\n","I0120 00:32:13.929325 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30168\n","INFO:tensorflow:loss = 1.271109, step = 34600 (43.446 sec)\n","I0120 00:32:13.930281 140441056839552 basic_session_run_hooks.py:260] loss = 1.271109, step = 34600 (43.446 sec)\n","INFO:tensorflow:global_step/sec: 2.29895\n","I0120 00:32:57.427381 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29895\n","INFO:tensorflow:loss = 1.8414481, step = 34700 (43.499 sec)\n","I0120 00:32:57.428991 140441056839552 basic_session_run_hooks.py:260] loss = 1.8414481, step = 34700 (43.499 sec)\n","INFO:tensorflow:global_step/sec: 2.29699\n","I0120 00:33:40.962663 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29699\n","INFO:tensorflow:loss = 1.607116, step = 34800 (43.535 sec)\n","I0120 00:33:40.963674 140441056839552 basic_session_run_hooks.py:260] loss = 1.607116, step = 34800 (43.535 sec)\n","INFO:tensorflow:global_step/sec: 2.30393\n","I0120 00:34:24.366772 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30393\n","INFO:tensorflow:loss = 1.515446, step = 34900 (43.404 sec)\n","I0120 00:34:24.367773 140441056839552 basic_session_run_hooks.py:260] loss = 1.515446, step = 34900 (43.404 sec)\n","INFO:tensorflow:global_step/sec: 2.29726\n","I0120 00:35:07.897220 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29726\n","INFO:tensorflow:loss = 1.5444605, step = 35000 (43.531 sec)\n","I0120 00:35:07.898664 140441056839552 basic_session_run_hooks.py:260] loss = 1.5444605, step = 35000 (43.531 sec)\n","INFO:tensorflow:global_step/sec: 2.27839\n","I0120 00:35:51.787698 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.27839\n","INFO:tensorflow:loss = 1.8335732, step = 35100 (43.890 sec)\n","I0120 00:35:51.788583 140441056839552 basic_session_run_hooks.py:260] loss = 1.8335732, step = 35100 (43.890 sec)\n","INFO:tensorflow:global_step/sec: 2.31099\n","I0120 00:36:35.059250 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31099\n","INFO:tensorflow:loss = 1.4404042, step = 35200 (43.272 sec)\n","I0120 00:36:35.060130 140441056839552 basic_session_run_hooks.py:260] loss = 1.4404042, step = 35200 (43.272 sec)\n","INFO:tensorflow:global_step/sec: 2.28849\n","I0120 00:37:18.756282 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28849\n","INFO:tensorflow:loss = 2.4186945, step = 35300 (43.698 sec)\n","I0120 00:37:18.757772 140441056839552 basic_session_run_hooks.py:260] loss = 2.4186945, step = 35300 (43.698 sec)\n","INFO:tensorflow:Saving checkpoints for 35365 into training/log/model.ckpt.\n","I0120 00:37:46.501466 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 35365 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 00:37:48.945701 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:37:51.067250 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:37:51.155320 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:37:51.241722 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:37:51.318258 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:37:51.406963 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:37:51.492259 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 00:37:52.931017 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T00:37:52Z\n","I0120 00:37:52.946852 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T00:37:52Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 00:37:53.452596 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 00:37:53.453290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:37:53.453589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 00:37:53.453695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 00:37:53.453721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 00:37:53.453746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 00:37:53.453768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 00:37:53.453789: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 00:37:53.453813: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 00:37:53.453838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 00:37:53.453977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:37:53.454351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:37:53.454587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 00:37:53.454701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 00:37:53.454717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 00:37:53.454726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 00:37:53.454861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:37:53.455181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:37:53.455417: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-35365\n","I0120 00:37:53.457309 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-35365\n","INFO:tensorflow:Running local_init_op.\n","I0120 00:37:54.509013 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 00:37:54.640955 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 00:37:58.425674 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 00:37:58.426956 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 00:37:58.432741 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.54s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.771\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.175\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.167\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.408\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.451\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.261\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.404\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.423\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.291\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n","INFO:tensorflow:Finished evaluation at 2020-01-20-00:37:59\n","I0120 00:37:59.115931 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-00:37:59\n","INFO:tensorflow:Saving dict for global step 35365: DetectionBoxes_Precision/mAP = 0.32595435, DetectionBoxes_Precision/mAP (large) = 0.45052567, DetectionBoxes_Precision/mAP (medium) = 0.40754277, DetectionBoxes_Precision/mAP (small) = 0.16724598, DetectionBoxes_Precision/mAP@.50IOU = 0.7707884, DetectionBoxes_Precision/mAP@.75IOU = 0.17484267, DetectionBoxes_Recall/AR@1 = 0.26095238, DetectionBoxes_Recall/AR@10 = 0.40380952, DetectionBoxes_Recall/AR@100 = 0.42285714, DetectionBoxes_Recall/AR@100 (large) = 0.5, DetectionBoxes_Recall/AR@100 (medium) = 0.48550725, DetectionBoxes_Recall/AR@100 (small) = 0.29117647, Loss/classification_loss = 6.516556, Loss/localization_loss = 1.4368083, Loss/regularization_loss = 0.31307092, Loss/total_loss = 8.266435, global_step = 35365, learning_rate = 0.004, loss = 8.266435\n","I0120 00:37:59.116225 140441056839552 estimator.py:2049] Saving dict for global step 35365: DetectionBoxes_Precision/mAP = 0.32595435, DetectionBoxes_Precision/mAP (large) = 0.45052567, DetectionBoxes_Precision/mAP (medium) = 0.40754277, DetectionBoxes_Precision/mAP (small) = 0.16724598, DetectionBoxes_Precision/mAP@.50IOU = 0.7707884, DetectionBoxes_Precision/mAP@.75IOU = 0.17484267, DetectionBoxes_Recall/AR@1 = 0.26095238, DetectionBoxes_Recall/AR@10 = 0.40380952, DetectionBoxes_Recall/AR@100 = 0.42285714, DetectionBoxes_Recall/AR@100 (large) = 0.5, DetectionBoxes_Recall/AR@100 (medium) = 0.48550725, DetectionBoxes_Recall/AR@100 (small) = 0.29117647, Loss/classification_loss = 6.516556, Loss/localization_loss = 1.4368083, Loss/regularization_loss = 0.31307092, Loss/total_loss = 8.266435, global_step = 35365, learning_rate = 0.004, loss = 8.266435\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 35365: training/log/model.ckpt-35365\n","I0120 00:37:59.118947 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 35365: training/log/model.ckpt-35365\n","INFO:tensorflow:global_step/sec: 1.78602\n","I0120 00:38:14.746489 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.78602\n","INFO:tensorflow:loss = 1.6588268, step = 35400 (55.990 sec)\n","I0120 00:38:14.747498 140441056839552 basic_session_run_hooks.py:260] loss = 1.6588268, step = 35400 (55.990 sec)\n","INFO:tensorflow:global_step/sec: 2.28146\n","I0120 00:38:58.578175 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28146\n","INFO:tensorflow:loss = 2.1103575, step = 35500 (43.832 sec)\n","I0120 00:38:58.579198 140441056839552 basic_session_run_hooks.py:260] loss = 2.1103575, step = 35500 (43.832 sec)\n","INFO:tensorflow:global_step/sec: 2.28545\n","I0120 00:39:42.333322 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28545\n","INFO:tensorflow:loss = 2.7331653, step = 35600 (43.756 sec)\n","I0120 00:39:42.334957 140441056839552 basic_session_run_hooks.py:260] loss = 2.7331653, step = 35600 (43.756 sec)\n","INFO:tensorflow:global_step/sec: 2.29366\n","I0120 00:40:25.931745 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29366\n","INFO:tensorflow:loss = 1.576217, step = 35700 (43.598 sec)\n","I0120 00:40:25.932744 140441056839552 basic_session_run_hooks.py:260] loss = 1.576217, step = 35700 (43.598 sec)\n","INFO:tensorflow:global_step/sec: 2.2898\n","I0120 00:41:09.603631 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2898\n","INFO:tensorflow:loss = 2.201328, step = 35800 (43.672 sec)\n","I0120 00:41:09.604653 140441056839552 basic_session_run_hooks.py:260] loss = 2.201328, step = 35800 (43.672 sec)\n","INFO:tensorflow:global_step/sec: 2.30826\n","I0120 00:41:52.926247 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30826\n","INFO:tensorflow:loss = 1.5920321, step = 35900 (43.323 sec)\n","I0120 00:41:52.927830 140441056839552 basic_session_run_hooks.py:260] loss = 1.5920321, step = 35900 (43.323 sec)\n","INFO:tensorflow:global_step/sec: 2.29353\n","I0120 00:42:36.527126 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29353\n","INFO:tensorflow:loss = 2.0439076, step = 36000 (43.601 sec)\n","I0120 00:42:36.528728 140441056839552 basic_session_run_hooks.py:260] loss = 2.0439076, step = 36000 (43.601 sec)\n","INFO:tensorflow:global_step/sec: 2.30458\n","I0120 00:43:19.918956 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30458\n","INFO:tensorflow:loss = 2.471436, step = 36100 (43.391 sec)\n","I0120 00:43:19.920154 140441056839552 basic_session_run_hooks.py:260] loss = 2.471436, step = 36100 (43.391 sec)\n","INFO:tensorflow:global_step/sec: 2.29893\n","I0120 00:44:03.417460 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29893\n","INFO:tensorflow:loss = 2.0107284, step = 36200 (43.499 sec)\n","I0120 00:44:03.418710 140441056839552 basic_session_run_hooks.py:260] loss = 2.0107284, step = 36200 (43.499 sec)\n","INFO:tensorflow:global_step/sec: 2.31278\n","I0120 00:44:46.655555 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31278\n","INFO:tensorflow:loss = 1.8948895, step = 36300 (43.238 sec)\n","I0120 00:44:46.656816 140441056839552 basic_session_run_hooks.py:260] loss = 1.8948895, step = 36300 (43.238 sec)\n","INFO:tensorflow:global_step/sec: 2.29583\n","I0120 00:45:30.212856 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29583\n","INFO:tensorflow:loss = 3.5369577, step = 36400 (43.557 sec)\n","I0120 00:45:30.214000 140441056839552 basic_session_run_hooks.py:260] loss = 3.5369577, step = 36400 (43.557 sec)\n","INFO:tensorflow:global_step/sec: 2.29691\n","I0120 00:46:13.749588 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29691\n","INFO:tensorflow:loss = 2.262222, step = 36500 (43.537 sec)\n","I0120 00:46:13.751367 140441056839552 basic_session_run_hooks.py:260] loss = 2.262222, step = 36500 (43.537 sec)\n","INFO:tensorflow:global_step/sec: 2.27762\n","I0120 00:46:57.655048 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.27762\n","INFO:tensorflow:loss = 1.6683083, step = 36600 (43.905 sec)\n","I0120 00:46:57.656435 140441056839552 basic_session_run_hooks.py:260] loss = 1.6683083, step = 36600 (43.905 sec)\n","INFO:tensorflow:global_step/sec: 2.29757\n","I0120 00:47:41.179279 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29757\n","INFO:tensorflow:loss = 1.6300305, step = 36700 (43.524 sec)\n","I0120 00:47:41.180476 140441056839552 basic_session_run_hooks.py:260] loss = 1.6300305, step = 36700 (43.524 sec)\n","INFO:tensorflow:Saving checkpoints for 36714 into training/log/model.ckpt.\n","I0120 00:47:46.849223 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 36714 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 00:47:49.603281 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:47:51.707946 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:47:51.789225 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:47:51.878013 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:47:51.958240 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:47:52.033439 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:47:52.108718 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 00:47:53.500622 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T00:47:53Z\n","I0120 00:47:53.515626 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T00:47:53Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 00:47:54.011585 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 00:47:54.012293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:47:54.012587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 00:47:54.012682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 00:47:54.012707: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 00:47:54.012728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 00:47:54.012751: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 00:47:54.012772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 00:47:54.012793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 00:47:54.012814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 00:47:54.012922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:47:54.013306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:47:54.013532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 00:47:54.013586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 00:47:54.013600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 00:47:54.013609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 00:47:54.013735: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:47:54.014032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:47:54.014280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-36714\n","I0120 00:47:54.016271 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-36714\n","INFO:tensorflow:Running local_init_op.\n","I0120 00:47:55.078683 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 00:47:55.214311 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 00:47:58.984788 140437385447168 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 00:47:58.985372 140437385447168 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 00:47:58.990271 140437385447168 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.54s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.295\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.776\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.180\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.356\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.240\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.368\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.387\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.276\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.442\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n","INFO:tensorflow:Finished evaluation at 2020-01-20-00:47:59\n","I0120 00:47:59.675812 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-00:47:59\n","INFO:tensorflow:Saving dict for global step 36714: DetectionBoxes_Precision/mAP = 0.29500663, DetectionBoxes_Precision/mAP (large) = 0.35049504, DetectionBoxes_Precision/mAP (medium) = 0.3557452, DetectionBoxes_Precision/mAP (small) = 0.1713932, DetectionBoxes_Precision/mAP@.50IOU = 0.77613324, DetectionBoxes_Precision/mAP@.75IOU = 0.17963491, DetectionBoxes_Recall/AR@1 = 0.24, DetectionBoxes_Recall/AR@10 = 0.36761904, DetectionBoxes_Recall/AR@100 = 0.38666666, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = 0.442029, DetectionBoxes_Recall/AR@100 (small) = 0.2764706, Loss/classification_loss = 7.688986, Loss/localization_loss = 1.5974226, Loss/regularization_loss = 0.31369212, Loss/total_loss = 9.600101, global_step = 36714, learning_rate = 0.004, loss = 9.600101\n","I0120 00:47:59.676115 140441056839552 estimator.py:2049] Saving dict for global step 36714: DetectionBoxes_Precision/mAP = 0.29500663, DetectionBoxes_Precision/mAP (large) = 0.35049504, DetectionBoxes_Precision/mAP (medium) = 0.3557452, DetectionBoxes_Precision/mAP (small) = 0.1713932, DetectionBoxes_Precision/mAP@.50IOU = 0.77613324, DetectionBoxes_Precision/mAP@.75IOU = 0.17963491, DetectionBoxes_Recall/AR@1 = 0.24, DetectionBoxes_Recall/AR@10 = 0.36761904, DetectionBoxes_Recall/AR@100 = 0.38666666, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = 0.442029, DetectionBoxes_Recall/AR@100 (small) = 0.2764706, Loss/classification_loss = 7.688986, Loss/localization_loss = 1.5974226, Loss/regularization_loss = 0.31369212, Loss/total_loss = 9.600101, global_step = 36714, learning_rate = 0.004, loss = 9.600101\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 36714: training/log/model.ckpt-36714\n","I0120 00:47:59.679022 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 36714: training/log/model.ckpt-36714\n","INFO:tensorflow:global_step/sec: 1.77176\n","I0120 00:48:37.620362 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.77176\n","INFO:tensorflow:loss = 1.6345971, step = 36800 (56.442 sec)\n","I0120 00:48:37.622186 140441056839552 basic_session_run_hooks.py:260] loss = 1.6345971, step = 36800 (56.442 sec)\n","INFO:tensorflow:global_step/sec: 2.28528\n","I0120 00:49:21.378604 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28528\n","INFO:tensorflow:loss = 1.9834085, step = 36900 (43.758 sec)\n","I0120 00:49:21.379689 140441056839552 basic_session_run_hooks.py:260] loss = 1.9834085, step = 36900 (43.758 sec)\n","INFO:tensorflow:global_step/sec: 2.29026\n","I0120 00:50:05.041728 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29026\n","INFO:tensorflow:loss = 1.6602403, step = 37000 (43.663 sec)\n","I0120 00:50:05.042745 140441056839552 basic_session_run_hooks.py:260] loss = 1.6602403, step = 37000 (43.663 sec)\n","INFO:tensorflow:global_step/sec: 2.32344\n","I0120 00:50:48.081317 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32344\n","INFO:tensorflow:loss = 2.1393998, step = 37100 (43.040 sec)\n","I0120 00:50:48.082560 140441056839552 basic_session_run_hooks.py:260] loss = 2.1393998, step = 37100 (43.040 sec)\n","INFO:tensorflow:global_step/sec: 2.28051\n","I0120 00:51:31.931172 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28051\n","INFO:tensorflow:loss = 1.1855555, step = 37200 (43.850 sec)\n","I0120 00:51:31.932172 140441056839552 basic_session_run_hooks.py:260] loss = 1.1855555, step = 37200 (43.850 sec)\n","INFO:tensorflow:global_step/sec: 2.30585\n","I0120 00:52:15.299170 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30585\n","INFO:tensorflow:loss = 2.3765287, step = 37300 (43.368 sec)\n","I0120 00:52:15.300463 140441056839552 basic_session_run_hooks.py:260] loss = 2.3765287, step = 37300 (43.368 sec)\n","INFO:tensorflow:global_step/sec: 2.29443\n","I0120 00:52:58.882988 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29443\n","INFO:tensorflow:loss = 1.7012168, step = 37400 (43.584 sec)\n","I0120 00:52:58.884592 140441056839552 basic_session_run_hooks.py:260] loss = 1.7012168, step = 37400 (43.584 sec)\n","INFO:tensorflow:global_step/sec: 2.2986\n","I0120 00:53:42.387659 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2986\n","INFO:tensorflow:loss = 2.200927, step = 37500 (43.504 sec)\n","I0120 00:53:42.388670 140441056839552 basic_session_run_hooks.py:260] loss = 2.200927, step = 37500 (43.504 sec)\n","INFO:tensorflow:global_step/sec: 2.30324\n","I0120 00:54:25.804728 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30324\n","INFO:tensorflow:loss = 1.7092311, step = 37600 (43.417 sec)\n","I0120 00:54:25.805685 140441056839552 basic_session_run_hooks.py:260] loss = 1.7092311, step = 37600 (43.417 sec)\n","INFO:tensorflow:global_step/sec: 2.29452\n","I0120 00:55:09.386884 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29452\n","INFO:tensorflow:loss = 2.091197, step = 37700 (43.583 sec)\n","I0120 00:55:09.388376 140441056839552 basic_session_run_hooks.py:260] loss = 2.091197, step = 37700 (43.583 sec)\n","INFO:tensorflow:global_step/sec: 2.29292\n","I0120 00:55:52.999435 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29292\n","INFO:tensorflow:loss = 3.1716805, step = 37800 (43.612 sec)\n","I0120 00:55:53.000555 140441056839552 basic_session_run_hooks.py:260] loss = 3.1716805, step = 37800 (43.612 sec)\n","INFO:tensorflow:global_step/sec: 2.29149\n","I0120 00:56:36.639226 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29149\n","INFO:tensorflow:loss = 1.6253333, step = 37900 (43.640 sec)\n","I0120 00:56:36.640210 140441056839552 basic_session_run_hooks.py:260] loss = 1.6253333, step = 37900 (43.640 sec)\n","INFO:tensorflow:global_step/sec: 2.30375\n","I0120 00:57:20.046766 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30375\n","INFO:tensorflow:loss = 2.4368212, step = 38000 (43.408 sec)\n","I0120 00:57:20.048317 140441056839552 basic_session_run_hooks.py:260] loss = 2.4368212, step = 38000 (43.408 sec)\n","INFO:tensorflow:Saving checkpoints for 38063 into training/log/model.ckpt.\n","I0120 00:57:47.186017 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 38063 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 00:57:49.586853 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:57:51.722642 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:57:51.798584 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:57:51.882972 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:57:51.960825 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:57:52.039415 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 00:57:52.115297 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 00:57:53.849027 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T00:57:53Z\n","I0120 00:57:53.864576 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T00:57:53Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 00:57:54.337849 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 00:57:54.338743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:57:54.339111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 00:57:54.339238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 00:57:54.339265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 00:57:54.339288: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 00:57:54.339309: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 00:57:54.339331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 00:57:54.339353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 00:57:54.339377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 00:57:54.339510: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:57:54.339890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:57:54.340160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 00:57:54.340440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 00:57:54.340460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 00:57:54.340470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 00:57:54.340671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:57:54.341007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 00:57:54.341257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-38063\n","I0120 00:57:54.343633 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-38063\n","INFO:tensorflow:Running local_init_op.\n","I0120 00:57:55.422288 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 00:57:55.557386 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 00:57:59.375513 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 00:57:59.375999 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 00:57:59.380179 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.53s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.279\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.738\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.169\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.122\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.365\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.242\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.359\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.385\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.238\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n","INFO:tensorflow:Finished evaluation at 2020-01-20-00:58:00\n","I0120 00:58:00.052277 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-00:58:00\n","INFO:tensorflow:Saving dict for global step 38063: DetectionBoxes_Precision/mAP = 0.278683, DetectionBoxes_Precision/mAP (large) = 0.35049504, DetectionBoxes_Precision/mAP (medium) = 0.3651653, DetectionBoxes_Precision/mAP (small) = 0.122354716, DetectionBoxes_Precision/mAP@.50IOU = 0.73756665, DetectionBoxes_Precision/mAP@.75IOU = 0.16932474, DetectionBoxes_Recall/AR@1 = 0.24190477, DetectionBoxes_Recall/AR@10 = 0.35904762, DetectionBoxes_Recall/AR@100 = 0.3847619, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = 0.457971, DetectionBoxes_Recall/AR@100 (small) = 0.2382353, Loss/classification_loss = 7.454205, Loss/localization_loss = 1.5468925, Loss/regularization_loss = 0.31429043, Loss/total_loss = 9.315389, global_step = 38063, learning_rate = 0.004, loss = 9.315389\n","I0120 00:58:00.052514 140441056839552 estimator.py:2049] Saving dict for global step 38063: DetectionBoxes_Precision/mAP = 0.278683, DetectionBoxes_Precision/mAP (large) = 0.35049504, DetectionBoxes_Precision/mAP (medium) = 0.3651653, DetectionBoxes_Precision/mAP (small) = 0.122354716, DetectionBoxes_Precision/mAP@.50IOU = 0.73756665, DetectionBoxes_Precision/mAP@.75IOU = 0.16932474, DetectionBoxes_Recall/AR@1 = 0.24190477, DetectionBoxes_Recall/AR@10 = 0.35904762, DetectionBoxes_Recall/AR@100 = 0.3847619, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = 0.457971, DetectionBoxes_Recall/AR@100 (small) = 0.2382353, Loss/classification_loss = 7.454205, Loss/localization_loss = 1.5468925, Loss/regularization_loss = 0.31429043, Loss/total_loss = 9.315389, global_step = 38063, learning_rate = 0.004, loss = 9.315389\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 38063: training/log/model.ckpt-38063\n","I0120 00:58:00.054973 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 38063: training/log/model.ckpt-38063\n","INFO:tensorflow:global_step/sec: 1.75951\n","I0120 00:58:16.880475 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.75951\n","INFO:tensorflow:loss = 2.450147, step = 38100 (56.833 sec)\n","I0120 00:58:16.881631 140441056839552 basic_session_run_hooks.py:260] loss = 2.450147, step = 38100 (56.833 sec)\n","INFO:tensorflow:global_step/sec: 2.28262\n","I0120 00:59:00.689750 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28262\n","INFO:tensorflow:loss = 1.8225255, step = 38200 (43.809 sec)\n","I0120 00:59:00.690802 140441056839552 basic_session_run_hooks.py:260] loss = 1.8225255, step = 38200 (43.809 sec)\n","INFO:tensorflow:global_step/sec: 2.31031\n","I0120 00:59:43.973931 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31031\n","INFO:tensorflow:loss = 1.499737, step = 38300 (43.285 sec)\n","I0120 00:59:43.975376 140441056839552 basic_session_run_hooks.py:260] loss = 1.499737, step = 38300 (43.285 sec)\n","INFO:tensorflow:global_step/sec: 2.3038\n","I0120 01:00:27.380481 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3038\n","INFO:tensorflow:loss = 3.1127586, step = 38400 (43.406 sec)\n","I0120 01:00:27.381611 140441056839552 basic_session_run_hooks.py:260] loss = 3.1127586, step = 38400 (43.406 sec)\n","INFO:tensorflow:global_step/sec: 2.29126\n","I0120 01:01:11.024687 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29126\n","INFO:tensorflow:loss = 2.2974174, step = 38500 (43.644 sec)\n","I0120 01:01:11.025715 140441056839552 basic_session_run_hooks.py:260] loss = 2.2974174, step = 38500 (43.644 sec)\n","INFO:tensorflow:global_step/sec: 2.29859\n","I0120 01:01:54.529672 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29859\n","INFO:tensorflow:loss = 2.8244708, step = 38600 (43.505 sec)\n","I0120 01:01:54.531158 140441056839552 basic_session_run_hooks.py:260] loss = 2.8244708, step = 38600 (43.505 sec)\n","INFO:tensorflow:global_step/sec: 2.31123\n","I0120 01:02:37.796689 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31123\n","INFO:tensorflow:loss = 1.8050034, step = 38700 (43.267 sec)\n","I0120 01:02:37.797861 140441056839552 basic_session_run_hooks.py:260] loss = 1.8050034, step = 38700 (43.267 sec)\n","INFO:tensorflow:global_step/sec: 2.28233\n","I0120 01:03:21.611526 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28233\n","INFO:tensorflow:loss = 1.5140334, step = 38800 (43.815 sec)\n","I0120 01:03:21.612569 140441056839552 basic_session_run_hooks.py:260] loss = 1.5140334, step = 38800 (43.815 sec)\n","INFO:tensorflow:global_step/sec: 2.30695\n","I0120 01:04:04.958820 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30695\n","INFO:tensorflow:loss = 1.8106092, step = 38900 (43.348 sec)\n","I0120 01:04:04.960479 140441056839552 basic_session_run_hooks.py:260] loss = 1.8106092, step = 38900 (43.348 sec)\n","INFO:tensorflow:global_step/sec: 2.28894\n","I0120 01:04:48.647175 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28894\n","INFO:tensorflow:loss = 1.6271566, step = 39000 (43.688 sec)\n","I0120 01:04:48.648166 140441056839552 basic_session_run_hooks.py:260] loss = 1.6271566, step = 39000 (43.688 sec)\n","INFO:tensorflow:global_step/sec: 2.31135\n","I0120 01:05:31.911948 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31135\n","INFO:tensorflow:loss = 2.6578684, step = 39100 (43.265 sec)\n","I0120 01:05:31.913165 140441056839552 basic_session_run_hooks.py:260] loss = 2.6578684, step = 39100 (43.265 sec)\n","INFO:tensorflow:global_step/sec: 2.29011\n","I0120 01:06:15.578087 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29011\n","INFO:tensorflow:loss = 2.4049256, step = 39200 (43.667 sec)\n","I0120 01:06:15.579783 140441056839552 basic_session_run_hooks.py:260] loss = 2.4049256, step = 39200 (43.667 sec)\n","INFO:tensorflow:global_step/sec: 2.3006\n","I0120 01:06:59.044971 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3006\n","INFO:tensorflow:loss = 1.6381288, step = 39300 (43.466 sec)\n","I0120 01:06:59.046036 140441056839552 basic_session_run_hooks.py:260] loss = 1.6381288, step = 39300 (43.466 sec)\n","INFO:tensorflow:global_step/sec: 2.3153\n","I0120 01:07:42.235864 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3153\n","INFO:tensorflow:loss = 1.9125731, step = 39400 (43.191 sec)\n","I0120 01:07:42.237022 140441056839552 basic_session_run_hooks.py:260] loss = 1.9125731, step = 39400 (43.191 sec)\n","INFO:tensorflow:Saving checkpoints for 39413 into training/log/model.ckpt.\n","I0120 01:07:47.468585 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 39413 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 01:07:49.845424 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:07:51.945347 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:07:52.032699 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:07:52.120599 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:07:52.199176 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:07:52.273327 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:07:52.347446 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 01:07:53.813588 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T01:07:53Z\n","I0120 01:07:53.829411 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T01:07:53Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 01:07:54.318475 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 01:07:54.319203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:07:54.319511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 01:07:54.319614: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 01:07:54.319643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 01:07:54.319661: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 01:07:54.319682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 01:07:54.319721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 01:07:54.319741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 01:07:54.319763: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 01:07:54.319872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:07:54.320228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:07:54.320479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 01:07:54.320573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 01:07:54.320588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 01:07:54.320597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 01:07:54.320722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:07:54.321049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:07:54.321316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-39413\n","I0120 01:07:54.324084 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-39413\n","INFO:tensorflow:Running local_init_op.\n","I0120 01:07:55.377671 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 01:07:55.510273 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 01:07:59.371036 140437385447168 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 01:07:59.371625 140437385447168 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 01:07:59.376297 140437385447168 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.53s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.293\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.693\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.174\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.357\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.336\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.250\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.381\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.411\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.294\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.470\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n","INFO:tensorflow:Finished evaluation at 2020-01-20-01:08:00\n","I0120 01:08:00.046267 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-01:08:00\n","INFO:tensorflow:Saving dict for global step 39413: DetectionBoxes_Precision/mAP = 0.29336423, DetectionBoxes_Precision/mAP (large) = 0.33627364, DetectionBoxes_Precision/mAP (medium) = 0.3570887, DetectionBoxes_Precision/mAP (small) = 0.17360565, DetectionBoxes_Precision/mAP@.50IOU = 0.6931258, DetectionBoxes_Precision/mAP@.75IOU = 0.22913598, DetectionBoxes_Recall/AR@1 = 0.25047618, DetectionBoxes_Recall/AR@10 = 0.3809524, DetectionBoxes_Recall/AR@100 = 0.41142857, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = 0.4695652, DetectionBoxes_Recall/AR@100 (small) = 0.29411766, Loss/classification_loss = 7.413974, Loss/localization_loss = 1.6648784, Loss/regularization_loss = 0.3148415, Loss/total_loss = 9.393695, global_step = 39413, learning_rate = 0.004, loss = 9.393695\n","I0120 01:08:00.046554 140441056839552 estimator.py:2049] Saving dict for global step 39413: DetectionBoxes_Precision/mAP = 0.29336423, DetectionBoxes_Precision/mAP (large) = 0.33627364, DetectionBoxes_Precision/mAP (medium) = 0.3570887, DetectionBoxes_Precision/mAP (small) = 0.17360565, DetectionBoxes_Precision/mAP@.50IOU = 0.6931258, DetectionBoxes_Precision/mAP@.75IOU = 0.22913598, DetectionBoxes_Recall/AR@1 = 0.25047618, DetectionBoxes_Recall/AR@10 = 0.3809524, DetectionBoxes_Recall/AR@100 = 0.41142857, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = 0.4695652, DetectionBoxes_Recall/AR@100 (small) = 0.29411766, Loss/classification_loss = 7.413974, Loss/localization_loss = 1.6648784, Loss/regularization_loss = 0.3148415, Loss/total_loss = 9.393695, global_step = 39413, learning_rate = 0.004, loss = 9.393695\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 39413: training/log/model.ckpt-39413\n","I0120 01:08:00.049259 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 39413: training/log/model.ckpt-39413\n","INFO:tensorflow:global_step/sec: 1.76859\n","I0120 01:08:38.778091 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.76859\n","INFO:tensorflow:loss = 1.6024554, step = 39500 (56.542 sec)\n","I0120 01:08:38.779451 140441056839552 basic_session_run_hooks.py:260] loss = 1.6024554, step = 39500 (56.542 sec)\n","INFO:tensorflow:global_step/sec: 2.3032\n","I0120 01:09:22.195866 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3032\n","INFO:tensorflow:loss = 1.7025689, step = 39600 (43.418 sec)\n","I0120 01:09:22.196996 140441056839552 basic_session_run_hooks.py:260] loss = 1.7025689, step = 39600 (43.418 sec)\n","INFO:tensorflow:global_step/sec: 2.29336\n","I0120 01:10:05.799904 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29336\n","INFO:tensorflow:loss = 2.5485756, step = 39700 (43.604 sec)\n","I0120 01:10:05.800820 140441056839552 basic_session_run_hooks.py:260] loss = 2.5485756, step = 39700 (43.604 sec)\n","INFO:tensorflow:global_step/sec: 2.30239\n","I0120 01:10:49.233034 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30239\n","INFO:tensorflow:loss = 1.5233963, step = 39800 (43.434 sec)\n","I0120 01:10:49.234448 140441056839552 basic_session_run_hooks.py:260] loss = 1.5233963, step = 39800 (43.434 sec)\n","INFO:tensorflow:global_step/sec: 2.29576\n","I0120 01:11:32.791641 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29576\n","INFO:tensorflow:loss = 1.7219474, step = 39900 (43.558 sec)\n","I0120 01:11:32.792779 140441056839552 basic_session_run_hooks.py:260] loss = 1.7219474, step = 39900 (43.558 sec)\n","INFO:tensorflow:global_step/sec: 2.28933\n","I0120 01:12:16.472611 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28933\n","INFO:tensorflow:loss = 1.7694784, step = 40000 (43.681 sec)\n","I0120 01:12:16.473988 140441056839552 basic_session_run_hooks.py:260] loss = 1.7694784, step = 40000 (43.681 sec)\n","INFO:tensorflow:global_step/sec: 2.30892\n","I0120 01:12:59.782809 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30892\n","INFO:tensorflow:loss = 1.8648701, step = 40100 (43.311 sec)\n","I0120 01:12:59.784524 140441056839552 basic_session_run_hooks.py:260] loss = 1.8648701, step = 40100 (43.311 sec)\n","INFO:tensorflow:global_step/sec: 2.2919\n","I0120 01:13:43.414631 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2919\n","INFO:tensorflow:loss = 1.2889124, step = 40200 (43.631 sec)\n","I0120 01:13:43.415615 140441056839552 basic_session_run_hooks.py:260] loss = 1.2889124, step = 40200 (43.631 sec)\n","INFO:tensorflow:global_step/sec: 2.29762\n","I0120 01:14:26.937883 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29762\n","INFO:tensorflow:loss = 1.5574183, step = 40300 (43.523 sec)\n","I0120 01:14:26.938962 140441056839552 basic_session_run_hooks.py:260] loss = 1.5574183, step = 40300 (43.523 sec)\n","INFO:tensorflow:global_step/sec: 2.30664\n","I0120 01:15:10.290995 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30664\n","INFO:tensorflow:loss = 1.1992469, step = 40400 (43.353 sec)\n","I0120 01:15:10.292449 140441056839552 basic_session_run_hooks.py:260] loss = 1.1992469, step = 40400 (43.353 sec)\n","INFO:tensorflow:global_step/sec: 2.30777\n","I0120 01:15:53.622910 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30777\n","INFO:tensorflow:loss = 1.8826298, step = 40500 (43.332 sec)\n","I0120 01:15:53.623991 140441056839552 basic_session_run_hooks.py:260] loss = 1.8826298, step = 40500 (43.332 sec)\n","INFO:tensorflow:global_step/sec: 2.30964\n","I0120 01:16:36.919745 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30964\n","INFO:tensorflow:loss = 1.6839383, step = 40600 (43.297 sec)\n","I0120 01:16:36.920814 140441056839552 basic_session_run_hooks.py:260] loss = 1.6839383, step = 40600 (43.297 sec)\n","INFO:tensorflow:global_step/sec: 2.29616\n","I0120 01:17:20.470744 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29616\n","INFO:tensorflow:loss = 1.9788656, step = 40700 (43.551 sec)\n","I0120 01:17:20.472208 140441056839552 basic_session_run_hooks.py:260] loss = 1.9788656, step = 40700 (43.551 sec)\n","INFO:tensorflow:Saving checkpoints for 40764 into training/log/model.ckpt.\n","I0120 01:17:47.778150 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 40764 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 01:17:50.113205 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:17:52.209079 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:17:52.296840 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:17:52.382043 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:17:52.460967 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:17:52.964160 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:17:53.039353 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 01:17:54.468796 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T01:17:54Z\n","I0120 01:17:54.484298 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T01:17:54Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 01:17:54.966614 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 01:17:54.967324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:17:54.967614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 01:17:54.967698: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 01:17:54.967713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 01:17:54.967726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 01:17:54.967740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 01:17:54.967752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 01:17:54.967765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 01:17:54.967779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 01:17:54.967872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:17:54.968196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:17:54.968414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 01:17:54.968449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 01:17:54.968458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 01:17:54.968467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 01:17:54.968576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:17:54.968845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:17:54.969075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-40764\n","I0120 01:17:54.971287 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-40764\n","INFO:tensorflow:Running local_init_op.\n","I0120 01:17:56.055102 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 01:17:56.198042 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 01:18:00.040377 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 01:18:00.040863 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 01:18:00.045938 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.50s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.774\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.168\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.154\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.384\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.253\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.386\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.244\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n","INFO:tensorflow:Finished evaluation at 2020-01-20-01:18:00\n","I0120 01:18:00.692312 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-01:18:00\n","INFO:tensorflow:Saving dict for global step 40764: DetectionBoxes_Precision/mAP = 0.30090293, DetectionBoxes_Precision/mAP (large) = 0.40005067, DetectionBoxes_Precision/mAP (medium) = 0.38353086, DetectionBoxes_Precision/mAP (small) = 0.15380703, DetectionBoxes_Precision/mAP@.50IOU = 0.7737942, DetectionBoxes_Precision/mAP@.75IOU = 0.16768868, DetectionBoxes_Recall/AR@1 = 0.25333333, DetectionBoxes_Recall/AR@10 = 0.3857143, DetectionBoxes_Recall/AR@100 = 0.40571427, DetectionBoxes_Recall/AR@100 (large) = 0.5, DetectionBoxes_Recall/AR@100 (medium) = 0.4826087, DetectionBoxes_Recall/AR@100 (small) = 0.24411765, Loss/classification_loss = 7.099638, Loss/localization_loss = 1.5264848, Loss/regularization_loss = 0.31537253, Loss/total_loss = 8.941496, global_step = 40764, learning_rate = 0.004, loss = 8.941496\n","I0120 01:18:00.692578 140441056839552 estimator.py:2049] Saving dict for global step 40764: DetectionBoxes_Precision/mAP = 0.30090293, DetectionBoxes_Precision/mAP (large) = 0.40005067, DetectionBoxes_Precision/mAP (medium) = 0.38353086, DetectionBoxes_Precision/mAP (small) = 0.15380703, DetectionBoxes_Precision/mAP@.50IOU = 0.7737942, DetectionBoxes_Precision/mAP@.75IOU = 0.16768868, DetectionBoxes_Recall/AR@1 = 0.25333333, DetectionBoxes_Recall/AR@10 = 0.3857143, DetectionBoxes_Recall/AR@100 = 0.40571427, DetectionBoxes_Recall/AR@100 (large) = 0.5, DetectionBoxes_Recall/AR@100 (medium) = 0.4826087, DetectionBoxes_Recall/AR@100 (small) = 0.24411765, Loss/classification_loss = 7.099638, Loss/localization_loss = 1.5264848, Loss/regularization_loss = 0.31537253, Loss/total_loss = 8.941496, global_step = 40764, learning_rate = 0.004, loss = 8.941496\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 40764: training/log/model.ckpt-40764\n","I0120 01:18:00.695126 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 40764: training/log/model.ckpt-40764\n","INFO:tensorflow:global_step/sec: 1.76431\n","I0120 01:18:17.150094 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.76431\n","INFO:tensorflow:loss = 2.09415, step = 40800 (56.679 sec)\n","I0120 01:18:17.151138 140441056839552 basic_session_run_hooks.py:260] loss = 2.09415, step = 40800 (56.679 sec)\n","INFO:tensorflow:global_step/sec: 2.30051\n","I0120 01:19:00.618765 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30051\n","INFO:tensorflow:loss = 2.1281176, step = 40900 (43.469 sec)\n","I0120 01:19:00.619847 140441056839552 basic_session_run_hooks.py:260] loss = 2.1281176, step = 40900 (43.469 sec)\n","INFO:tensorflow:global_step/sec: 2.30462\n","I0120 01:19:44.009805 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30462\n","INFO:tensorflow:loss = 1.456233, step = 41000 (43.391 sec)\n","I0120 01:19:44.011346 140441056839552 basic_session_run_hooks.py:260] loss = 1.456233, step = 41000 (43.391 sec)\n","INFO:tensorflow:global_step/sec: 2.30247\n","I0120 01:20:27.441455 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30247\n","INFO:tensorflow:loss = 2.6531432, step = 41100 (43.431 sec)\n","I0120 01:20:27.442581 140441056839552 basic_session_run_hooks.py:260] loss = 2.6531432, step = 41100 (43.431 sec)\n","INFO:tensorflow:global_step/sec: 2.30274\n","I0120 01:21:10.868081 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30274\n","INFO:tensorflow:loss = 1.8923062, step = 41200 (43.427 sec)\n","I0120 01:21:10.869309 140441056839552 basic_session_run_hooks.py:260] loss = 1.8923062, step = 41200 (43.427 sec)\n","INFO:tensorflow:global_step/sec: 2.28495\n","I0120 01:21:54.632655 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28495\n","INFO:tensorflow:loss = 1.7982895, step = 41300 (43.765 sec)\n","I0120 01:21:54.634231 140441056839552 basic_session_run_hooks.py:260] loss = 1.7982895, step = 41300 (43.765 sec)\n","INFO:tensorflow:global_step/sec: 2.30947\n","I0120 01:22:37.932644 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30947\n","INFO:tensorflow:loss = 1.805863, step = 41400 (43.300 sec)\n","I0120 01:22:37.933936 140441056839552 basic_session_run_hooks.py:260] loss = 1.805863, step = 41400 (43.300 sec)\n","INFO:tensorflow:global_step/sec: 2.30051\n","I0120 01:23:21.401327 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30051\n","INFO:tensorflow:loss = 1.7360606, step = 41500 (43.468 sec)\n","I0120 01:23:21.402361 140441056839552 basic_session_run_hooks.py:260] loss = 1.7360606, step = 41500 (43.468 sec)\n","INFO:tensorflow:global_step/sec: 2.29981\n","I0120 01:24:04.883139 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29981\n","INFO:tensorflow:loss = 1.8168979, step = 41600 (43.482 sec)\n","I0120 01:24:04.884525 140441056839552 basic_session_run_hooks.py:260] loss = 1.8168979, step = 41600 (43.482 sec)\n","INFO:tensorflow:global_step/sec: 2.3191\n","I0120 01:24:48.003326 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3191\n","INFO:tensorflow:loss = 1.8377368, step = 41700 (43.120 sec)\n","I0120 01:24:48.004318 140441056839552 basic_session_run_hooks.py:260] loss = 1.8377368, step = 41700 (43.120 sec)\n","INFO:tensorflow:global_step/sec: 2.31195\n","I0120 01:25:31.256820 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31195\n","INFO:tensorflow:loss = 1.9737947, step = 41800 (43.254 sec)\n","I0120 01:25:31.258016 140441056839552 basic_session_run_hooks.py:260] loss = 1.9737947, step = 41800 (43.254 sec)\n","INFO:tensorflow:global_step/sec: 2.29481\n","I0120 01:26:14.833314 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29481\n","INFO:tensorflow:loss = 1.8012283, step = 41900 (43.577 sec)\n","I0120 01:26:14.834947 140441056839552 basic_session_run_hooks.py:260] loss = 1.8012283, step = 41900 (43.577 sec)\n","INFO:tensorflow:global_step/sec: 2.32386\n","I0120 01:26:57.865221 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32386\n","INFO:tensorflow:loss = 2.741825, step = 42000 (43.031 sec)\n","I0120 01:26:57.866190 140441056839552 basic_session_run_hooks.py:260] loss = 2.741825, step = 42000 (43.031 sec)\n","INFO:tensorflow:global_step/sec: 2.29968\n","I0120 01:27:41.349565 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29968\n","INFO:tensorflow:loss = 1.6855252, step = 42100 (43.484 sec)\n","I0120 01:27:41.350579 140441056839552 basic_session_run_hooks.py:260] loss = 1.6855252, step = 42100 (43.484 sec)\n","INFO:tensorflow:Saving checkpoints for 42116 into training/log/model.ckpt.\n","I0120 01:27:47.814255 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 42116 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 01:27:50.225347 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:27:52.285439 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:27:52.360525 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:27:52.441788 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:27:52.515868 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:27:52.597922 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:27:52.673105 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 01:27:54.091585 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T01:27:54Z\n","I0120 01:27:54.106750 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T01:27:54Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 01:27:54.584457 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 01:27:54.585312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:27:54.585644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 01:27:54.585739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 01:27:54.585769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 01:27:54.585794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 01:27:54.585820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 01:27:54.585843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 01:27:54.585863: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 01:27:54.585885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 01:27:54.585994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:27:54.586345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:27:54.586573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 01:27:54.586817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 01:27:54.586834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 01:27:54.586843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 01:27:54.587020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:27:54.587401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:27:54.587661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-42116\n","I0120 01:27:54.589729 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-42116\n","INFO:tensorflow:Running local_init_op.\n","I0120 01:27:55.641730 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 01:27:55.774067 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 01:27:59.459920 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 01:27:59.460558 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 01:27:59.465179 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.54s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.807\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.245\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.140\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.424\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.267\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.410\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.428\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.274\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.503\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n","INFO:tensorflow:Finished evaluation at 2020-01-20-01:28:00\n","I0120 01:28:00.158688 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-01:28:00\n","INFO:tensorflow:Saving dict for global step 42116: DetectionBoxes_Precision/mAP = 0.3283388, DetectionBoxes_Precision/mAP (large) = 0.40102515, DetectionBoxes_Precision/mAP (medium) = 0.424341, DetectionBoxes_Precision/mAP (small) = 0.14011398, DetectionBoxes_Precision/mAP@.50IOU = 0.80708474, DetectionBoxes_Precision/mAP@.75IOU = 0.24463153, DetectionBoxes_Recall/AR@1 = 0.26666668, DetectionBoxes_Recall/AR@10 = 0.41047618, DetectionBoxes_Recall/AR@100 = 0.42761904, DetectionBoxes_Recall/AR@100 (large) = 0.45, DetectionBoxes_Recall/AR@100 (medium) = 0.5028986, DetectionBoxes_Recall/AR@100 (small) = 0.2735294, Loss/classification_loss = 7.687085, Loss/localization_loss = 1.4429089, Loss/regularization_loss = 0.31591105, Loss/total_loss = 9.445907, global_step = 42116, learning_rate = 0.004, loss = 9.445907\n","I0120 01:28:00.158977 140441056839552 estimator.py:2049] Saving dict for global step 42116: DetectionBoxes_Precision/mAP = 0.3283388, DetectionBoxes_Precision/mAP (large) = 0.40102515, DetectionBoxes_Precision/mAP (medium) = 0.424341, DetectionBoxes_Precision/mAP (small) = 0.14011398, DetectionBoxes_Precision/mAP@.50IOU = 0.80708474, DetectionBoxes_Precision/mAP@.75IOU = 0.24463153, DetectionBoxes_Recall/AR@1 = 0.26666668, DetectionBoxes_Recall/AR@10 = 0.41047618, DetectionBoxes_Recall/AR@100 = 0.42761904, DetectionBoxes_Recall/AR@100 (large) = 0.45, DetectionBoxes_Recall/AR@100 (medium) = 0.5028986, DetectionBoxes_Recall/AR@100 (small) = 0.2735294, Loss/classification_loss = 7.687085, Loss/localization_loss = 1.4429089, Loss/regularization_loss = 0.31591105, Loss/total_loss = 9.445907, global_step = 42116, learning_rate = 0.004, loss = 9.445907\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 42116: training/log/model.ckpt-42116\n","I0120 01:28:00.162109 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 42116: training/log/model.ckpt-42116\n","INFO:tensorflow:global_step/sec: 1.78969\n","I0120 01:28:37.225015 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.78969\n","INFO:tensorflow:loss = 1.5669856, step = 42200 (55.876 sec)\n","I0120 01:28:37.226451 140441056839552 basic_session_run_hooks.py:260] loss = 1.5669856, step = 42200 (55.876 sec)\n","INFO:tensorflow:global_step/sec: 2.2959\n","I0120 01:29:20.780973 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2959\n","INFO:tensorflow:loss = 1.9181832, step = 42300 (43.556 sec)\n","I0120 01:29:20.782109 140441056839552 basic_session_run_hooks.py:260] loss = 1.9181832, step = 42300 (43.556 sec)\n","INFO:tensorflow:global_step/sec: 2.30406\n","I0120 01:30:04.182662 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30406\n","INFO:tensorflow:loss = 2.8581357, step = 42400 (43.402 sec)\n","I0120 01:30:04.183934 140441056839552 basic_session_run_hooks.py:260] loss = 2.8581357, step = 42400 (43.402 sec)\n","INFO:tensorflow:global_step/sec: 2.30954\n","I0120 01:30:47.481329 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30954\n","INFO:tensorflow:loss = 2.2548513, step = 42500 (43.299 sec)\n","I0120 01:30:47.482752 140441056839552 basic_session_run_hooks.py:260] loss = 2.2548513, step = 42500 (43.299 sec)\n","INFO:tensorflow:global_step/sec: 2.31993\n","I0120 01:31:30.586003 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31993\n","INFO:tensorflow:loss = 1.5376098, step = 42600 (43.104 sec)\n","I0120 01:31:30.587033 140441056839552 basic_session_run_hooks.py:260] loss = 1.5376098, step = 42600 (43.104 sec)\n","INFO:tensorflow:global_step/sec: 2.30406\n","I0120 01:32:13.987608 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30406\n","INFO:tensorflow:loss = 1.8747704, step = 42700 (43.402 sec)\n","I0120 01:32:13.988651 140441056839552 basic_session_run_hooks.py:260] loss = 1.8747704, step = 42700 (43.402 sec)\n","INFO:tensorflow:global_step/sec: 2.31509\n","I0120 01:32:57.182550 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31509\n","INFO:tensorflow:loss = 1.9207453, step = 42800 (43.196 sec)\n","I0120 01:32:57.184186 140441056839552 basic_session_run_hooks.py:260] loss = 1.9207453, step = 42800 (43.196 sec)\n","INFO:tensorflow:global_step/sec: 2.30069\n","I0120 01:33:40.647801 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30069\n","INFO:tensorflow:loss = 1.7526742, step = 42900 (43.465 sec)\n","I0120 01:33:40.649199 140441056839552 basic_session_run_hooks.py:260] loss = 1.7526742, step = 42900 (43.465 sec)\n","INFO:tensorflow:global_step/sec: 2.31136\n","I0120 01:34:23.912272 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31136\n","INFO:tensorflow:loss = 1.8320868, step = 43000 (43.264 sec)\n","I0120 01:34:23.913486 140441056839552 basic_session_run_hooks.py:260] loss = 1.8320868, step = 43000 (43.264 sec)\n","INFO:tensorflow:global_step/sec: 2.31089\n","I0120 01:35:07.185638 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31089\n","INFO:tensorflow:loss = 2.0035543, step = 43100 (43.274 sec)\n","I0120 01:35:07.187443 140441056839552 basic_session_run_hooks.py:260] loss = 2.0035543, step = 43100 (43.274 sec)\n","INFO:tensorflow:global_step/sec: 2.28728\n","I0120 01:35:50.905573 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28728\n","INFO:tensorflow:loss = 2.0312374, step = 43200 (43.719 sec)\n","I0120 01:35:50.906554 140441056839552 basic_session_run_hooks.py:260] loss = 2.0312374, step = 43200 (43.719 sec)\n","INFO:tensorflow:global_step/sec: 2.29854\n","I0120 01:36:34.411484 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29854\n","INFO:tensorflow:loss = 1.520652, step = 43300 (43.506 sec)\n","I0120 01:36:34.412450 140441056839552 basic_session_run_hooks.py:260] loss = 1.520652, step = 43300 (43.506 sec)\n","INFO:tensorflow:global_step/sec: 2.3162\n","I0120 01:37:17.585740 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3162\n","INFO:tensorflow:loss = 1.9663647, step = 43400 (43.175 sec)\n","I0120 01:37:17.587129 140441056839552 basic_session_run_hooks.py:260] loss = 1.9663647, step = 43400 (43.175 sec)\n","INFO:tensorflow:Saving checkpoints for 43472 into training/log/model.ckpt.\n","I0120 01:37:48.241783 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 43472 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 01:37:50.580334 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:37:53.079893 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:37:53.161639 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:37:53.246559 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:37:53.323163 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:37:53.412608 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:37:53.490823 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 01:37:54.932053 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T01:37:54Z\n","I0120 01:37:54.947658 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T01:37:54Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 01:37:55.423485 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 01:37:55.424211: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:37:55.424562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 01:37:55.424668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 01:37:55.424694: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 01:37:55.424716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 01:37:55.424736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 01:37:55.424756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 01:37:55.424776: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 01:37:55.424797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 01:37:55.424915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:37:55.425278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:37:55.425506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 01:37:55.425586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 01:37:55.425600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 01:37:55.425611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 01:37:55.425741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:37:55.426041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:37:55.426287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-43472\n","I0120 01:37:55.428967 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-43472\n","INFO:tensorflow:Running local_init_op.\n","I0120 01:37:56.503673 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 01:37:56.638412 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 01:38:00.477798 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 01:38:00.478341 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 01:38:00.480782 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.54s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.320\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.767\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.198\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.415\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.402\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.261\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.405\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.427\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.279\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.500\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.400\n","INFO:tensorflow:Finished evaluation at 2020-01-20-01:38:01\n","I0120 01:38:01.159381 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-01:38:01\n","INFO:tensorflow:Saving dict for global step 43472: DetectionBoxes_Precision/mAP = 0.31993905, DetectionBoxes_Precision/mAP (large) = 0.4019802, DetectionBoxes_Precision/mAP (medium) = 0.41494757, DetectionBoxes_Precision/mAP (small) = 0.15050794, DetectionBoxes_Precision/mAP@.50IOU = 0.7666659, DetectionBoxes_Precision/mAP@.75IOU = 0.1982514, DetectionBoxes_Recall/AR@1 = 0.26095238, DetectionBoxes_Recall/AR@10 = 0.4047619, DetectionBoxes_Recall/AR@100 = 0.42666668, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = 0.5, DetectionBoxes_Recall/AR@100 (small) = 0.27941176, Loss/classification_loss = 7.2101, Loss/localization_loss = 1.4424884, Loss/regularization_loss = 0.3163941, Loss/total_loss = 8.968983, global_step = 43472, learning_rate = 0.004, loss = 8.968983\n","I0120 01:38:01.159642 140441056839552 estimator.py:2049] Saving dict for global step 43472: DetectionBoxes_Precision/mAP = 0.31993905, DetectionBoxes_Precision/mAP (large) = 0.4019802, DetectionBoxes_Precision/mAP (medium) = 0.41494757, DetectionBoxes_Precision/mAP (small) = 0.15050794, DetectionBoxes_Precision/mAP@.50IOU = 0.7666659, DetectionBoxes_Precision/mAP@.75IOU = 0.1982514, DetectionBoxes_Recall/AR@1 = 0.26095238, DetectionBoxes_Recall/AR@10 = 0.4047619, DetectionBoxes_Recall/AR@100 = 0.42666668, DetectionBoxes_Recall/AR@100 (large) = 0.4, DetectionBoxes_Recall/AR@100 (medium) = 0.5, DetectionBoxes_Recall/AR@100 (small) = 0.27941176, Loss/classification_loss = 7.2101, Loss/localization_loss = 1.4424884, Loss/regularization_loss = 0.3163941, Loss/total_loss = 8.968983, global_step = 43472, learning_rate = 0.004, loss = 8.968983\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 43472: training/log/model.ckpt-43472\n","I0120 01:38:01.162298 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 43472: training/log/model.ckpt-43472\n","INFO:tensorflow:global_step/sec: 1.78197\n","I0120 01:38:13.703488 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.78197\n","INFO:tensorflow:loss = 1.6625595, step = 43500 (56.117 sec)\n","I0120 01:38:13.704380 140441056839552 basic_session_run_hooks.py:260] loss = 1.6625595, step = 43500 (56.117 sec)\n","INFO:tensorflow:global_step/sec: 2.29571\n","I0120 01:38:57.262933 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29571\n","INFO:tensorflow:loss = 1.8192642, step = 43600 (43.560 sec)\n","I0120 01:38:57.263928 140441056839552 basic_session_run_hooks.py:260] loss = 1.8192642, step = 43600 (43.560 sec)\n","INFO:tensorflow:global_step/sec: 2.29148\n","I0120 01:39:40.902777 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29148\n","INFO:tensorflow:loss = 2.2191384, step = 43700 (43.641 sec)\n","I0120 01:39:40.904474 140441056839552 basic_session_run_hooks.py:260] loss = 2.2191384, step = 43700 (43.641 sec)\n","INFO:tensorflow:global_step/sec: 2.32013\n","I0120 01:40:24.003705 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32013\n","INFO:tensorflow:loss = 1.6819549, step = 43800 (43.100 sec)\n","I0120 01:40:24.004624 140441056839552 basic_session_run_hooks.py:260] loss = 1.6819549, step = 43800 (43.100 sec)\n","INFO:tensorflow:global_step/sec: 2.33016\n","I0120 01:41:06.919226 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.33016\n","INFO:tensorflow:loss = 1.260147, step = 43900 (42.916 sec)\n","I0120 01:41:06.920219 140441056839552 basic_session_run_hooks.py:260] loss = 1.260147, step = 43900 (42.916 sec)\n","INFO:tensorflow:global_step/sec: 2.29664\n","I0120 01:41:50.460982 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29664\n","INFO:tensorflow:loss = 1.8874182, step = 44000 (43.542 sec)\n","I0120 01:41:50.462449 140441056839552 basic_session_run_hooks.py:260] loss = 1.8874182, step = 44000 (43.542 sec)\n","INFO:tensorflow:global_step/sec: 2.2917\n","I0120 01:42:34.096699 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2917\n","INFO:tensorflow:loss = 1.9479276, step = 44100 (43.635 sec)\n","I0120 01:42:34.097796 140441056839552 basic_session_run_hooks.py:260] loss = 1.9479276, step = 44100 (43.635 sec)\n","INFO:tensorflow:global_step/sec: 2.29279\n","I0120 01:43:17.711654 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29279\n","INFO:tensorflow:loss = 1.4095577, step = 44200 (43.615 sec)\n","I0120 01:43:17.712624 140441056839552 basic_session_run_hooks.py:260] loss = 1.4095577, step = 44200 (43.615 sec)\n","INFO:tensorflow:global_step/sec: 2.30368\n","I0120 01:44:01.120483 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30368\n","INFO:tensorflow:loss = 1.5396717, step = 44300 (43.409 sec)\n","I0120 01:44:01.121952 140441056839552 basic_session_run_hooks.py:260] loss = 1.5396717, step = 44300 (43.409 sec)\n","INFO:tensorflow:global_step/sec: 2.29309\n","I0120 01:44:44.729805 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29309\n","INFO:tensorflow:loss = 1.7189604, step = 44400 (43.609 sec)\n","I0120 01:44:44.730962 140441056839552 basic_session_run_hooks.py:260] loss = 1.7189604, step = 44400 (43.609 sec)\n","INFO:tensorflow:global_step/sec: 2.29446\n","I0120 01:45:28.313098 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29446\n","INFO:tensorflow:loss = 2.09346, step = 44500 (43.583 sec)\n","I0120 01:45:28.314030 140441056839552 basic_session_run_hooks.py:260] loss = 2.09346, step = 44500 (43.583 sec)\n","INFO:tensorflow:global_step/sec: 2.30511\n","I0120 01:46:11.695005 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30511\n","INFO:tensorflow:loss = 2.3269951, step = 44600 (43.382 sec)\n","I0120 01:46:11.696499 140441056839552 basic_session_run_hooks.py:260] loss = 2.3269951, step = 44600 (43.382 sec)\n","INFO:tensorflow:global_step/sec: 2.28755\n","I0120 01:46:55.409870 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28755\n","INFO:tensorflow:loss = 1.4400946, step = 44700 (43.714 sec)\n","I0120 01:46:55.410907 140441056839552 basic_session_run_hooks.py:260] loss = 1.4400946, step = 44700 (43.714 sec)\n","INFO:tensorflow:global_step/sec: 2.30048\n","I0120 01:47:38.879007 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30048\n","INFO:tensorflow:loss = 2.6811833, step = 44800 (43.469 sec)\n","I0120 01:47:38.879912 140441056839552 basic_session_run_hooks.py:260] loss = 2.6811833, step = 44800 (43.469 sec)\n","INFO:tensorflow:Saving checkpoints for 44823 into training/log/model.ckpt.\n","I0120 01:47:48.358092 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 44823 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 01:47:50.728561 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:47:52.780478 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:47:52.860291 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:47:52.942982 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:47:53.021167 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:47:53.106281 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:47:53.181997 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 01:47:54.692959 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T01:47:54Z\n","I0120 01:47:54.707816 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T01:47:54Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 01:47:55.513907 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 01:47:55.514624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:47:55.514935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 01:47:55.515033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 01:47:55.515076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 01:47:55.515105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 01:47:55.515128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 01:47:55.515154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 01:47:55.515180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 01:47:55.515206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 01:47:55.515317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:47:55.515651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:47:55.515894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 01:47:55.515937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 01:47:55.515951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 01:47:55.515961: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 01:47:55.516097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:47:55.516412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:47:55.516670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-44823\n","I0120 01:47:55.518842 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-44823\n","INFO:tensorflow:Running local_init_op.\n","I0120 01:47:56.639223 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 01:47:56.795203 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 01:48:00.486253 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 01:48:00.487533 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 01:48:00.492330 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.51s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.283\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.704\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.169\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.146\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.363\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.159\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.250\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.369\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.406\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.291\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n","INFO:tensorflow:Finished evaluation at 2020-01-20-01:48:01\n","I0120 01:48:01.148288 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-01:48:01\n","INFO:tensorflow:Saving dict for global step 44823: DetectionBoxes_Precision/mAP = 0.2832883, DetectionBoxes_Precision/mAP (large) = 0.15858085, DetectionBoxes_Precision/mAP (medium) = 0.3630008, DetectionBoxes_Precision/mAP (small) = 0.14594045, DetectionBoxes_Precision/mAP@.50IOU = 0.7042602, DetectionBoxes_Precision/mAP@.75IOU = 0.16908857, DetectionBoxes_Recall/AR@1 = 0.25047618, DetectionBoxes_Recall/AR@10 = 0.36857143, DetectionBoxes_Recall/AR@100 = 0.40571427, DetectionBoxes_Recall/AR@100 (large) = 0.25, DetectionBoxes_Recall/AR@100 (medium) = 0.46666667, DetectionBoxes_Recall/AR@100 (small) = 0.29117647, Loss/classification_loss = 8.5297985, Loss/localization_loss = 1.4658918, Loss/regularization_loss = 0.31686857, Loss/total_loss = 10.312561, global_step = 44823, learning_rate = 0.004, loss = 10.312561\n","I0120 01:48:01.148561 140441056839552 estimator.py:2049] Saving dict for global step 44823: DetectionBoxes_Precision/mAP = 0.2832883, DetectionBoxes_Precision/mAP (large) = 0.15858085, DetectionBoxes_Precision/mAP (medium) = 0.3630008, DetectionBoxes_Precision/mAP (small) = 0.14594045, DetectionBoxes_Precision/mAP@.50IOU = 0.7042602, DetectionBoxes_Precision/mAP@.75IOU = 0.16908857, DetectionBoxes_Recall/AR@1 = 0.25047618, DetectionBoxes_Recall/AR@10 = 0.36857143, DetectionBoxes_Recall/AR@100 = 0.40571427, DetectionBoxes_Recall/AR@100 (large) = 0.25, DetectionBoxes_Recall/AR@100 (medium) = 0.46666667, DetectionBoxes_Recall/AR@100 (small) = 0.29117647, Loss/classification_loss = 8.5297985, Loss/localization_loss = 1.4658918, Loss/regularization_loss = 0.31686857, Loss/total_loss = 10.312561, global_step = 44823, learning_rate = 0.004, loss = 10.312561\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 44823: training/log/model.ckpt-44823\n","I0120 01:48:01.154325 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 44823: training/log/model.ckpt-44823\n","INFO:tensorflow:global_step/sec: 1.79109\n","I0120 01:48:34.711013 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.79109\n","INFO:tensorflow:loss = 1.8262112, step = 44900 (55.832 sec)\n","I0120 01:48:34.712361 140441056839552 basic_session_run_hooks.py:260] loss = 1.8262112, step = 44900 (55.832 sec)\n","INFO:tensorflow:global_step/sec: 2.29796\n","I0120 01:49:18.227929 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29796\n","INFO:tensorflow:loss = 2.0634305, step = 45000 (43.517 sec)\n","I0120 01:49:18.229131 140441056839552 basic_session_run_hooks.py:260] loss = 2.0634305, step = 45000 (43.517 sec)\n","INFO:tensorflow:global_step/sec: 2.30919\n","I0120 01:50:01.533187 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30919\n","INFO:tensorflow:loss = 1.7022529, step = 45100 (43.305 sec)\n","I0120 01:50:01.534018 140441056839552 basic_session_run_hooks.py:260] loss = 1.7022529, step = 45100 (43.305 sec)\n","INFO:tensorflow:global_step/sec: 2.32402\n","I0120 01:50:44.562213 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32402\n","INFO:tensorflow:loss = 1.6700457, step = 45200 (43.030 sec)\n","I0120 01:50:44.563698 140441056839552 basic_session_run_hooks.py:260] loss = 1.6700457, step = 45200 (43.030 sec)\n","INFO:tensorflow:global_step/sec: 2.30955\n","I0120 01:51:27.860719 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30955\n","INFO:tensorflow:loss = 1.7584906, step = 45300 (43.298 sec)\n","I0120 01:51:27.861937 140441056839552 basic_session_run_hooks.py:260] loss = 1.7584906, step = 45300 (43.298 sec)\n","INFO:tensorflow:global_step/sec: 2.30722\n","I0120 01:52:11.202731 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30722\n","INFO:tensorflow:loss = 1.7554027, step = 45400 (43.342 sec)\n","I0120 01:52:11.203817 140441056839552 basic_session_run_hooks.py:260] loss = 1.7554027, step = 45400 (43.342 sec)\n","INFO:tensorflow:global_step/sec: 2.30122\n","I0120 01:52:54.658033 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30122\n","INFO:tensorflow:loss = 1.7140234, step = 45500 (43.456 sec)\n","I0120 01:52:54.659463 140441056839552 basic_session_run_hooks.py:260] loss = 1.7140234, step = 45500 (43.456 sec)\n","INFO:tensorflow:global_step/sec: 2.3165\n","I0120 01:53:37.826640 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3165\n","INFO:tensorflow:loss = 1.3397291, step = 45600 (43.168 sec)\n","I0120 01:53:37.827864 140441056839552 basic_session_run_hooks.py:260] loss = 1.3397291, step = 45600 (43.168 sec)\n","INFO:tensorflow:global_step/sec: 2.30872\n","I0120 01:54:21.140605 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30872\n","INFO:tensorflow:loss = 1.6161551, step = 45700 (43.314 sec)\n","I0120 01:54:21.141849 140441056839552 basic_session_run_hooks.py:260] loss = 1.6161551, step = 45700 (43.314 sec)\n","INFO:tensorflow:global_step/sec: 2.30728\n","I0120 01:55:04.481691 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30728\n","INFO:tensorflow:loss = 2.1167657, step = 45800 (43.341 sec)\n","I0120 01:55:04.483145 140441056839552 basic_session_run_hooks.py:260] loss = 2.1167657, step = 45800 (43.341 sec)\n","INFO:tensorflow:global_step/sec: 2.30272\n","I0120 01:55:47.908488 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30272\n","INFO:tensorflow:loss = 1.9414426, step = 45900 (43.426 sec)\n","I0120 01:55:47.909604 140441056839552 basic_session_run_hooks.py:260] loss = 1.9414426, step = 45900 (43.426 sec)\n","INFO:tensorflow:global_step/sec: 2.30806\n","I0120 01:56:31.234856 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30806\n","INFO:tensorflow:loss = 2.1555312, step = 46000 (43.326 sec)\n","I0120 01:56:31.235844 140441056839552 basic_session_run_hooks.py:260] loss = 2.1555312, step = 46000 (43.326 sec)\n","INFO:tensorflow:global_step/sec: 2.31923\n","I0120 01:57:14.352581 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31923\n","INFO:tensorflow:loss = 1.831644, step = 46100 (43.118 sec)\n","I0120 01:57:14.354183 140441056839552 basic_session_run_hooks.py:260] loss = 1.831644, step = 46100 (43.118 sec)\n","INFO:tensorflow:Saving checkpoints for 46180 into training/log/model.ckpt.\n","I0120 01:57:48.784586 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 46180 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 01:57:51.134358 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:57:53.193031 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:57:53.267666 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:57:53.358547 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:57:53.439473 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:57:53.513556 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 01:57:53.587553 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 01:57:55.109485 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T01:57:55Z\n","I0120 01:57:55.125252 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T01:57:55Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 01:57:55.622487 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 01:57:55.623393: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:57:55.623721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 01:57:55.623815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 01:57:55.623839: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 01:57:55.623857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 01:57:55.623877: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 01:57:55.623902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 01:57:55.623923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 01:57:55.623945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 01:57:55.624068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:57:55.624379: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:57:55.624607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 01:57:55.624851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 01:57:55.624868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 01:57:55.624877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 01:57:55.625037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:57:55.625358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 01:57:55.625600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-46180\n","I0120 01:57:55.627928 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-46180\n","INFO:tensorflow:Running local_init_op.\n","I0120 01:57:56.724977 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 01:57:56.853187 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 01:58:00.505565 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 01:58:00.506045 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 01:58:00.510622 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.54s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.342\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.789\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.224\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.177\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.432\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.281\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.430\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.445\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.282\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550\n","INFO:tensorflow:Finished evaluation at 2020-01-20-01:58:01\n","I0120 01:58:01.191267 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-01:58:01\n","INFO:tensorflow:Saving dict for global step 46180: DetectionBoxes_Precision/mAP = 0.3416026, DetectionBoxes_Precision/mAP (large) = 0.550495, DetectionBoxes_Precision/mAP (medium) = 0.43241924, DetectionBoxes_Precision/mAP (small) = 0.17734562, DetectionBoxes_Precision/mAP@.50IOU = 0.78940916, DetectionBoxes_Precision/mAP@.75IOU = 0.22353224, DetectionBoxes_Recall/AR@1 = 0.2809524, DetectionBoxes_Recall/AR@10 = 0.4295238, DetectionBoxes_Recall/AR@100 = 0.4447619, DetectionBoxes_Recall/AR@100 (large) = 0.55, DetectionBoxes_Recall/AR@100 (medium) = 0.5217391, DetectionBoxes_Recall/AR@100 (small) = 0.28235295, Loss/classification_loss = 6.591427, Loss/localization_loss = 1.301673, Loss/regularization_loss = 0.31728536, Loss/total_loss = 8.210382, global_step = 46180, learning_rate = 0.004, loss = 8.210382\n","I0120 01:58:01.191525 140441056839552 estimator.py:2049] Saving dict for global step 46180: DetectionBoxes_Precision/mAP = 0.3416026, DetectionBoxes_Precision/mAP (large) = 0.550495, DetectionBoxes_Precision/mAP (medium) = 0.43241924, DetectionBoxes_Precision/mAP (small) = 0.17734562, DetectionBoxes_Precision/mAP@.50IOU = 0.78940916, DetectionBoxes_Precision/mAP@.75IOU = 0.22353224, DetectionBoxes_Recall/AR@1 = 0.2809524, DetectionBoxes_Recall/AR@10 = 0.4295238, DetectionBoxes_Recall/AR@100 = 0.4447619, DetectionBoxes_Recall/AR@100 (large) = 0.55, DetectionBoxes_Recall/AR@100 (medium) = 0.5217391, DetectionBoxes_Recall/AR@100 (small) = 0.28235295, Loss/classification_loss = 6.591427, Loss/localization_loss = 1.301673, Loss/regularization_loss = 0.31728536, Loss/total_loss = 8.210382, global_step = 46180, learning_rate = 0.004, loss = 8.210382\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 46180: training/log/model.ckpt-46180\n","I0120 01:58:01.196336 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 46180: training/log/model.ckpt-46180\n","INFO:tensorflow:global_step/sec: 1.78527\n","I0120 01:58:10.366523 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.78527\n","INFO:tensorflow:loss = 1.3820952, step = 46200 (56.013 sec)\n","I0120 01:58:10.367646 140441056839552 basic_session_run_hooks.py:260] loss = 1.3820952, step = 46200 (56.013 sec)\n","INFO:tensorflow:global_step/sec: 2.3045\n","I0120 01:58:53.759876 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3045\n","INFO:tensorflow:loss = 1.4998813, step = 46300 (43.393 sec)\n","I0120 01:58:53.760869 140441056839552 basic_session_run_hooks.py:260] loss = 1.4998813, step = 46300 (43.393 sec)\n","INFO:tensorflow:global_step/sec: 2.30344\n","I0120 01:59:37.173250 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30344\n","INFO:tensorflow:loss = 1.5571723, step = 46400 (43.414 sec)\n","I0120 01:59:37.174618 140441056839552 basic_session_run_hooks.py:260] loss = 1.5571723, step = 46400 (43.414 sec)\n","INFO:tensorflow:global_step/sec: 2.31817\n","I0120 02:00:20.310741 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31817\n","INFO:tensorflow:loss = 1.8353013, step = 46500 (43.137 sec)\n","I0120 02:00:20.312085 140441056839552 basic_session_run_hooks.py:260] loss = 1.8353013, step = 46500 (43.137 sec)\n","INFO:tensorflow:global_step/sec: 2.31014\n","I0120 02:01:03.598099 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31014\n","INFO:tensorflow:loss = 2.2545795, step = 46600 (43.287 sec)\n","I0120 02:01:03.599142 140441056839552 basic_session_run_hooks.py:260] loss = 2.2545795, step = 46600 (43.287 sec)\n","INFO:tensorflow:global_step/sec: 2.29167\n","I0120 02:01:47.234283 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29167\n","INFO:tensorflow:loss = 1.9192518, step = 46700 (43.637 sec)\n","I0120 02:01:47.235748 140441056839552 basic_session_run_hooks.py:260] loss = 1.9192518, step = 46700 (43.637 sec)\n","INFO:tensorflow:global_step/sec: 2.31718\n","I0120 02:02:30.390125 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31718\n","INFO:tensorflow:loss = 1.8148491, step = 46800 (43.155 sec)\n","I0120 02:02:30.391226 140441056839552 basic_session_run_hooks.py:260] loss = 1.8148491, step = 46800 (43.155 sec)\n","INFO:tensorflow:global_step/sec: 2.31799\n","I0120 02:03:13.530989 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31799\n","INFO:tensorflow:loss = 1.4542358, step = 46900 (43.141 sec)\n","I0120 02:03:13.532042 140441056839552 basic_session_run_hooks.py:260] loss = 1.4542358, step = 46900 (43.141 sec)\n","INFO:tensorflow:global_step/sec: 2.30771\n","I0120 02:03:56.863980 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30771\n","INFO:tensorflow:loss = 1.9440289, step = 47000 (43.333 sec)\n","I0120 02:03:56.865515 140441056839552 basic_session_run_hooks.py:260] loss = 1.9440289, step = 47000 (43.333 sec)\n","INFO:tensorflow:global_step/sec: 2.31296\n","I0120 02:04:40.098553 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31296\n","INFO:tensorflow:loss = 1.5900726, step = 47100 (43.234 sec)\n","I0120 02:04:40.099760 140441056839552 basic_session_run_hooks.py:260] loss = 1.5900726, step = 47100 (43.234 sec)\n","INFO:tensorflow:global_step/sec: 2.30551\n","I0120 02:05:23.472912 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30551\n","INFO:tensorflow:loss = 1.68752, step = 47200 (43.374 sec)\n","I0120 02:05:23.473973 140441056839552 basic_session_run_hooks.py:260] loss = 1.68752, step = 47200 (43.374 sec)\n","INFO:tensorflow:global_step/sec: 2.31555\n","I0120 02:06:06.659122 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31555\n","INFO:tensorflow:loss = 2.3665195, step = 47300 (43.186 sec)\n","I0120 02:06:06.660429 140441056839552 basic_session_run_hooks.py:260] loss = 2.3665195, step = 47300 (43.186 sec)\n","INFO:tensorflow:global_step/sec: 2.30082\n","I0120 02:06:50.121854 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30082\n","INFO:tensorflow:loss = 1.8595644, step = 47400 (43.462 sec)\n","I0120 02:06:50.122895 140441056839552 basic_session_run_hooks.py:260] loss = 1.8595644, step = 47400 (43.462 sec)\n","INFO:tensorflow:global_step/sec: 2.30208\n","I0120 02:07:33.560756 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30208\n","INFO:tensorflow:loss = 1.83816, step = 47500 (43.439 sec)\n","I0120 02:07:33.561860 140441056839552 basic_session_run_hooks.py:260] loss = 1.83816, step = 47500 (43.439 sec)\n","INFO:tensorflow:Saving checkpoints for 47537 into training/log/model.ckpt.\n","I0120 02:07:49.215703 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 47537 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 02:07:51.574150 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:07:53.660114 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:07:53.759702 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:07:53.843423 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:07:53.917227 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:07:53.995515 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:07:54.070053 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 02:07:55.951906 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T02:07:55Z\n","I0120 02:07:55.967302 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T02:07:55Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 02:07:56.429819 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 02:07:56.430499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:07:56.430801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 02:07:56.430900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 02:07:56.430925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 02:07:56.430947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 02:07:56.430969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 02:07:56.430990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 02:07:56.431010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 02:07:56.431031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 02:07:56.431171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:07:56.431494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:07:56.431803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 02:07:56.431908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 02:07:56.431930: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 02:07:56.431943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 02:07:56.432151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:07:56.432604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:07:56.432855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-47537\n","I0120 02:07:56.435157 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-47537\n","INFO:tensorflow:Running local_init_op.\n","I0120 02:07:57.566298 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 02:07:57.707477 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 02:08:01.374866 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 02:08:01.375438 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 02:08:01.379616 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.52s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.301\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.766\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.172\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.382\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.246\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.386\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.410\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.484\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n","INFO:tensorflow:Finished evaluation at 2020-01-20-02:08:02\n","I0120 02:08:02.051913 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-02:08:02\n","INFO:tensorflow:Saving dict for global step 47537: DetectionBoxes_Precision/mAP = 0.30148438, DetectionBoxes_Precision/mAP (large) = 0.35049504, DetectionBoxes_Precision/mAP (medium) = 0.38167363, DetectionBoxes_Precision/mAP (small) = 0.15837303, DetectionBoxes_Precision/mAP@.50IOU = 0.7658695, DetectionBoxes_Precision/mAP@.75IOU = 0.17182095, DetectionBoxes_Recall/AR@1 = 0.24571429, DetectionBoxes_Recall/AR@10 = 0.3857143, DetectionBoxes_Recall/AR@100 = 0.40952381, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = 0.48405796, DetectionBoxes_Recall/AR@100 (small) = 0.2617647, Loss/classification_loss = 7.1269937, Loss/localization_loss = 1.4583218, Loss/regularization_loss = 0.31768233, Loss/total_loss = 8.902998, global_step = 47537, learning_rate = 0.004, loss = 8.902998\n","I0120 02:08:02.052231 140441056839552 estimator.py:2049] Saving dict for global step 47537: DetectionBoxes_Precision/mAP = 0.30148438, DetectionBoxes_Precision/mAP (large) = 0.35049504, DetectionBoxes_Precision/mAP (medium) = 0.38167363, DetectionBoxes_Precision/mAP (small) = 0.15837303, DetectionBoxes_Precision/mAP@.50IOU = 0.7658695, DetectionBoxes_Precision/mAP@.75IOU = 0.17182095, DetectionBoxes_Recall/AR@1 = 0.24571429, DetectionBoxes_Recall/AR@10 = 0.3857143, DetectionBoxes_Recall/AR@100 = 0.40952381, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = 0.48405796, DetectionBoxes_Recall/AR@100 (small) = 0.2617647, Loss/classification_loss = 7.1269937, Loss/localization_loss = 1.4583218, Loss/regularization_loss = 0.31768233, Loss/total_loss = 8.902998, global_step = 47537, learning_rate = 0.004, loss = 8.902998\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 47537: training/log/model.ckpt-47537\n","I0120 02:08:02.055881 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 47537: training/log/model.ckpt-47537\n","INFO:tensorflow:global_step/sec: 1.77225\n","I0120 02:08:29.986228 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.77225\n","INFO:tensorflow:loss = 1.7855737, step = 47600 (56.426 sec)\n","I0120 02:08:29.987631 140441056839552 basic_session_run_hooks.py:260] loss = 1.7855737, step = 47600 (56.426 sec)\n","INFO:tensorflow:global_step/sec: 2.31046\n","I0120 02:09:13.267698 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31046\n","INFO:tensorflow:loss = 1.4893712, step = 47700 (43.281 sec)\n","I0120 02:09:13.268817 140441056839552 basic_session_run_hooks.py:260] loss = 1.4893712, step = 47700 (43.281 sec)\n","INFO:tensorflow:global_step/sec: 2.30341\n","I0120 02:09:56.681508 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30341\n","INFO:tensorflow:loss = 1.2255696, step = 47800 (43.414 sec)\n","I0120 02:09:56.682538 140441056839552 basic_session_run_hooks.py:260] loss = 1.2255696, step = 47800 (43.414 sec)\n","INFO:tensorflow:global_step/sec: 2.30862\n","I0120 02:10:39.997426 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30862\n","INFO:tensorflow:loss = 1.5996681, step = 47900 (43.316 sec)\n","I0120 02:10:39.999014 140441056839552 basic_session_run_hooks.py:260] loss = 1.5996681, step = 47900 (43.316 sec)\n","INFO:tensorflow:global_step/sec: 2.30459\n","I0120 02:11:23.389208 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30459\n","INFO:tensorflow:loss = 1.3935885, step = 48000 (43.391 sec)\n","I0120 02:11:23.390166 140441056839552 basic_session_run_hooks.py:260] loss = 1.3935885, step = 48000 (43.391 sec)\n","INFO:tensorflow:global_step/sec: 2.31638\n","I0120 02:12:06.559890 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31638\n","INFO:tensorflow:loss = 2.9306762, step = 48100 (43.171 sec)\n","I0120 02:12:06.560850 140441056839552 basic_session_run_hooks.py:260] loss = 2.9306762, step = 48100 (43.171 sec)\n","INFO:tensorflow:global_step/sec: 2.30889\n","I0120 02:12:49.870834 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30889\n","INFO:tensorflow:loss = 1.653131, step = 48200 (43.311 sec)\n","I0120 02:12:49.872313 140441056839552 basic_session_run_hooks.py:260] loss = 1.653131, step = 48200 (43.311 sec)\n","INFO:tensorflow:global_step/sec: 2.30967\n","I0120 02:13:33.167087 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30967\n","INFO:tensorflow:loss = 1.9326589, step = 48300 (43.296 sec)\n","I0120 02:13:33.168177 140441056839552 basic_session_run_hooks.py:260] loss = 1.9326589, step = 48300 (43.296 sec)\n","INFO:tensorflow:global_step/sec: 2.30217\n","I0120 02:14:16.604258 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30217\n","INFO:tensorflow:loss = 2.282927, step = 48400 (43.437 sec)\n","I0120 02:14:16.605395 140441056839552 basic_session_run_hooks.py:260] loss = 2.282927, step = 48400 (43.437 sec)\n","INFO:tensorflow:global_step/sec: 2.3153\n","I0120 02:14:59.795302 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3153\n","INFO:tensorflow:loss = 1.6912892, step = 48500 (43.192 sec)\n","I0120 02:14:59.797387 140441056839552 basic_session_run_hooks.py:260] loss = 1.6912892, step = 48500 (43.192 sec)\n","INFO:tensorflow:global_step/sec: 2.30486\n","I0120 02:15:43.181886 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30486\n","INFO:tensorflow:loss = 1.9008707, step = 48600 (43.386 sec)\n","I0120 02:15:43.182920 140441056839552 basic_session_run_hooks.py:260] loss = 1.9008707, step = 48600 (43.386 sec)\n","INFO:tensorflow:global_step/sec: 2.3142\n","I0120 02:16:26.393265 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3142\n","INFO:tensorflow:loss = 2.5288367, step = 48700 (43.211 sec)\n","I0120 02:16:26.394239 140441056839552 basic_session_run_hooks.py:260] loss = 2.5288367, step = 48700 (43.211 sec)\n","INFO:tensorflow:global_step/sec: 2.32384\n","I0120 02:17:09.425587 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32384\n","INFO:tensorflow:loss = 1.3580079, step = 48800 (43.033 sec)\n","I0120 02:17:09.426999 140441056839552 basic_session_run_hooks.py:260] loss = 1.3580079, step = 48800 (43.033 sec)\n","INFO:tensorflow:Saving checkpoints for 48893 into training/log/model.ckpt.\n","I0120 02:17:49.497591 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 48893 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 02:17:51.848472 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:17:53.928337 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:17:54.003806 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:17:54.087029 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:17:54.174470 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:17:54.251806 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:17:54.329035 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 02:17:55.807338 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T02:17:55Z\n","I0120 02:17:55.822820 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T02:17:55Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 02:17:56.315294 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 02:17:56.316397: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:17:56.316921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 02:17:56.317129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 02:17:56.317240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 02:17:56.317312: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 02:17:56.317354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 02:17:56.317379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 02:17:56.317467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 02:17:56.317520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 02:17:56.317718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:17:56.318357: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:17:56.318821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 02:17:56.318920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 02:17:56.318944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 02:17:56.318956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 02:17:56.319213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:17:56.319895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:17:56.320400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-48893\n","I0120 02:17:56.325048 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-48893\n","INFO:tensorflow:Running local_init_op.\n","I0120 02:17:57.406955 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 02:17:57.547217 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 02:18:01.246877 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 02:18:01.247805 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 02:18:01.252431 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.52s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.313\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.781\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.135\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.183\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.262\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.380\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.399\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.259\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.467\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.450\n","INFO:tensorflow:Finished evaluation at 2020-01-20-02:18:01\n","I0120 02:18:01.915663 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-02:18:01\n","INFO:tensorflow:Saving dict for global step 48893: DetectionBoxes_Precision/mAP = 0.3133214, DetectionBoxes_Precision/mAP (large) = 0.45049506, DetectionBoxes_Precision/mAP (medium) = 0.384647, DetectionBoxes_Precision/mAP (small) = 0.18290004, DetectionBoxes_Precision/mAP@.50IOU = 0.78071415, DetectionBoxes_Precision/mAP@.75IOU = 0.13467601, DetectionBoxes_Recall/AR@1 = 0.26190478, DetectionBoxes_Recall/AR@10 = 0.38, DetectionBoxes_Recall/AR@100 = 0.3990476, DetectionBoxes_Recall/AR@100 (large) = 0.45, DetectionBoxes_Recall/AR@100 (medium) = 0.46666667, DetectionBoxes_Recall/AR@100 (small) = 0.25882354, Loss/classification_loss = 7.2816367, Loss/localization_loss = 1.6401939, Loss/regularization_loss = 0.31807703, Loss/total_loss = 9.239906, global_step = 48893, learning_rate = 0.004, loss = 9.239906\n","I0120 02:18:01.915953 140441056839552 estimator.py:2049] Saving dict for global step 48893: DetectionBoxes_Precision/mAP = 0.3133214, DetectionBoxes_Precision/mAP (large) = 0.45049506, DetectionBoxes_Precision/mAP (medium) = 0.384647, DetectionBoxes_Precision/mAP (small) = 0.18290004, DetectionBoxes_Precision/mAP@.50IOU = 0.78071415, DetectionBoxes_Precision/mAP@.75IOU = 0.13467601, DetectionBoxes_Recall/AR@1 = 0.26190478, DetectionBoxes_Recall/AR@10 = 0.38, DetectionBoxes_Recall/AR@100 = 0.3990476, DetectionBoxes_Recall/AR@100 (large) = 0.45, DetectionBoxes_Recall/AR@100 (medium) = 0.46666667, DetectionBoxes_Recall/AR@100 (small) = 0.25882354, Loss/classification_loss = 7.2816367, Loss/localization_loss = 1.6401939, Loss/regularization_loss = 0.31807703, Loss/total_loss = 9.239906, global_step = 48893, learning_rate = 0.004, loss = 9.239906\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 48893: training/log/model.ckpt-48893\n","I0120 02:18:01.918956 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 48893: training/log/model.ckpt-48893\n","INFO:tensorflow:global_step/sec: 1.78246\n","I0120 02:18:05.527884 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.78246\n","INFO:tensorflow:loss = 1.5337964, step = 48900 (56.102 sec)\n","I0120 02:18:05.529169 140441056839552 basic_session_run_hooks.py:260] loss = 1.5337964, step = 48900 (56.102 sec)\n","INFO:tensorflow:global_step/sec: 2.30555\n","I0120 02:18:48.901451 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30555\n","INFO:tensorflow:loss = 1.9012983, step = 49000 (43.373 sec)\n","I0120 02:18:48.902415 140441056839552 basic_session_run_hooks.py:260] loss = 1.9012983, step = 49000 (43.373 sec)\n","INFO:tensorflow:global_step/sec: 2.3083\n","I0120 02:19:32.223530 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3083\n","INFO:tensorflow:loss = 2.5346746, step = 49100 (43.323 sec)\n","I0120 02:19:32.224938 140441056839552 basic_session_run_hooks.py:260] loss = 2.5346746, step = 49100 (43.323 sec)\n","INFO:tensorflow:global_step/sec: 2.30656\n","I0120 02:20:15.578221 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30656\n","INFO:tensorflow:loss = 1.6199055, step = 49200 (43.354 sec)\n","I0120 02:20:15.579309 140441056839552 basic_session_run_hooks.py:260] loss = 1.6199055, step = 49200 (43.354 sec)\n","INFO:tensorflow:global_step/sec: 2.30712\n","I0120 02:20:58.922247 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30712\n","INFO:tensorflow:loss = 1.967358, step = 49300 (43.344 sec)\n","I0120 02:20:58.923249 140441056839552 basic_session_run_hooks.py:260] loss = 1.967358, step = 49300 (43.344 sec)\n","INFO:tensorflow:global_step/sec: 2.32014\n","I0120 02:21:42.023005 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32014\n","INFO:tensorflow:loss = 2.0505173, step = 49400 (43.101 sec)\n","I0120 02:21:42.024442 140441056839552 basic_session_run_hooks.py:260] loss = 2.0505173, step = 49400 (43.101 sec)\n","INFO:tensorflow:global_step/sec: 2.30903\n","I0120 02:22:25.331290 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30903\n","INFO:tensorflow:loss = 1.8320047, step = 49500 (43.308 sec)\n","I0120 02:22:25.332163 140441056839552 basic_session_run_hooks.py:260] loss = 1.8320047, step = 49500 (43.308 sec)\n","INFO:tensorflow:global_step/sec: 2.30563\n","I0120 02:23:08.703519 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30563\n","INFO:tensorflow:loss = 1.699895, step = 49600 (43.373 sec)\n","I0120 02:23:08.705144 140441056839552 basic_session_run_hooks.py:260] loss = 1.699895, step = 49600 (43.373 sec)\n","INFO:tensorflow:global_step/sec: 2.31233\n","I0120 02:23:51.949864 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31233\n","INFO:tensorflow:loss = 1.4540595, step = 49700 (43.246 sec)\n","I0120 02:23:51.951082 140441056839552 basic_session_run_hooks.py:260] loss = 1.4540595, step = 49700 (43.246 sec)\n","INFO:tensorflow:global_step/sec: 2.3067\n","I0120 02:24:35.301884 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3067\n","INFO:tensorflow:loss = 1.9917094, step = 49800 (43.352 sec)\n","I0120 02:24:35.302972 140441056839552 basic_session_run_hooks.py:260] loss = 1.9917094, step = 49800 (43.352 sec)\n","INFO:tensorflow:global_step/sec: 2.2988\n","I0120 02:25:18.802899 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.2988\n","INFO:tensorflow:loss = 2.1486802, step = 49900 (43.501 sec)\n","I0120 02:25:18.803982 140441056839552 basic_session_run_hooks.py:260] loss = 2.1486802, step = 49900 (43.501 sec)\n","INFO:tensorflow:global_step/sec: 2.31044\n","I0120 02:26:02.084692 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31044\n","INFO:tensorflow:loss = 1.8188839, step = 50000 (43.283 sec)\n","I0120 02:26:02.086511 140441056839552 basic_session_run_hooks.py:260] loss = 1.8188839, step = 50000 (43.283 sec)\n","INFO:tensorflow:global_step/sec: 2.3102\n","I0120 02:26:45.371082 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3102\n","INFO:tensorflow:loss = 1.580482, step = 50100 (43.286 sec)\n","I0120 02:26:45.372274 140441056839552 basic_session_run_hooks.py:260] loss = 1.580482, step = 50100 (43.286 sec)\n","INFO:tensorflow:global_step/sec: 2.33056\n","I0120 02:27:28.279304 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.33056\n","INFO:tensorflow:loss = 2.5218232, step = 50200 (42.908 sec)\n","I0120 02:27:28.280257 140441056839552 basic_session_run_hooks.py:260] loss = 2.5218232, step = 50200 (42.908 sec)\n","INFO:tensorflow:Saving checkpoints for 50251 into training/log/model.ckpt.\n","I0120 02:27:49.930946 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 50251 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 02:27:52.281111 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:27:54.738029 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:27:54.813505 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:27:54.894978 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:27:54.969087 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:27:55.048355 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:27:55.128587 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 02:27:56.617032 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T02:27:56Z\n","I0120 02:27:56.635992 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T02:27:56Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 02:27:57.134325 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 02:27:57.135155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:27:57.135472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 02:27:57.135559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 02:27:57.135588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 02:27:57.135602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 02:27:57.135617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 02:27:57.135630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 02:27:57.135643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 02:27:57.135657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 02:27:57.135749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:27:57.136020: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:27:57.136264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 02:27:57.136502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 02:27:57.136515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 02:27:57.136524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 02:27:57.136683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:27:57.136965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:27:57.137199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-50251\n","I0120 02:27:57.139550 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-50251\n","INFO:tensorflow:Running local_init_op.\n","I0120 02:27:58.243613 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 02:27:58.377641 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 02:28:02.025218 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 02:28:02.026227 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 02:28:02.030731 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.52s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.366\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.807\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.252\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.191\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.452\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.652\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.290\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.437\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.444\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.262\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.528\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n","INFO:tensorflow:Finished evaluation at 2020-01-20-02:28:02\n","I0120 02:28:02.721315 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-02:28:02\n","INFO:tensorflow:Saving dict for global step 50251: DetectionBoxes_Precision/mAP = 0.36624682, DetectionBoxes_Precision/mAP (large) = 0.65247524, DetectionBoxes_Precision/mAP (medium) = 0.45227218, DetectionBoxes_Precision/mAP (small) = 0.19106364, DetectionBoxes_Precision/mAP@.50IOU = 0.8073831, DetectionBoxes_Precision/mAP@.75IOU = 0.2520403, DetectionBoxes_Recall/AR@1 = 0.2904762, DetectionBoxes_Recall/AR@10 = 0.43714285, DetectionBoxes_Recall/AR@100 = 0.4438095, DetectionBoxes_Recall/AR@100 (large) = 0.65, DetectionBoxes_Recall/AR@100 (medium) = 0.5275362, DetectionBoxes_Recall/AR@100 (small) = 0.2617647, Loss/classification_loss = 7.1990814, Loss/localization_loss = 1.3769121, Loss/regularization_loss = 0.3184578, Loss/total_loss = 8.894449, global_step = 50251, learning_rate = 0.004, loss = 8.894449\n","I0120 02:28:02.721613 140441056839552 estimator.py:2049] Saving dict for global step 50251: DetectionBoxes_Precision/mAP = 0.36624682, DetectionBoxes_Precision/mAP (large) = 0.65247524, DetectionBoxes_Precision/mAP (medium) = 0.45227218, DetectionBoxes_Precision/mAP (small) = 0.19106364, DetectionBoxes_Precision/mAP@.50IOU = 0.8073831, DetectionBoxes_Precision/mAP@.75IOU = 0.2520403, DetectionBoxes_Recall/AR@1 = 0.2904762, DetectionBoxes_Recall/AR@10 = 0.43714285, DetectionBoxes_Recall/AR@100 = 0.4438095, DetectionBoxes_Recall/AR@100 (large) = 0.65, DetectionBoxes_Recall/AR@100 (medium) = 0.5275362, DetectionBoxes_Recall/AR@100 (small) = 0.2617647, Loss/classification_loss = 7.1990814, Loss/localization_loss = 1.3769121, Loss/regularization_loss = 0.3184578, Loss/total_loss = 8.894449, global_step = 50251, learning_rate = 0.004, loss = 8.894449\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50251: training/log/model.ckpt-50251\n","I0120 02:28:02.725776 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 50251: training/log/model.ckpt-50251\n","INFO:tensorflow:global_step/sec: 1.78485\n","I0120 02:28:24.306362 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.78485\n","INFO:tensorflow:loss = 1.8908744, step = 50300 (56.028 sec)\n","I0120 02:28:24.308019 140441056839552 basic_session_run_hooks.py:260] loss = 1.8908744, step = 50300 (56.028 sec)\n","INFO:tensorflow:global_step/sec: 2.31583\n","I0120 02:29:07.487375 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31583\n","INFO:tensorflow:loss = 2.2343733, step = 50400 (43.180 sec)\n","I0120 02:29:07.488434 140441056839552 basic_session_run_hooks.py:260] loss = 2.2343733, step = 50400 (43.180 sec)\n","INFO:tensorflow:global_step/sec: 2.30864\n","I0120 02:29:50.802915 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30864\n","INFO:tensorflow:loss = 1.3933913, step = 50500 (43.316 sec)\n","I0120 02:29:50.803980 140441056839552 basic_session_run_hooks.py:260] loss = 1.3933913, step = 50500 (43.316 sec)\n","INFO:tensorflow:global_step/sec: 2.30966\n","I0120 02:30:34.099293 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30966\n","INFO:tensorflow:loss = 1.3028313, step = 50600 (43.297 sec)\n","I0120 02:30:34.100669 140441056839552 basic_session_run_hooks.py:260] loss = 1.3028313, step = 50600 (43.297 sec)\n","INFO:tensorflow:global_step/sec: 2.31298\n","I0120 02:31:17.333705 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31298\n","INFO:tensorflow:loss = 1.6682279, step = 50700 (43.234 sec)\n","I0120 02:31:17.334898 140441056839552 basic_session_run_hooks.py:260] loss = 1.6682279, step = 50700 (43.234 sec)\n","INFO:tensorflow:global_step/sec: 2.32092\n","I0120 02:32:00.420010 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32092\n","INFO:tensorflow:loss = 1.5481217, step = 50800 (43.086 sec)\n","I0120 02:32:00.421108 140441056839552 basic_session_run_hooks.py:260] loss = 1.5481217, step = 50800 (43.086 sec)\n","INFO:tensorflow:global_step/sec: 2.3174\n","I0120 02:32:43.571920 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3174\n","INFO:tensorflow:loss = 2.1869617, step = 50900 (43.152 sec)\n","I0120 02:32:43.573416 140441056839552 basic_session_run_hooks.py:260] loss = 2.1869617, step = 50900 (43.152 sec)\n","INFO:tensorflow:global_step/sec: 2.31462\n","I0120 02:33:26.775509 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31462\n","INFO:tensorflow:loss = 1.882129, step = 51000 (43.203 sec)\n","I0120 02:33:26.776523 140441056839552 basic_session_run_hooks.py:260] loss = 1.882129, step = 51000 (43.203 sec)\n","INFO:tensorflow:global_step/sec: 2.31998\n","I0120 02:34:09.879294 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31998\n","INFO:tensorflow:loss = 1.7810814, step = 51100 (43.104 sec)\n","I0120 02:34:09.880261 140441056839552 basic_session_run_hooks.py:260] loss = 1.7810814, step = 51100 (43.104 sec)\n","INFO:tensorflow:global_step/sec: 2.31552\n","I0120 02:34:53.066139 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31552\n","INFO:tensorflow:loss = 2.087504, step = 51200 (43.188 sec)\n","I0120 02:34:53.067779 140441056839552 basic_session_run_hooks.py:260] loss = 2.087504, step = 51200 (43.188 sec)\n","INFO:tensorflow:global_step/sec: 2.31061\n","I0120 02:35:36.344738 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31061\n","INFO:tensorflow:loss = 1.5156429, step = 51300 (43.278 sec)\n","I0120 02:35:36.345810 140441056839552 basic_session_run_hooks.py:260] loss = 1.5156429, step = 51300 (43.278 sec)\n","INFO:tensorflow:global_step/sec: 2.31777\n","I0120 02:36:19.489665 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31777\n","INFO:tensorflow:loss = 2.1012638, step = 51400 (43.145 sec)\n","I0120 02:36:19.490615 140441056839552 basic_session_run_hooks.py:260] loss = 2.1012638, step = 51400 (43.145 sec)\n","INFO:tensorflow:global_step/sec: 2.31794\n","I0120 02:37:02.631342 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31794\n","INFO:tensorflow:loss = 1.6467862, step = 51500 (43.142 sec)\n","I0120 02:37:02.632986 140441056839552 basic_session_run_hooks.py:260] loss = 1.6467862, step = 51500 (43.142 sec)\n","INFO:tensorflow:global_step/sec: 2.33195\n","I0120 02:37:45.513936 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.33195\n","INFO:tensorflow:loss = 1.8774965, step = 51600 (42.882 sec)\n","I0120 02:37:45.514881 140441056839552 basic_session_run_hooks.py:260] loss = 1.8774965, step = 51600 (42.882 sec)\n","INFO:tensorflow:Saving checkpoints for 51612 into training/log/model.ckpt.\n","I0120 02:37:50.190840 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 51612 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 02:37:52.523122 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:37:54.571501 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:37:54.644857 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:37:54.726602 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:37:54.809158 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:37:54.886720 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:37:54.960886 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 02:37:56.461653 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T02:37:56Z\n","I0120 02:37:56.477270 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T02:37:56Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 02:37:56.952813 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 02:37:56.953475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:37:56.953756: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 02:37:56.953838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 02:37:56.953858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 02:37:56.953872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 02:37:56.953887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 02:37:56.953901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 02:37:56.953914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 02:37:56.953929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 02:37:56.954016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:37:56.954347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:37:56.954600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 02:37:56.954678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 02:37:56.954688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 02:37:56.954697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 02:37:56.954809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:37:56.955098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:37:56.955321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-51612\n","I0120 02:37:56.957591 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-51612\n","INFO:tensorflow:Running local_init_op.\n","I0120 02:37:58.054769 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 02:37:58.188404 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 02:38:01.815425 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 02:38:01.816027 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 02:38:01.820701 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.51s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.316\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.779\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.181\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.397\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.268\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.404\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.297\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.486\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n","INFO:tensorflow:Finished evaluation at 2020-01-20-02:38:02\n","I0120 02:38:02.473716 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-02:38:02\n","INFO:tensorflow:Saving dict for global step 51612: DetectionBoxes_Precision/mAP = 0.3159556, DetectionBoxes_Precision/mAP (large) = 0.5, DetectionBoxes_Precision/mAP (medium) = 0.39708143, DetectionBoxes_Precision/mAP (small) = 0.15133154, DetectionBoxes_Precision/mAP@.50IOU = 0.77882075, DetectionBoxes_Precision/mAP@.75IOU = 0.18092659, DetectionBoxes_Recall/AR@1 = 0.26761904, DetectionBoxes_Recall/AR@10 = 0.40380952, DetectionBoxes_Recall/AR@100 = 0.4247619, DetectionBoxes_Recall/AR@100 (large) = 0.5, DetectionBoxes_Recall/AR@100 (medium) = 0.48550725, DetectionBoxes_Recall/AR@100 (small) = 0.29705882, Loss/classification_loss = 7.7759504, Loss/localization_loss = 1.4595671, Loss/regularization_loss = 0.31880182, Loss/total_loss = 9.554319, global_step = 51612, learning_rate = 0.004, loss = 9.554319\n","I0120 02:38:02.473957 140441056839552 estimator.py:2049] Saving dict for global step 51612: DetectionBoxes_Precision/mAP = 0.3159556, DetectionBoxes_Precision/mAP (large) = 0.5, DetectionBoxes_Precision/mAP (medium) = 0.39708143, DetectionBoxes_Precision/mAP (small) = 0.15133154, DetectionBoxes_Precision/mAP@.50IOU = 0.77882075, DetectionBoxes_Precision/mAP@.75IOU = 0.18092659, DetectionBoxes_Recall/AR@1 = 0.26761904, DetectionBoxes_Recall/AR@10 = 0.40380952, DetectionBoxes_Recall/AR@100 = 0.4247619, DetectionBoxes_Recall/AR@100 (large) = 0.5, DetectionBoxes_Recall/AR@100 (medium) = 0.48550725, DetectionBoxes_Recall/AR@100 (small) = 0.29705882, Loss/classification_loss = 7.7759504, Loss/localization_loss = 1.4595671, Loss/regularization_loss = 0.31880182, Loss/total_loss = 9.554319, global_step = 51612, learning_rate = 0.004, loss = 9.554319\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 51612: training/log/model.ckpt-51612\n","I0120 02:38:02.618676 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 51612: training/log/model.ckpt-51612\n","INFO:tensorflow:global_step/sec: 1.7828\n","I0120 02:38:41.605346 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.7828\n","INFO:tensorflow:loss = 1.9937155, step = 51700 (56.092 sec)\n","I0120 02:38:41.606406 140441056839552 basic_session_run_hooks.py:260] loss = 1.9937155, step = 51700 (56.092 sec)\n","INFO:tensorflow:global_step/sec: 2.3191\n","I0120 02:39:24.725605 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3191\n","INFO:tensorflow:loss = 1.4647915, step = 51800 (43.121 sec)\n","I0120 02:39:24.727004 140441056839552 basic_session_run_hooks.py:260] loss = 1.4647915, step = 51800 (43.121 sec)\n","INFO:tensorflow:global_step/sec: 2.29376\n","I0120 02:40:08.322037 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29376\n","INFO:tensorflow:loss = 1.4832934, step = 51900 (43.596 sec)\n","I0120 02:40:08.323110 140441056839552 basic_session_run_hooks.py:260] loss = 1.4832934, step = 51900 (43.596 sec)\n","INFO:tensorflow:global_step/sec: 2.32544\n","I0120 02:40:51.324603 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32544\n","INFO:tensorflow:loss = 1.715204, step = 52000 (43.003 sec)\n","I0120 02:40:51.325729 140441056839552 basic_session_run_hooks.py:260] loss = 1.715204, step = 52000 (43.003 sec)\n","INFO:tensorflow:global_step/sec: 2.29718\n","I0120 02:41:34.856247 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29718\n","INFO:tensorflow:loss = 1.6717722, step = 52100 (43.532 sec)\n","I0120 02:41:34.857859 140441056839552 basic_session_run_hooks.py:260] loss = 1.6717722, step = 52100 (43.532 sec)\n","INFO:tensorflow:global_step/sec: 2.31371\n","I0120 02:42:18.076845 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31371\n","INFO:tensorflow:loss = 1.8758739, step = 52200 (43.220 sec)\n","I0120 02:42:18.077915 140441056839552 basic_session_run_hooks.py:260] loss = 1.8758739, step = 52200 (43.220 sec)\n","INFO:tensorflow:global_step/sec: 2.31735\n","I0120 02:43:01.229571 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31735\n","INFO:tensorflow:loss = 1.5885379, step = 52300 (43.153 sec)\n","I0120 02:43:01.230524 140441056839552 basic_session_run_hooks.py:260] loss = 1.5885379, step = 52300 (43.153 sec)\n","INFO:tensorflow:global_step/sec: 2.3082\n","I0120 02:43:44.553304 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3082\n","INFO:tensorflow:loss = 2.2252188, step = 52400 (43.324 sec)\n","I0120 02:43:44.554692 140441056839552 basic_session_run_hooks.py:260] loss = 2.2252188, step = 52400 (43.324 sec)\n","INFO:tensorflow:global_step/sec: 2.30043\n","I0120 02:44:28.023448 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30043\n","INFO:tensorflow:loss = 2.103764, step = 52500 (43.470 sec)\n","I0120 02:44:28.024518 140441056839552 basic_session_run_hooks.py:260] loss = 2.103764, step = 52500 (43.470 sec)\n","INFO:tensorflow:global_step/sec: 2.31821\n","I0120 02:45:11.160187 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31821\n","INFO:tensorflow:loss = 1.9977429, step = 52600 (43.138 sec)\n","I0120 02:45:11.162194 140441056839552 basic_session_run_hooks.py:260] loss = 1.9977429, step = 52600 (43.138 sec)\n","INFO:tensorflow:global_step/sec: 2.32664\n","I0120 02:45:54.140667 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32664\n","INFO:tensorflow:loss = 1.6403894, step = 52700 (42.980 sec)\n","I0120 02:45:54.142586 140441056839552 basic_session_run_hooks.py:260] loss = 1.6403894, step = 52700 (42.980 sec)\n","INFO:tensorflow:global_step/sec: 2.31142\n","I0120 02:46:37.404160 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31142\n","INFO:tensorflow:loss = 2.0798097, step = 52800 (43.263 sec)\n","I0120 02:46:37.405479 140441056839552 basic_session_run_hooks.py:260] loss = 2.0798097, step = 52800 (43.263 sec)\n","INFO:tensorflow:global_step/sec: 2.30558\n","I0120 02:47:20.777142 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30558\n","INFO:tensorflow:loss = 1.7120681, step = 52900 (43.373 sec)\n","I0120 02:47:20.778423 140441056839552 basic_session_run_hooks.py:260] loss = 1.7120681, step = 52900 (43.373 sec)\n","INFO:tensorflow:Saving checkpoints for 52970 into training/log/model.ckpt.\n","I0120 02:47:50.512165 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 52970 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 02:47:53.213648 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:47:55.279561 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:47:55.365807 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:47:55.448317 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:47:55.522023 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:47:55.604022 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:47:55.682581 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 02:47:57.154227 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T02:47:57Z\n","I0120 02:47:57.169146 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T02:47:57Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 02:47:57.659305 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 02:47:57.659947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:47:57.660266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 02:47:57.660361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 02:47:57.660386: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 02:47:57.660407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 02:47:57.660427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 02:47:57.660452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 02:47:57.660475: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 02:47:57.660497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 02:47:57.660611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:47:57.660920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:47:57.661154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 02:47:57.661196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 02:47:57.661208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 02:47:57.661217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 02:47:57.661339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:47:57.661652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:47:57.661888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-52970\n","I0120 02:47:57.664476 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-52970\n","INFO:tensorflow:Running local_init_op.\n","I0120 02:47:58.810682 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 02:47:58.951435 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 02:48:02.608499 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 02:48:02.608911 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 02:48:02.611768 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.58s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.340\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.795\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.212\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.162\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.435\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.273\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.425\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.432\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.274\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.509\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.500\n","INFO:tensorflow:Finished evaluation at 2020-01-20-02:48:03\n","I0120 02:48:03.325502 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-02:48:03\n","INFO:tensorflow:Saving dict for global step 52970: DetectionBoxes_Precision/mAP = 0.3400913, DetectionBoxes_Precision/mAP (large) = 0.5, DetectionBoxes_Precision/mAP (medium) = 0.4348482, DetectionBoxes_Precision/mAP (small) = 0.16233115, DetectionBoxes_Precision/mAP@.50IOU = 0.7953483, DetectionBoxes_Precision/mAP@.75IOU = 0.21234475, DetectionBoxes_Recall/AR@1 = 0.27333334, DetectionBoxes_Recall/AR@10 = 0.4247619, DetectionBoxes_Recall/AR@100 = 0.43238094, DetectionBoxes_Recall/AR@100 (large) = 0.5, DetectionBoxes_Recall/AR@100 (medium) = 0.50869566, DetectionBoxes_Recall/AR@100 (small) = 0.2735294, Loss/classification_loss = 7.4833236, Loss/localization_loss = 1.3530052, Loss/regularization_loss = 0.31915095, Loss/total_loss = 9.15548, global_step = 52970, learning_rate = 0.004, loss = 9.15548\n","I0120 02:48:03.325761 140441056839552 estimator.py:2049] Saving dict for global step 52970: DetectionBoxes_Precision/mAP = 0.3400913, DetectionBoxes_Precision/mAP (large) = 0.5, DetectionBoxes_Precision/mAP (medium) = 0.4348482, DetectionBoxes_Precision/mAP (small) = 0.16233115, DetectionBoxes_Precision/mAP@.50IOU = 0.7953483, DetectionBoxes_Precision/mAP@.75IOU = 0.21234475, DetectionBoxes_Recall/AR@1 = 0.27333334, DetectionBoxes_Recall/AR@10 = 0.4247619, DetectionBoxes_Recall/AR@100 = 0.43238094, DetectionBoxes_Recall/AR@100 (large) = 0.5, DetectionBoxes_Recall/AR@100 (medium) = 0.50869566, DetectionBoxes_Recall/AR@100 (small) = 0.2735294, Loss/classification_loss = 7.4833236, Loss/localization_loss = 1.3530052, Loss/regularization_loss = 0.31915095, Loss/total_loss = 9.15548, global_step = 52970, learning_rate = 0.004, loss = 9.15548\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 52970: training/log/model.ckpt-52970\n","I0120 02:48:03.329823 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 52970: training/log/model.ckpt-52970\n","INFO:tensorflow:global_step/sec: 1.78496\n","I0120 02:48:16.800657 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.78496\n","INFO:tensorflow:loss = 1.7301171, step = 53000 (56.024 sec)\n","I0120 02:48:16.802238 140441056839552 basic_session_run_hooks.py:260] loss = 1.7301171, step = 53000 (56.024 sec)\n","INFO:tensorflow:global_step/sec: 2.28828\n","I0120 02:49:00.501658 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28828\n","INFO:tensorflow:loss = 1.7654243, step = 53100 (43.700 sec)\n","I0120 02:49:00.502663 140441056839552 basic_session_run_hooks.py:260] loss = 1.7654243, step = 53100 (43.700 sec)\n","INFO:tensorflow:global_step/sec: 2.31862\n","I0120 02:49:43.630847 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31862\n","INFO:tensorflow:loss = 2.6631036, step = 53200 (43.129 sec)\n","I0120 02:49:43.631834 140441056839552 basic_session_run_hooks.py:260] loss = 2.6631036, step = 53200 (43.129 sec)\n","INFO:tensorflow:global_step/sec: 2.29446\n","I0120 02:50:27.214149 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29446\n","INFO:tensorflow:loss = 1.5231875, step = 53300 (43.584 sec)\n","I0120 02:50:27.215789 140441056839552 basic_session_run_hooks.py:260] loss = 1.5231875, step = 53300 (43.584 sec)\n","INFO:tensorflow:global_step/sec: 2.31043\n","I0120 02:51:10.496112 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31043\n","INFO:tensorflow:loss = 2.1390154, step = 53400 (43.281 sec)\n","I0120 02:51:10.497136 140441056839552 basic_session_run_hooks.py:260] loss = 2.1390154, step = 53400 (43.281 sec)\n","INFO:tensorflow:global_step/sec: 2.32475\n","I0120 02:51:53.511389 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32475\n","INFO:tensorflow:loss = 1.5144353, step = 53500 (43.015 sec)\n","I0120 02:51:53.512374 140441056839552 basic_session_run_hooks.py:260] loss = 1.5144353, step = 53500 (43.015 sec)\n","INFO:tensorflow:global_step/sec: 2.32192\n","I0120 02:52:36.579186 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32192\n","INFO:tensorflow:loss = 1.8396903, step = 53600 (43.068 sec)\n","I0120 02:52:36.580424 140441056839552 basic_session_run_hooks.py:260] loss = 1.8396903, step = 53600 (43.068 sec)\n","INFO:tensorflow:global_step/sec: 2.3063\n","I0120 02:53:19.938760 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3063\n","INFO:tensorflow:loss = 2.6092892, step = 53700 (43.360 sec)\n","I0120 02:53:19.939947 140441056839552 basic_session_run_hooks.py:260] loss = 2.6092892, step = 53700 (43.360 sec)\n","INFO:tensorflow:global_step/sec: 2.31928\n","I0120 02:54:03.055485 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31928\n","INFO:tensorflow:loss = 1.571009, step = 53800 (43.116 sec)\n","I0120 02:54:03.056433 140441056839552 basic_session_run_hooks.py:260] loss = 1.571009, step = 53800 (43.116 sec)\n","INFO:tensorflow:global_step/sec: 2.31882\n","I0120 02:54:46.180895 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31882\n","INFO:tensorflow:loss = 2.3172305, step = 53900 (43.126 sec)\n","I0120 02:54:46.182370 140441056839552 basic_session_run_hooks.py:260] loss = 2.3172305, step = 53900 (43.126 sec)\n","INFO:tensorflow:global_step/sec: 2.29822\n","I0120 02:55:29.692925 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29822\n","INFO:tensorflow:loss = 1.5787129, step = 54000 (43.512 sec)\n","I0120 02:55:29.694068 140441056839552 basic_session_run_hooks.py:260] loss = 1.5787129, step = 54000 (43.512 sec)\n","INFO:tensorflow:global_step/sec: 2.32971\n","I0120 02:56:12.616647 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32971\n","INFO:tensorflow:loss = 1.7637995, step = 54100 (42.924 sec)\n","I0120 02:56:12.617606 140441056839552 basic_session_run_hooks.py:260] loss = 1.7637995, step = 54100 (42.924 sec)\n","INFO:tensorflow:global_step/sec: 2.29054\n","I0120 02:56:56.274517 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29054\n","INFO:tensorflow:loss = 1.635466, step = 54200 (43.659 sec)\n","I0120 02:56:56.276181 140441056839552 basic_session_run_hooks.py:260] loss = 1.635466, step = 54200 (43.659 sec)\n","INFO:tensorflow:global_step/sec: 2.29503\n","I0120 02:57:39.847014 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29503\n","INFO:tensorflow:loss = 1.8357153, step = 54300 (43.572 sec)\n","I0120 02:57:39.848195 140441056839552 basic_session_run_hooks.py:260] loss = 1.8357153, step = 54300 (43.572 sec)\n","INFO:tensorflow:Saving checkpoints for 54326 into training/log/model.ckpt.\n","I0120 02:57:50.615225 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 54326 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 02:57:52.980361 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:57:55.044834 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:57:55.119265 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:57:55.201777 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:57:55.276363 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:57:55.355351 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 02:57:55.429767 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 02:57:57.162763 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T02:57:57Z\n","I0120 02:57:57.178337 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T02:57:57Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 02:57:57.686010 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 02:57:57.686842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:57:57.687185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 02:57:57.687294: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 02:57:57.687343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 02:57:57.687393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 02:57:57.687421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 02:57:57.687495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 02:57:57.687548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 02:57:57.687585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 02:57:57.687738: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:57:57.688189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:57:57.688513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 02:57:57.688787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 02:57:57.688807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 02:57:57.688816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 02:57:57.688965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:57:57.689265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 02:57:57.689485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-54326\n","I0120 02:57:57.691769 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-54326\n","INFO:tensorflow:Running local_init_op.\n","I0120 02:57:58.817317 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 02:57:58.959146 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 02:58:02.584399 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 02:58:02.584906 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 02:58:02.589195 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.58s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.354\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.798\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.289\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.151\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.459\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.277\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.425\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.429\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.226\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.522\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.650\n","INFO:tensorflow:Finished evaluation at 2020-01-20-02:58:03\n","I0120 02:58:03.310620 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-02:58:03\n","INFO:tensorflow:Saving dict for global step 54326: DetectionBoxes_Precision/mAP = 0.3544559, DetectionBoxes_Precision/mAP (large) = 0.65049505, DetectionBoxes_Precision/mAP (medium) = 0.4586175, DetectionBoxes_Precision/mAP (small) = 0.15120758, DetectionBoxes_Precision/mAP@.50IOU = 0.7984133, DetectionBoxes_Precision/mAP@.75IOU = 0.2894398, DetectionBoxes_Recall/AR@1 = 0.27714285, DetectionBoxes_Recall/AR@10 = 0.4247619, DetectionBoxes_Recall/AR@100 = 0.42857143, DetectionBoxes_Recall/AR@100 (large) = 0.65, DetectionBoxes_Recall/AR@100 (medium) = 0.5217391, DetectionBoxes_Recall/AR@100 (small) = 0.22647059, Loss/classification_loss = 7.209858, Loss/localization_loss = 1.4090381, Loss/regularization_loss = 0.31950745, Loss/total_loss = 8.938403, global_step = 54326, learning_rate = 0.004, loss = 8.938403\n","I0120 02:58:03.310883 140441056839552 estimator.py:2049] Saving dict for global step 54326: DetectionBoxes_Precision/mAP = 0.3544559, DetectionBoxes_Precision/mAP (large) = 0.65049505, DetectionBoxes_Precision/mAP (medium) = 0.4586175, DetectionBoxes_Precision/mAP (small) = 0.15120758, DetectionBoxes_Precision/mAP@.50IOU = 0.7984133, DetectionBoxes_Precision/mAP@.75IOU = 0.2894398, DetectionBoxes_Recall/AR@1 = 0.27714285, DetectionBoxes_Recall/AR@10 = 0.4247619, DetectionBoxes_Recall/AR@100 = 0.42857143, DetectionBoxes_Recall/AR@100 (large) = 0.65, DetectionBoxes_Recall/AR@100 (medium) = 0.5217391, DetectionBoxes_Recall/AR@100 (small) = 0.22647059, Loss/classification_loss = 7.209858, Loss/localization_loss = 1.4090381, Loss/regularization_loss = 0.31950745, Loss/total_loss = 8.938403, global_step = 54326, learning_rate = 0.004, loss = 8.938403\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 54326: training/log/model.ckpt-54326\n","I0120 02:58:03.313644 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 54326: training/log/model.ckpt-54326\n","INFO:tensorflow:global_step/sec: 1.78571\n","I0120 02:58:35.847213 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.78571\n","INFO:tensorflow:loss = 1.3967979, step = 54400 (56.000 sec)\n","I0120 02:58:35.848164 140441056839552 basic_session_run_hooks.py:260] loss = 1.3967979, step = 54400 (56.000 sec)\n","INFO:tensorflow:global_step/sec: 2.30226\n","I0120 02:59:19.282838 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30226\n","INFO:tensorflow:loss = 1.7031376, step = 54500 (43.436 sec)\n","I0120 02:59:19.284349 140441056839552 basic_session_run_hooks.py:260] loss = 1.7031376, step = 54500 (43.436 sec)\n","INFO:tensorflow:global_step/sec: 2.27902\n","I0120 03:00:03.161409 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.27902\n","INFO:tensorflow:loss = 1.5663892, step = 54600 (43.878 sec)\n","I0120 03:00:03.162375 140441056839552 basic_session_run_hooks.py:260] loss = 1.5663892, step = 54600 (43.878 sec)\n","INFO:tensorflow:global_step/sec: 2.31704\n","I0120 03:00:46.319919 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31704\n","INFO:tensorflow:loss = 1.7894614, step = 54700 (43.159 sec)\n","I0120 03:00:46.320924 140441056839552 basic_session_run_hooks.py:260] loss = 1.7894614, step = 54700 (43.159 sec)\n","INFO:tensorflow:global_step/sec: 2.31112\n","I0120 03:01:29.588971 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31112\n","INFO:tensorflow:loss = 1.9324363, step = 54800 (43.270 sec)\n","I0120 03:01:29.590575 140441056839552 basic_session_run_hooks.py:260] loss = 1.9324363, step = 54800 (43.270 sec)\n","INFO:tensorflow:global_step/sec: 2.31833\n","I0120 03:02:12.723626 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31833\n","INFO:tensorflow:loss = 2.1130576, step = 54900 (43.134 sec)\n","I0120 03:02:12.724705 140441056839552 basic_session_run_hooks.py:260] loss = 2.1130576, step = 54900 (43.134 sec)\n","INFO:tensorflow:global_step/sec: 2.31389\n","I0120 03:02:55.940807 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31389\n","INFO:tensorflow:loss = 1.2278179, step = 55000 (43.217 sec)\n","I0120 03:02:55.941702 140441056839552 basic_session_run_hooks.py:260] loss = 1.2278179, step = 55000 (43.217 sec)\n","INFO:tensorflow:global_step/sec: 2.30185\n","I0120 03:03:39.384227 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30185\n","INFO:tensorflow:loss = 1.3685433, step = 55100 (43.444 sec)\n","I0120 03:03:39.385566 140441056839552 basic_session_run_hooks.py:260] loss = 1.3685433, step = 55100 (43.444 sec)\n","INFO:tensorflow:global_step/sec: 2.32315\n","I0120 03:04:22.429267 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32315\n","INFO:tensorflow:loss = 1.1900615, step = 55200 (43.045 sec)\n","I0120 03:04:22.430183 140441056839552 basic_session_run_hooks.py:260] loss = 1.1900615, step = 55200 (43.045 sec)\n","INFO:tensorflow:global_step/sec: 2.32177\n","I0120 03:05:05.499802 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32177\n","INFO:tensorflow:loss = 1.3358293, step = 55300 (43.071 sec)\n","I0120 03:05:05.500695 140441056839552 basic_session_run_hooks.py:260] loss = 1.3358293, step = 55300 (43.071 sec)\n","INFO:tensorflow:global_step/sec: 2.30774\n","I0120 03:05:48.832244 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30774\n","INFO:tensorflow:loss = 1.3607498, step = 55400 (43.333 sec)\n","I0120 03:05:48.833874 140441056839552 basic_session_run_hooks.py:260] loss = 1.3607498, step = 55400 (43.333 sec)\n","INFO:tensorflow:global_step/sec: 2.32006\n","I0120 03:06:31.934602 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32006\n","INFO:tensorflow:loss = 2.5869408, step = 55500 (43.102 sec)\n","I0120 03:06:31.935664 140441056839552 basic_session_run_hooks.py:260] loss = 2.5869408, step = 55500 (43.102 sec)\n","INFO:tensorflow:global_step/sec: 2.28678\n","I0120 03:07:15.664253 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28678\n","INFO:tensorflow:loss = 1.9844083, step = 55600 (43.730 sec)\n","I0120 03:07:15.665371 140441056839552 basic_session_run_hooks.py:260] loss = 1.9844083, step = 55600 (43.730 sec)\n","INFO:tensorflow:Saving checkpoints for 55682 into training/log/model.ckpt.\n","I0120 03:07:50.880979 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 55682 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 03:07:53.206689 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:07:55.336243 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:07:55.411383 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:07:55.493071 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:07:55.566875 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:07:55.645597 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:07:55.719141 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 03:07:57.095019 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T03:07:57Z\n","I0120 03:07:57.118041 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T03:07:57Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 03:07:57.664214 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 03:07:57.664878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:07:57.665213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 03:07:57.665302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 03:07:57.665318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 03:07:57.665331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 03:07:57.665344: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 03:07:57.665357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 03:07:57.665371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 03:07:57.665385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 03:07:57.665477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:07:57.665764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:07:57.665971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 03:07:57.666041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 03:07:57.666052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 03:07:57.666073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 03:07:57.666189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:07:57.666458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:07:57.666682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-55682\n","I0120 03:07:57.669478 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-55682\n","INFO:tensorflow:Running local_init_op.\n","I0120 03:07:58.794079 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 03:07:58.937662 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 03:08:02.506875 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 03:08:02.509171 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 03:08:02.513805 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.59s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.336\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.794\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.204\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.178\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.413\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.260\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.399\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.414\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.268\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.483\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550\n","INFO:tensorflow:Finished evaluation at 2020-01-20-03:08:03\n","I0120 03:08:03.237203 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-03:08:03\n","INFO:tensorflow:Saving dict for global step 55682: DetectionBoxes_Precision/mAP = 0.33558238, DetectionBoxes_Precision/mAP (large) = 0.550495, DetectionBoxes_Precision/mAP (medium) = 0.41347456, DetectionBoxes_Precision/mAP (small) = 0.17770028, DetectionBoxes_Precision/mAP@.50IOU = 0.7943212, DetectionBoxes_Precision/mAP@.75IOU = 0.20400503, DetectionBoxes_Recall/AR@1 = 0.26, DetectionBoxes_Recall/AR@10 = 0.3990476, DetectionBoxes_Recall/AR@100 = 0.41428572, DetectionBoxes_Recall/AR@100 (large) = 0.55, DetectionBoxes_Recall/AR@100 (medium) = 0.4826087, DetectionBoxes_Recall/AR@100 (small) = 0.26764706, Loss/classification_loss = 7.5022764, Loss/localization_loss = 1.4818184, Loss/regularization_loss = 0.319786, Loss/total_loss = 9.303881, global_step = 55682, learning_rate = 0.004, loss = 9.303881\n","I0120 03:08:03.237465 140441056839552 estimator.py:2049] Saving dict for global step 55682: DetectionBoxes_Precision/mAP = 0.33558238, DetectionBoxes_Precision/mAP (large) = 0.550495, DetectionBoxes_Precision/mAP (medium) = 0.41347456, DetectionBoxes_Precision/mAP (small) = 0.17770028, DetectionBoxes_Precision/mAP@.50IOU = 0.7943212, DetectionBoxes_Precision/mAP@.75IOU = 0.20400503, DetectionBoxes_Recall/AR@1 = 0.26, DetectionBoxes_Recall/AR@10 = 0.3990476, DetectionBoxes_Recall/AR@100 = 0.41428572, DetectionBoxes_Recall/AR@100 (large) = 0.55, DetectionBoxes_Recall/AR@100 (medium) = 0.4826087, DetectionBoxes_Recall/AR@100 (small) = 0.26764706, Loss/classification_loss = 7.5022764, Loss/localization_loss = 1.4818184, Loss/regularization_loss = 0.319786, Loss/total_loss = 9.303881, global_step = 55682, learning_rate = 0.004, loss = 9.303881\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 55682: training/log/model.ckpt-55682\n","I0120 03:08:03.241048 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 55682: training/log/model.ckpt-55682\n","INFO:tensorflow:global_step/sec: 1.79375\n","I0120 03:08:11.413214 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.79375\n","INFO:tensorflow:loss = 1.2157044, step = 55700 (55.749 sec)\n","I0120 03:08:11.414119 140441056839552 basic_session_run_hooks.py:260] loss = 1.2157044, step = 55700 (55.749 sec)\n","INFO:tensorflow:global_step/sec: 2.30703\n","I0120 03:08:54.758912 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30703\n","INFO:tensorflow:loss = 2.350088, step = 55800 (43.346 sec)\n","I0120 03:08:54.759939 140441056839552 basic_session_run_hooks.py:260] loss = 2.350088, step = 55800 (43.346 sec)\n","INFO:tensorflow:global_step/sec: 2.29077\n","I0120 03:09:38.412431 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29077\n","INFO:tensorflow:loss = 2.1483243, step = 55900 (43.654 sec)\n","I0120 03:09:38.413446 140441056839552 basic_session_run_hooks.py:260] loss = 2.1483243, step = 55900 (43.654 sec)\n","INFO:tensorflow:global_step/sec: 2.32871\n","I0120 03:10:21.354702 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32871\n","INFO:tensorflow:loss = 1.4245979, step = 56000 (42.943 sec)\n","I0120 03:10:21.356088 140441056839552 basic_session_run_hooks.py:260] loss = 1.4245979, step = 56000 (42.943 sec)\n","INFO:tensorflow:global_step/sec: 2.31988\n","I0120 03:11:04.460299 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31988\n","INFO:tensorflow:loss = 1.5165749, step = 56100 (43.105 sec)\n","I0120 03:11:04.461227 140441056839552 basic_session_run_hooks.py:260] loss = 1.5165749, step = 56100 (43.105 sec)\n","INFO:tensorflow:global_step/sec: 2.30351\n","I0120 03:11:47.872343 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30351\n","INFO:tensorflow:loss = 1.4455338, step = 56200 (43.412 sec)\n","I0120 03:11:47.873284 140441056839552 basic_session_run_hooks.py:260] loss = 1.4455338, step = 56200 (43.412 sec)\n","INFO:tensorflow:global_step/sec: 2.30797\n","I0120 03:12:31.200508 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30797\n","INFO:tensorflow:loss = 2.2667, step = 56300 (43.329 sec)\n","I0120 03:12:31.202165 140441056839552 basic_session_run_hooks.py:260] loss = 2.2667, step = 56300 (43.329 sec)\n","INFO:tensorflow:global_step/sec: 2.30673\n","I0120 03:13:14.551942 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30673\n","INFO:tensorflow:loss = 1.7219086, step = 56400 (43.351 sec)\n","I0120 03:13:14.552873 140441056839552 basic_session_run_hooks.py:260] loss = 1.7219086, step = 56400 (43.351 sec)\n","INFO:tensorflow:global_step/sec: 2.31709\n","I0120 03:13:57.709549 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31709\n","INFO:tensorflow:loss = 1.8313637, step = 56500 (43.158 sec)\n","I0120 03:13:57.710463 140441056839552 basic_session_run_hooks.py:260] loss = 1.8313637, step = 56500 (43.158 sec)\n","INFO:tensorflow:global_step/sec: 2.31824\n","I0120 03:14:40.845683 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31824\n","INFO:tensorflow:loss = 1.6817853, step = 56600 (43.137 sec)\n","I0120 03:14:40.847439 140441056839552 basic_session_run_hooks.py:260] loss = 1.6817853, step = 56600 (43.137 sec)\n","INFO:tensorflow:global_step/sec: 2.31251\n","I0120 03:15:24.088654 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31251\n","INFO:tensorflow:loss = 1.6454707, step = 56700 (43.242 sec)\n","I0120 03:15:24.089709 140441056839552 basic_session_run_hooks.py:260] loss = 1.6454707, step = 56700 (43.242 sec)\n","INFO:tensorflow:global_step/sec: 2.32615\n","I0120 03:16:07.078266 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32615\n","INFO:tensorflow:loss = 1.7151436, step = 56800 (42.990 sec)\n","I0120 03:16:07.079473 140441056839552 basic_session_run_hooks.py:260] loss = 1.7151436, step = 56800 (42.990 sec)\n","INFO:tensorflow:global_step/sec: 2.321\n","I0120 03:16:50.163144 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.321\n","INFO:tensorflow:loss = 2.0493088, step = 56900 (43.085 sec)\n","I0120 03:16:50.164802 140441056839552 basic_session_run_hooks.py:260] loss = 2.0493088, step = 56900 (43.085 sec)\n","INFO:tensorflow:global_step/sec: 2.30918\n","I0120 03:17:33.468602 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30918\n","INFO:tensorflow:loss = 2.0376604, step = 57000 (43.305 sec)\n","I0120 03:17:33.469686 140441056839552 basic_session_run_hooks.py:260] loss = 2.0376604, step = 57000 (43.305 sec)\n","INFO:tensorflow:Saving checkpoints for 57042 into training/log/model.ckpt.\n","I0120 03:17:51.212794 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 57042 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 03:17:53.537621 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:17:55.665723 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:17:55.745688 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:17:55.834297 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:17:55.915210 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:17:55.994487 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:17:56.494442 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 03:17:58.002993 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T03:17:58Z\n","I0120 03:17:58.019805 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T03:17:58Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 03:17:58.532725 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 03:17:58.533435: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:17:58.533729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 03:17:58.533811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 03:17:58.533827: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 03:17:58.533840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 03:17:58.533853: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 03:17:58.533866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 03:17:58.533878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 03:17:58.533892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 03:17:58.533982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:17:58.534323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:17:58.534555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 03:17:58.534590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 03:17:58.534600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 03:17:58.534608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 03:17:58.534710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:17:58.534976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:17:58.535209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-57042\n","I0120 03:17:58.537483 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-57042\n","INFO:tensorflow:Running local_init_op.\n","I0120 03:17:59.649336 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 03:17:59.783621 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 03:18:03.463797 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 03:18:03.464386 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 03:18:03.469049 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.53s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.317\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.760\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.202\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.180\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.392\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.256\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.401\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.412\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.291\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.350\n","INFO:tensorflow:Finished evaluation at 2020-01-20-03:18:04\n","I0120 03:18:04.138186 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-03:18:04\n","INFO:tensorflow:Saving dict for global step 57042: DetectionBoxes_Precision/mAP = 0.31737092, DetectionBoxes_Precision/mAP (large) = 0.35049504, DetectionBoxes_Precision/mAP (medium) = 0.39172053, DetectionBoxes_Precision/mAP (small) = 0.17951281, DetectionBoxes_Precision/mAP@.50IOU = 0.7596144, DetectionBoxes_Precision/mAP@.75IOU = 0.20156156, DetectionBoxes_Recall/AR@1 = 0.25619048, DetectionBoxes_Recall/AR@10 = 0.40095237, DetectionBoxes_Recall/AR@100 = 0.41238096, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = 0.47391304, DetectionBoxes_Recall/AR@100 (small) = 0.29117647, Loss/classification_loss = 8.257516, Loss/localization_loss = 1.5194488, Loss/regularization_loss = 0.32008952, Loss/total_loss = 10.097053, global_step = 57042, learning_rate = 0.004, loss = 10.097053\n","I0120 03:18:04.138481 140441056839552 estimator.py:2049] Saving dict for global step 57042: DetectionBoxes_Precision/mAP = 0.31737092, DetectionBoxes_Precision/mAP (large) = 0.35049504, DetectionBoxes_Precision/mAP (medium) = 0.39172053, DetectionBoxes_Precision/mAP (small) = 0.17951281, DetectionBoxes_Precision/mAP@.50IOU = 0.7596144, DetectionBoxes_Precision/mAP@.75IOU = 0.20156156, DetectionBoxes_Recall/AR@1 = 0.25619048, DetectionBoxes_Recall/AR@10 = 0.40095237, DetectionBoxes_Recall/AR@100 = 0.41238096, DetectionBoxes_Recall/AR@100 (large) = 0.35, DetectionBoxes_Recall/AR@100 (medium) = 0.47391304, DetectionBoxes_Recall/AR@100 (small) = 0.29117647, Loss/classification_loss = 8.257516, Loss/localization_loss = 1.5194488, Loss/regularization_loss = 0.32008952, Loss/total_loss = 10.097053, global_step = 57042, learning_rate = 0.004, loss = 10.097053\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 57042: training/log/model.ckpt-57042\n","I0120 03:18:04.141321 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 57042: training/log/model.ckpt-57042\n","INFO:tensorflow:global_step/sec: 1.7767\n","I0120 03:18:29.752729 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.7767\n","INFO:tensorflow:loss = 1.5670984, step = 57100 (56.284 sec)\n","I0120 03:18:29.753687 140441056839552 basic_session_run_hooks.py:260] loss = 1.5670984, step = 57100 (56.284 sec)\n","INFO:tensorflow:global_step/sec: 2.29996\n","I0120 03:19:13.231813 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29996\n","INFO:tensorflow:loss = 1.9578916, step = 57200 (43.480 sec)\n","I0120 03:19:13.233240 140441056839552 basic_session_run_hooks.py:260] loss = 1.9578916, step = 57200 (43.480 sec)\n","INFO:tensorflow:global_step/sec: 2.29887\n","I0120 03:19:56.731449 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29887\n","INFO:tensorflow:loss = 1.5755435, step = 57300 (43.499 sec)\n","I0120 03:19:56.732387 140441056839552 basic_session_run_hooks.py:260] loss = 1.5755435, step = 57300 (43.499 sec)\n","INFO:tensorflow:global_step/sec: 2.31801\n","I0120 03:20:39.871958 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31801\n","INFO:tensorflow:loss = 1.6540389, step = 57400 (43.141 sec)\n","I0120 03:20:39.872974 140441056839552 basic_session_run_hooks.py:260] loss = 1.6540389, step = 57400 (43.141 sec)\n","INFO:tensorflow:global_step/sec: 2.31289\n","I0120 03:21:23.107971 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31289\n","INFO:tensorflow:loss = 2.6236193, step = 57500 (43.236 sec)\n","I0120 03:21:23.109396 140441056839552 basic_session_run_hooks.py:260] loss = 2.6236193, step = 57500 (43.236 sec)\n","INFO:tensorflow:global_step/sec: 2.29981\n","I0120 03:22:06.589846 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29981\n","INFO:tensorflow:loss = 2.2321796, step = 57600 (43.481 sec)\n","I0120 03:22:06.590893 140441056839552 basic_session_run_hooks.py:260] loss = 2.2321796, step = 57600 (43.481 sec)\n","INFO:tensorflow:global_step/sec: 2.30181\n","I0120 03:22:50.033912 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30181\n","INFO:tensorflow:loss = 1.9872212, step = 57700 (43.444 sec)\n","I0120 03:22:50.034945 140441056839552 basic_session_run_hooks.py:260] loss = 1.9872212, step = 57700 (43.444 sec)\n","INFO:tensorflow:global_step/sec: 2.30155\n","I0120 03:23:33.483014 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30155\n","INFO:tensorflow:loss = 1.654615, step = 57800 (43.450 sec)\n","I0120 03:23:33.485013 140441056839552 basic_session_run_hooks.py:260] loss = 1.654615, step = 57800 (43.450 sec)\n","INFO:tensorflow:global_step/sec: 2.30144\n","I0120 03:24:16.934001 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30144\n","INFO:tensorflow:loss = 1.8917216, step = 57900 (43.450 sec)\n","I0120 03:24:16.935128 140441056839552 basic_session_run_hooks.py:260] loss = 1.8917216, step = 57900 (43.450 sec)\n","INFO:tensorflow:global_step/sec: 2.28527\n","I0120 03:25:00.692563 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28527\n","INFO:tensorflow:loss = 1.8217312, step = 58000 (43.758 sec)\n","I0120 03:25:00.693591 140441056839552 basic_session_run_hooks.py:260] loss = 1.8217312, step = 58000 (43.758 sec)\n","INFO:tensorflow:global_step/sec: 2.28686\n","I0120 03:25:44.420687 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.28686\n","INFO:tensorflow:loss = 1.7816892, step = 58100 (43.729 sec)\n","I0120 03:25:44.422229 140441056839552 basic_session_run_hooks.py:260] loss = 1.7816892, step = 58100 (43.729 sec)\n","INFO:tensorflow:global_step/sec: 2.31712\n","I0120 03:26:27.577646 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31712\n","INFO:tensorflow:loss = 1.3666582, step = 58200 (43.156 sec)\n","I0120 03:26:27.578568 140441056839552 basic_session_run_hooks.py:260] loss = 1.3666582, step = 58200 (43.156 sec)\n","INFO:tensorflow:global_step/sec: 2.3193\n","I0120 03:27:10.694158 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3193\n","INFO:tensorflow:loss = 1.5564871, step = 58300 (43.117 sec)\n","I0120 03:27:10.695140 140441056839552 basic_session_run_hooks.py:260] loss = 1.5564871, step = 58300 (43.117 sec)\n","INFO:tensorflow:Saving checkpoints for 58394 into training/log/model.ckpt.\n","I0120 03:27:51.226862 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 58394 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 03:27:53.570070 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:27:55.644430 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:27:55.718883 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:27:55.811256 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:27:55.895655 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:27:55.976737 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:27:56.051040 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 03:27:57.418321 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T03:27:57Z\n","I0120 03:27:57.433190 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T03:27:57Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 03:27:57.987956 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 03:27:57.988806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:27:57.989157: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 03:27:57.989248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 03:27:57.989264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 03:27:57.989277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 03:27:57.989290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 03:27:57.989306: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 03:27:57.989319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 03:27:57.989333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 03:27:57.989427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:27:57.989710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:27:57.989917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 03:27:57.990163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 03:27:57.990179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 03:27:57.990191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 03:27:57.990452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:27:57.990935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:27:57.991191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-58394\n","I0120 03:27:57.993495 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-58394\n","INFO:tensorflow:Running local_init_op.\n","I0120 03:27:59.113905 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 03:27:59.258220 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 03:28:02.914332 140437393839872 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 03:28:02.915108 140437393839872 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 03:28:02.918612 140437393839872 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.53s).\n","Accumulating evaluation results...\n","DONE (t=0.04s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.786\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.211\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.136\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.427\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.265\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.409\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.416\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.218\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.510\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.550\n","INFO:tensorflow:Finished evaluation at 2020-01-20-03:28:03\n","I0120 03:28:03.585567 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-03:28:03\n","INFO:tensorflow:Saving dict for global step 58394: DetectionBoxes_Precision/mAP = 0.3277931, DetectionBoxes_Precision/mAP (large) = 0.550495, DetectionBoxes_Precision/mAP (medium) = 0.4268714, DetectionBoxes_Precision/mAP (small) = 0.13559523, DetectionBoxes_Precision/mAP@.50IOU = 0.7863656, DetectionBoxes_Precision/mAP@.75IOU = 0.21130855, DetectionBoxes_Recall/AR@1 = 0.2647619, DetectionBoxes_Recall/AR@10 = 0.40857142, DetectionBoxes_Recall/AR@100 = 0.41619048, DetectionBoxes_Recall/AR@100 (large) = 0.55, DetectionBoxes_Recall/AR@100 (medium) = 0.51014495, DetectionBoxes_Recall/AR@100 (small) = 0.21764706, Loss/classification_loss = 6.5578547, Loss/localization_loss = 1.492854, Loss/regularization_loss = 0.32033408, Loss/total_loss = 8.371041, global_step = 58394, learning_rate = 0.004, loss = 8.371041\n","I0120 03:28:03.585799 140441056839552 estimator.py:2049] Saving dict for global step 58394: DetectionBoxes_Precision/mAP = 0.3277931, DetectionBoxes_Precision/mAP (large) = 0.550495, DetectionBoxes_Precision/mAP (medium) = 0.4268714, DetectionBoxes_Precision/mAP (small) = 0.13559523, DetectionBoxes_Precision/mAP@.50IOU = 0.7863656, DetectionBoxes_Precision/mAP@.75IOU = 0.21130855, DetectionBoxes_Recall/AR@1 = 0.2647619, DetectionBoxes_Recall/AR@10 = 0.40857142, DetectionBoxes_Recall/AR@100 = 0.41619048, DetectionBoxes_Recall/AR@100 (large) = 0.55, DetectionBoxes_Recall/AR@100 (medium) = 0.51014495, DetectionBoxes_Recall/AR@100 (small) = 0.21764706, Loss/classification_loss = 6.5578547, Loss/localization_loss = 1.492854, Loss/regularization_loss = 0.32033408, Loss/total_loss = 8.371041, global_step = 58394, learning_rate = 0.004, loss = 8.371041\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 58394: training/log/model.ckpt-58394\n","I0120 03:28:03.588684 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 58394: training/log/model.ckpt-58394\n","INFO:tensorflow:global_step/sec: 1.78398\n","I0120 03:28:06.748462 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 1.78398\n","INFO:tensorflow:loss = 1.3885378, step = 58400 (56.054 sec)\n","I0120 03:28:06.749425 140441056839552 basic_session_run_hooks.py:260] loss = 1.3885378, step = 58400 (56.054 sec)\n","INFO:tensorflow:global_step/sec: 2.30424\n","I0120 03:28:50.146725 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30424\n","INFO:tensorflow:loss = 1.8746369, step = 58500 (43.398 sec)\n","I0120 03:28:50.147819 140441056839552 basic_session_run_hooks.py:260] loss = 1.8746369, step = 58500 (43.398 sec)\n","INFO:tensorflow:global_step/sec: 2.32023\n","I0120 03:29:33.245908 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32023\n","INFO:tensorflow:loss = 1.3678279, step = 58600 (43.099 sec)\n","I0120 03:29:33.246995 140441056839552 basic_session_run_hooks.py:260] loss = 1.3678279, step = 58600 (43.099 sec)\n","INFO:tensorflow:global_step/sec: 2.31083\n","I0120 03:30:16.520429 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31083\n","INFO:tensorflow:loss = 2.7828348, step = 58700 (43.275 sec)\n","I0120 03:30:16.521878 140441056839552 basic_session_run_hooks.py:260] loss = 2.7828348, step = 58700 (43.275 sec)\n","INFO:tensorflow:global_step/sec: 2.32543\n","I0120 03:30:59.523262 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.32543\n","INFO:tensorflow:loss = 2.4972498, step = 58800 (43.002 sec)\n","I0120 03:30:59.524345 140441056839552 basic_session_run_hooks.py:260] loss = 2.4972498, step = 58800 (43.002 sec)\n","INFO:tensorflow:global_step/sec: 2.29602\n","I0120 03:31:43.076847 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.29602\n","INFO:tensorflow:loss = 1.905204, step = 58900 (43.554 sec)\n","I0120 03:31:43.077859 140441056839552 basic_session_run_hooks.py:260] loss = 1.905204, step = 58900 (43.554 sec)\n","INFO:tensorflow:global_step/sec: 2.30789\n","I0120 03:32:26.406393 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30789\n","INFO:tensorflow:loss = 1.7551857, step = 59000 (43.330 sec)\n","I0120 03:32:26.407871 140441056839552 basic_session_run_hooks.py:260] loss = 1.7551857, step = 59000 (43.330 sec)\n","INFO:tensorflow:global_step/sec: 2.30732\n","I0120 03:33:09.746633 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30732\n","INFO:tensorflow:loss = 2.004979, step = 59100 (43.340 sec)\n","I0120 03:33:09.747631 140441056839552 basic_session_run_hooks.py:260] loss = 2.004979, step = 59100 (43.340 sec)\n","INFO:tensorflow:global_step/sec: 2.30218\n","I0120 03:33:53.183716 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.30218\n","INFO:tensorflow:loss = 2.1445909, step = 59200 (43.437 sec)\n","I0120 03:33:53.184678 140441056839552 basic_session_run_hooks.py:260] loss = 2.1445909, step = 59200 (43.437 sec)\n","INFO:tensorflow:global_step/sec: 2.31768\n","I0120 03:34:36.330377 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31768\n","INFO:tensorflow:loss = 1.342757, step = 59300 (43.147 sec)\n","I0120 03:34:36.331636 140441056839552 basic_session_run_hooks.py:260] loss = 1.342757, step = 59300 (43.147 sec)\n","INFO:tensorflow:global_step/sec: 2.3202\n","I0120 03:35:19.430051 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3202\n","INFO:tensorflow:loss = 2.2915056, step = 59400 (43.099 sec)\n","I0120 03:35:19.431016 140441056839552 basic_session_run_hooks.py:260] loss = 2.2915056, step = 59400 (43.099 sec)\n","INFO:tensorflow:global_step/sec: 2.31778\n","I0120 03:36:02.574766 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31778\n","INFO:tensorflow:loss = 2.1220145, step = 59500 (43.145 sec)\n","I0120 03:36:02.575740 140441056839552 basic_session_run_hooks.py:260] loss = 2.1220145, step = 59500 (43.145 sec)\n","INFO:tensorflow:global_step/sec: 2.31283\n","I0120 03:36:45.811819 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31283\n","INFO:tensorflow:loss = 1.3479278, step = 59600 (43.238 sec)\n","I0120 03:36:45.813364 140441056839552 basic_session_run_hooks.py:260] loss = 1.3479278, step = 59600 (43.238 sec)\n","INFO:tensorflow:global_step/sec: 2.31305\n","I0120 03:37:29.044703 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.31305\n","INFO:tensorflow:loss = 2.0383499, step = 59700 (43.232 sec)\n","I0120 03:37:29.045690 140441056839552 basic_session_run_hooks.py:260] loss = 2.0383499, step = 59700 (43.232 sec)\n","INFO:tensorflow:Saving checkpoints for 59752 into training/log/model.ckpt.\n","I0120 03:37:51.250674 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 59752 into training/log/model.ckpt.\n","INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (600 secs).\n","I0120 03:37:52.919540 140441056839552 training.py:527] Skip the current checkpoint eval due to throttle secs (600 secs).\n","INFO:tensorflow:global_step/sec: 2.20769\n","I0120 03:38:14.340996 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.20769\n","INFO:tensorflow:loss = 1.6182177, step = 59800 (45.296 sec)\n","I0120 03:38:14.342049 140441056839552 basic_session_run_hooks.py:260] loss = 1.6182177, step = 59800 (45.296 sec)\n","INFO:tensorflow:global_step/sec: 2.3119\n","I0120 03:38:57.595459 140441056839552 basic_session_run_hooks.py:692] global_step/sec: 2.3119\n","INFO:tensorflow:loss = 1.6471508, step = 59900 (43.255 sec)\n","I0120 03:38:57.596922 140441056839552 basic_session_run_hooks.py:260] loss = 1.6471508, step = 59900 (43.255 sec)\n","INFO:tensorflow:Saving checkpoints for 60000 into training/log/model.ckpt.\n","I0120 03:39:40.645707 140441056839552 basic_session_run_hooks.py:606] Saving checkpoints for 60000 into training/log/model.ckpt.\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","INFO:tensorflow:Calling model_fn.\n","I0120 03:39:43.023858 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:45.558271 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:45.635045 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:45.718424 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:45.802581 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:45.877351 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:45.952145 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","Loading...\n","INFO:tensorflow:Done calling model_fn.\n","I0120 03:39:47.326934 140441056839552 estimator.py:1150] Done calling model_fn.\n","INFO:tensorflow:Starting evaluation at 2020-01-20T03:39:47Z\n","I0120 03:39:47.341838 140441056839552 evaluation.py:255] Starting evaluation at 2020-01-20T03:39:47Z\n","INFO:tensorflow:Graph was finalized.\n","I0120 03:39:47.831931 140441056839552 monitored_session.py:240] Graph was finalized.\n","2020-01-20 03:39:47.832622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:39:47.832898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 03:39:47.832985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 03:39:47.833001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 03:39:47.833016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 03:39:47.833029: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 03:39:47.833042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 03:39:47.833078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 03:39:47.833110: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 03:39:47.833207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:39:47.833495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:39:47.833704: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 03:39:47.833771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 03:39:47.833781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 03:39:47.833790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 03:39:47.833899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:39:47.834189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:39:47.834409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-60000\n","I0120 03:39:47.836600 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-60000\n","INFO:tensorflow:Running local_init_op.\n","I0120 03:39:49.050952 140441056839552 session_manager.py:500] Running local_init_op.\n","INFO:tensorflow:Done running local_init_op.\n","I0120 03:39:49.191617 140441056839552 session_manager.py:502] Done running local_init_op.\n","INFO:tensorflow:Performing evaluation on 62 images.\n","I0120 03:39:52.835850 140437385447168 coco_evaluation.py:205] Performing evaluation on 62 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0120 03:39:52.836460 140437385447168 coco_tools.py:115] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0120 03:39:52.840622 140437385447168 coco_tools.py:137] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.54s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.806\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.273\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.194\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.418\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.701\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.268\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.423\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.441\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.300\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.503\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.700\n","INFO:tensorflow:Finished evaluation at 2020-01-20-03:39:53\n","I0120 03:39:53.525411 140441056839552 evaluation.py:275] Finished evaluation at 2020-01-20-03:39:53\n","INFO:tensorflow:Saving dict for global step 60000: DetectionBoxes_Precision/mAP = 0.34862772, DetectionBoxes_Precision/mAP (large) = 0.7009901, DetectionBoxes_Precision/mAP (medium) = 0.41797927, DetectionBoxes_Precision/mAP (small) = 0.19380079, DetectionBoxes_Precision/mAP@.50IOU = 0.8062001, DetectionBoxes_Precision/mAP@.75IOU = 0.27345467, DetectionBoxes_Recall/AR@1 = 0.26761904, DetectionBoxes_Recall/AR@10 = 0.42285714, DetectionBoxes_Recall/AR@100 = 0.4409524, DetectionBoxes_Recall/AR@100 (large) = 0.7, DetectionBoxes_Recall/AR@100 (medium) = 0.5028986, DetectionBoxes_Recall/AR@100 (small) = 0.3, Loss/classification_loss = 7.218647, Loss/localization_loss = 1.4059654, Loss/regularization_loss = 0.32065386, Loss/total_loss = 8.945269, global_step = 60000, learning_rate = 0.004, loss = 8.945269\n","I0120 03:39:53.525652 140441056839552 estimator.py:2049] Saving dict for global step 60000: DetectionBoxes_Precision/mAP = 0.34862772, DetectionBoxes_Precision/mAP (large) = 0.7009901, DetectionBoxes_Precision/mAP (medium) = 0.41797927, DetectionBoxes_Precision/mAP (small) = 0.19380079, DetectionBoxes_Precision/mAP@.50IOU = 0.8062001, DetectionBoxes_Precision/mAP@.75IOU = 0.27345467, DetectionBoxes_Recall/AR@1 = 0.26761904, DetectionBoxes_Recall/AR@10 = 0.42285714, DetectionBoxes_Recall/AR@100 = 0.4409524, DetectionBoxes_Recall/AR@100 (large) = 0.7, DetectionBoxes_Recall/AR@100 (medium) = 0.5028986, DetectionBoxes_Recall/AR@100 (small) = 0.3, Loss/classification_loss = 7.218647, Loss/localization_loss = 1.4059654, Loss/regularization_loss = 0.32065386, Loss/total_loss = 8.945269, global_step = 60000, learning_rate = 0.004, loss = 8.945269\n","INFO:tensorflow:Saving 'checkpoint_path' summary for global step 60000: training/log/model.ckpt-60000\n","I0120 03:39:53.528793 140441056839552 estimator.py:2109] Saving 'checkpoint_path' summary for global step 60000: training/log/model.ckpt-60000\n","INFO:tensorflow:Performing the final export in the end of training.\n","I0120 03:39:53.529695 140441056839552 exporter.py:410] Performing the final export in the end of training.\n","WARNING:tensorflow:From /content/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0120 03:39:53.535563 140441056839552 module_wrapper.py:139] From /content/models/research/object_detection/inputs.py:750: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","INFO:tensorflow:Calling model_fn.\n","I0120 03:39:53.760644 140441056839552 estimator.py:1148] Calling model_fn.\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:55.796755 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:55.873359 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:55.958992 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:56.038741 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:56.115709 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0120 03:39:56.193171 140441056839552 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","W0120 03:39:56.613889 140441056839552 module_wrapper.py:139] From /content/models/research/object_detection/model_lib.py:426: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","INFO:tensorflow:Done calling model_fn.\n","I0120 03:39:56.901885 140441056839552 estimator.py:1150] Done calling model_fn.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0120 03:39:56.902133 140441056839552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n","I0120 03:39:56.902699 140441056839552 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n","INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n","I0120 03:39:56.902794 140441056839552 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n","INFO:tensorflow:Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","I0120 03:39:56.902848 140441056839552 export_utils.py:170] Signatures INCLUDED in export for Predict: ['tensorflow/serving/predict', 'serving_default']\n","INFO:tensorflow:Signatures INCLUDED in export for Train: None\n","I0120 03:39:56.902892 140441056839552 export_utils.py:170] Signatures INCLUDED in export for Train: None\n","INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n","I0120 03:39:56.902932 140441056839552 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n","2020-01-20 03:39:56.903396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:39:56.903673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 03:39:56.903744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-20 03:39:56.903759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-20 03:39:56.903772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-20 03:39:56.903785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-20 03:39:56.903798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-20 03:39:56.903810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-20 03:39:56.903823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 03:39:56.903911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:39:56.904240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:39:56.904454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 03:39:56.904493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 03:39:56.904503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 03:39:56.904511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 03:39:56.904611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:39:56.904877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 03:39:56.905109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","INFO:tensorflow:Restoring parameters from training/log/model.ckpt-60000\n","I0120 03:39:56.908633 140441056839552 saver.py:1284] Restoring parameters from training/log/model.ckpt-60000\n","INFO:tensorflow:Assets added to graph.\n","I0120 03:39:57.450366 140441056839552 builder_impl.py:665] Assets added to graph.\n","INFO:tensorflow:No assets to write.\n","I0120 03:39:57.450576 140441056839552 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: training/log/export/Servo/temp-b'1579491593'/saved_model.pb\n","I0120 03:39:58.282142 140441056839552 builder_impl.py:425] SavedModel written to: training/log/export/Servo/temp-b'1579491593'/saved_model.pb\n","INFO:tensorflow:Loss for final step: 1.8736447.\n","I0120 03:39:58.732803 140441056839552 estimator.py:371] Loss for final step: 1.8736447.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"smfpYe34eYzn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XBCKfts3ZtFn","colab_type":"code","outputId":"9a09578f-a04f-4187-d52c-bb18308e0e42","executionInfo":{"status":"ok","timestamp":1579475988069,"user_tz":360,"elapsed":66017,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%cd /content/drive/My Drive/Colab Notebooks/EnemyDetection\n","shutil.copyfile(\"/content/models/research/object_detection/legacy/eval.py\", \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/eval.py\")\n","# If model_main does not update evaluation directory for Tensorboard, you can use this. \n","# python object_detection/legacy/eval.py --logtostderr \\ \n","#  --pipeline_config_path=<path to pipeline.config for trained model> \\\n","#  --checkpoint_dir=<directory containing model checkpoints> \\\n","#  --eval_dir=<output directory for eval files to be read by tensorboard>\n","!python \"eval.py\" --logtostderr  --pipeline_config_path=\"training/ssdlite_mobilenet_v2_coco.config\" --checkpoint_dir=\"inference_graph/\" --eval_dir=\"training/log/eval_py\"\n","# !python \"eval.py\" --logtostderr  --pipeline_config_path=\"training/ssdlite_mobilenet_v2_coco.config\" --checkpoint_dir=\"training/log\" --eval_dir=\"training/log/eval_py\"\n"],"execution_count":70,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/EnemyDetection\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n","\n","WARNING:tensorflow:From eval.py:57: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n","\n","WARNING:tensorflow:From eval.py:57: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n","\n","WARNING:tensorflow:From eval.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use object_detection/model_main.py.\n","W0119 23:18:45.521696 140511718733696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use object_detection/model_main.py.\n","WARNING:tensorflow:From eval.py:88: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0119 23:18:45.521917 140511718733696 module_wrapper.py:139] From eval.py:88: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0119 23:18:45.522634 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From eval.py:92: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n","\n","W0119 23:18:45.692492 140511718733696 module_wrapper.py:139] From eval.py:92: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n","\n","Loading...\n","WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","W0119 23:18:45.700317 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","W0119 23:18:45.700558 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n","\n","Loading...\n","Loading...\n","Loading...\n","Loading...\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","W0119 23:18:45.717254 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","W0119 23:18:45.723971 140511718733696 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.experimental.parallel_interleave(...)`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","W0119 23:18:45.724206 140511718733696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0119 23:18:45.743266 140511718733696 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n","W0119 23:18:46.262410 140511718733696 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n","WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0119 23:18:46.268740 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n","\n","W0119 23:18:46.270294 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:57: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","W0119 23:18:46.272043 140511718733696 deprecation.py:323] From /content/models/research/object_detection/core/prefetcher.py:57: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:57: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","W0119 23:18:46.272908 140511718733696 deprecation.py:323] From /content/models/research/object_detection/core/prefetcher.py:57: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","To construct input pipelines, use the `tf.data` module.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","W0119 23:18:46.273118 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0119 23:18:46.279759 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0119 23:18:46.292039 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0119 23:18:46.294581 140511718733696 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0119 23:18:48.572853 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0119 23:18:48.582594 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0119 23:18:48.582793 140511718733696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0119 23:18:48.669440 140511718733696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0119 23:18:48.759207 140511718733696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0119 23:18:48.841733 140511718733696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0119 23:18:48.919443 140511718733696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0119 23:18:49.002795 140511718733696 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0119 23:18:49.189027 140511718733696 deprecation.py:323] From /content/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","W0119 23:18:49.551026 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:79: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","W0119 23:18:49.618366 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:79: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","W0119 23:18:49.619507 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","W0119 23:18:49.620568 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0119 23:18:49.747577 140511718733696 deprecation.py:323] From /content/models/research/object_detection/eval_util.py:796: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/evaluator.py:263: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","W0119 23:18:49.946410 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/legacy/evaluator.py:263: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/evaluator.py:264: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","W0119 23:18:49.946630 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/legacy/evaluator.py:264: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/evaluator.py:270: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0119 23:18:49.949519 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/legacy/evaluator.py:270: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","INFO:tensorflow:Starting evaluation at 2020-01-19-23:18:50\n","I0119 23:18:50.250025 140511718733696 eval_util.py:496] Starting evaluation at 2020-01-19-23:18:50\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:308: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0119 23:18:50.253443 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/eval_util.py:308: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:308: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0119 23:18:50.253630 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/eval_util.py:308: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","2020-01-19 23:18:50.254911: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-01-19 23:18:50.260101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-19 23:18:50.260530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-19 23:18:50.260900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-19 23:18:50.262157: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-19 23:18:50.263734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-19 23:18:50.264113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-19 23:18:50.265916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-19 23:18:50.267422: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-19 23:18:50.271379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-19 23:18:50.271515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-19 23:18:50.271964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-19 23:18:50.272387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-19 23:18:50.272754: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2020-01-19 23:18:50.277595: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-01-19 23:18:50.277781: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e74f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-01-19 23:18:50.277809: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-01-19 23:18:50.377928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-19 23:18:50.378526: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1e74d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-01-19 23:18:50.378559: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-01-19 23:18:50.378755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-19 23:18:50.379223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-19 23:18:50.379305: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-19 23:18:50.379325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2020-01-19 23:18:50.379339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2020-01-19 23:18:50.379356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2020-01-19 23:18:50.379370: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2020-01-19 23:18:50.379384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2020-01-19 23:18:50.379398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-19 23:18:50.379496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-19 23:18:50.380019: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-19 23:18:50.380470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-19 23:18:50.380541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2020-01-19 23:18:50.381846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-19 23:18:50.381878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-19 23:18:50.381889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-19 23:18:50.382033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-19 23:18:50.382603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-19 23:18:50.383013: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-01-19 23:18:50.383044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8182 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:309: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","W0119 23:18:50.383852 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/eval_util.py:309: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:310: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n","\n","W0119 23:18:51.678344 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/eval_util.py:310: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:311: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n","\n","W0119 23:18:51.853691 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/eval_util.py:311: The name tf.tables_initializer is deprecated. Please use tf.compat.v1.tables_initializer instead.\n","\n","INFO:tensorflow:Restoring parameters from inference_graph/model.ckpt\n","I0119 23:18:52.121877 140511718733696 saver.py:1284] Restoring parameters from inference_graph/model.ckpt\n","2020-01-19 23:18:53.685548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-19 23:18:55.880190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/evaluator.py:240: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.\n","\n","W0119 23:18:56.754173 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/legacy/evaluator.py:240: The name tf.train.global_step is deprecated. Please use tf.compat.v1.train.global_step instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/legacy/evaluator.py:240: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n","\n","W0119 23:18:56.754639 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/legacy/evaluator.py:240: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n","\n","INFO:tensorflow:Creating detection visualizations.\n","I0119 23:18:56.845648 140511718733696 eval_util.py:168] Creating detection visualizations.\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:222: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","W0119 23:18:56.855642 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/eval_util.py:222: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n","\n","WARNING:tensorflow:From /content/models/research/object_detection/eval_util.py:229: The name tf.summary.FileWriterCache is deprecated. Please use tf.compat.v1.summary.FileWriterCache instead.\n","\n","W0119 23:18:56.877226 140511718733696 module_wrapper.py:139] From /content/models/research/object_detection/eval_util.py:229: The name tf.summary.FileWriterCache is deprecated. Please use tf.compat.v1.summary.FileWriterCache instead.\n","\n","INFO:tensorflow:Detection visualizations written to summary with tag image-0.\n","I0119 23:18:57.486046 140511718733696 eval_util.py:233] Detection visualizations written to summary with tag image-0.\n","W0119 23:18:57.486430 140511718733696 object_detection_evaluation.py:335] image b'j_101-4.png' does not have groundtruth difficult flag specified\n","INFO:tensorflow:Creating detection visualizations.\n","I0119 23:18:57.507545 140511718733696 eval_util.py:168] Creating detection visualizations.\n","INFO:tensorflow:Detection visualizations written to summary with tag image-1.\n","I0119 23:18:57.525745 140511718733696 eval_util.py:233] Detection visualizations written to summary with tag image-1.\n","INFO:tensorflow:Creating detection visualizations.\n","I0119 23:18:57.544119 140511718733696 eval_util.py:168] Creating detection visualizations.\n","INFO:tensorflow:Detection visualizations written to summary with tag image-2.\n","I0119 23:18:57.561561 140511718733696 eval_util.py:233] Detection visualizations written to summary with tag image-2.\n","INFO:tensorflow:Creating detection visualizations.\n","I0119 23:18:57.580985 140511718733696 eval_util.py:168] Creating detection visualizations.\n","INFO:tensorflow:Detection visualizations written to summary with tag image-3.\n","I0119 23:18:57.601655 140511718733696 eval_util.py:233] Detection visualizations written to summary with tag image-3.\n","INFO:tensorflow:Creating detection visualizations.\n","I0119 23:18:57.618993 140511718733696 eval_util.py:168] Creating detection visualizations.\n","INFO:tensorflow:Detection visualizations written to summary with tag image-4.\n","I0119 23:18:57.639202 140511718733696 eval_util.py:233] Detection visualizations written to summary with tag image-4.\n","INFO:tensorflow:Creating detection visualizations.\n","I0119 23:18:57.657366 140511718733696 eval_util.py:168] Creating detection visualizations.\n","INFO:tensorflow:Detection visualizations written to summary with tag image-5.\n","I0119 23:18:57.674721 140511718733696 eval_util.py:233] Detection visualizations written to summary with tag image-5.\n","INFO:tensorflow:Creating detection visualizations.\n","I0119 23:18:57.693256 140511718733696 eval_util.py:168] Creating detection visualizations.\n","INFO:tensorflow:Detection visualizations written to summary with tag image-6.\n","I0119 23:18:57.711898 140511718733696 eval_util.py:233] Detection visualizations written to summary with tag image-6.\n","INFO:tensorflow:Creating detection visualizations.\n","I0119 23:18:57.729520 140511718733696 eval_util.py:168] Creating detection visualizations.\n","INFO:tensorflow:Detection visualizations written to summary with tag image-7.\n","I0119 23:18:57.744509 140511718733696 eval_util.py:233] Detection visualizations written to summary with tag image-7.\n","INFO:tensorflow:Creating detection visualizations.\n","I0119 23:18:57.762020 140511718733696 eval_util.py:168] Creating detection visualizations.\n","INFO:tensorflow:Detection visualizations written to summary with tag image-8.\n","I0119 23:18:57.779113 140511718733696 eval_util.py:233] Detection visualizations written to summary with tag image-8.\n","INFO:tensorflow:Creating detection visualizations.\n","I0119 23:18:57.801822 140511718733696 eval_util.py:168] Creating detection visualizations.\n","INFO:tensorflow:Detection visualizations written to summary with tag image-9.\n","I0119 23:18:57.820502 140511718733696 eval_util.py:233] Detection visualizations written to summary with tag image-9.\n","INFO:tensorflow:Running eval batches done.\n","I0119 23:18:58.797441 140511718733696 eval_util.py:366] Running eval batches done.\n","INFO:tensorflow:# success: 62\n","I0119 23:18:58.797624 140511718733696 eval_util.py:371] # success: 62\n","INFO:tensorflow:# skipped: 0\n","I0119 23:18:58.797705 140511718733696 eval_util.py:372] # skipped: 0\n","I0119 23:18:58.818070 140511718733696 object_detection_evaluation.py:1311] average_precision: 0.731023\n","INFO:tensorflow:Writing metrics to tf summary.\n","I0119 23:18:59.017615 140511718733696 eval_util.py:80] Writing metrics to tf summary.\n","INFO:tensorflow:Losses/Loss/classification_loss: 7.951154\n","I0119 23:18:59.017972 140511718733696 eval_util.py:87] Losses/Loss/classification_loss: 7.951154\n","INFO:tensorflow:Losses/Loss/localization_loss: 1.423563\n","I0119 23:18:59.018182 140511718733696 eval_util.py:87] Losses/Loss/localization_loss: 1.423563\n","INFO:tensorflow:PascalBoxes_PerformanceByCategory/AP@0.5IOU/model: 0.731023\n","I0119 23:18:59.018335 140511718733696 eval_util.py:87] PascalBoxes_PerformanceByCategory/AP@0.5IOU/model: 0.731023\n","INFO:tensorflow:PascalBoxes_Precision/mAP@0.5IOU: 0.731023\n","I0119 23:18:59.018462 140511718733696 eval_util.py:87] PascalBoxes_Precision/mAP@0.5IOU: 0.731023\n","INFO:tensorflow:Metrics written to tf summary.\n","I0119 23:18:59.018556 140511718733696 eval_util.py:88] Metrics written to tf summary.\n","Traceback (most recent call last):\n","  File \"eval.py\", line 143, in <module>\n","    tf.app.run()\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n","    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n","    sys.exit(main(argv))\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n","    return func(*args, **kwargs)\n","  File \"eval.py\", line 139, in main\n","    graph_hook_fn=graph_rewriter_fn)\n","  File \"/content/models/research/object_detection/legacy/evaluator.py\", line 296, in evaluate\n","    eval_export_path=eval_config.export_path)\n","  File \"/content/models/research/object_detection/eval_util.py\", line 533, in repeated_checkpoint_run\n","KeyboardInterrupt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nzv3Gz0-ZsoE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wjs2Mz7IPoXW","colab_type":"code","colab":{}},"source":["import shutil\n","\n","# Copy export inference graph script\n","shutil.copyfile(\"/content/models/research/object_detection/export_inference_graph.py\", \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/export_inference_graph.py\")\n","\n","%cd /content/drive/My Drive/Colab Notebooks/EnemyDetection\n","# Export the graph into the inference_graph directory, which also has the frozen inference pb file that contains the classifier.\n","# Remember to select the checkpoint and add it as the appropriate flag for the checkpoint prefix! (i.e. training/log/model.ckpt-21650)\n","#!python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/faster_rcnn_inception_v2_coco.config --trained_checkpoint_prefix training/log/model.ckpt-23143 --output_directory inference_graph\n","!python export_inference_graph.py --input_type image_tensor --pipeline_config_path training/ssdlite_mobilenet_v2_coco.config --trained_checkpoint_prefix training/log/model.ckpt-60000 --output_directory inference_graph"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2C76m7GurL0","colab_type":"code","colab":{}},"source":["# For TF Lite, we export as follows.\n","# object_detection/export_tflite_ssd_graph.py \\\n","#  — pipeline_config_path=$CONFIG_FILE \\\n","#  — trained_checkpoint_prefix=$CHECKPOINT_PATH \\\n","#  — output_directory=$OUTPUT_DIR \\\n","#  — add_postprocessing_op=true\n","import shutil\n","shutil.copyfile(\"/content/models/research/object_detection/export_tflite_ssd_graph.py\", \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/export_tflite_ssd_graph.py\")\n","\n","%cd /content/drive/My Drive/Colab Notebooks/EnemyDetection\n","!python export_tflite_ssd_graph.py --pipeline_config_path=\"training/ssdlite_mobilenet_v2_coco.config\" --trained_checkpoint_prefix training/log/model.ckpt-60000 --output_directory inference_graph --add_postprocessing_op=true"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWVsK-HswwoJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a69b9485-ea76-46ae-c05f-24462f33fc36","executionInfo":{"status":"ok","timestamp":1579504568940,"user_tz":360,"elapsed":31215,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}}},"source":["\n","# ~~~~~~~ DEPRECATED ~~~~~~~~~~~~ \n","# Skip to next cell.\n","# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","\n","# For TF Lite, Bazel TOCO --> TF Lite Flatbuffer conversion\n","# bazel run -c opt tensorflow/lite/toco:toco — \\\n","#  — input_file=$OUTPUT_DIR/tflite_graph.pb \\\n","#  — output_file=$OUTPUT_DIR/detect.tflite \\\n","#  — input_shapes=1,300,300,3 \\\n","#  — input_arrays=normalized_input_image_tensor \\\n","#  — output_arrays=’TFLite_Detection_PostProcess’,’TFLite_Detection_PostProcess:1',’TFLite_Detection_PostProcess:2',’TFLite_Detection_PostProcess:3' \\\n","#  — inference_type=FLOAT \\\n","#  — allow_custom_ops\n","\n","!sudo apt install curl\n","!curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -\n","!echo \"deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" | sudo tee /etc/apt/sources.list.d/bazel.list\n","\n","!sudo apt update && sudo apt install bazel-1.2.1\n","\n","%cd /content/tensorflow\n","!bazel run -c opt tensorflow/lite/toco:toco --input_file=\"/content/drive/My Drive/Colab Notebooks/EnemyDetection/inference_graph/tflite_graph.pb\" --output_file=\"/content/drive/My Drive/Colab Notebooks/EnemyDetection/inference_graph/detect.tflite\" --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=FLOAT --allow_custom_ops"],"execution_count":16,"outputs":[{"output_type":"stream","text":["\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 0%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 7%\r\rReading package lists... 65%\r\rReading package lists... 65%\r\rReading package lists... 66%\r\rReading package lists... 66%\r\rReading package lists... 72%\r\rReading package lists... 72%\r\rReading package lists... 73%\r\rReading package lists... 73%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 82%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 87%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 93%\r\rReading package lists... 94%\r\rReading package lists... 94%\r\rReading package lists... 95%\r\rReading package lists... 95%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... 98%\r\rReading package lists... Done\r\n","\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 0%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree... 50%\r\rBuilding dependency tree       \r\n","\rReading state information... 0%\r\rReading state information... 0%\r\rReading state information... Done\r\n","curl is already the newest version (7.58.0-2ubuntu3.8).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-430\n","Use 'sudo apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 65 not upgraded.\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  4654  100  4654    0     0  20147      0 --:--:-- --:--:-- --:--:-- 20060\n","OK\n","deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\n","Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n","Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Hit:3 https://storage.googleapis.com/bazel-apt stable InRelease\n","Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Hit:13 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Fetched 252 kB in 2s (103 kB/s)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","65 packages can be upgraded. Run 'apt list --upgradable' to see them.\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-430\n","Use 'sudo apt autoremove' to remove it.\n","Suggested packages:\n","  bash-completion\n","The following NEW packages will be installed:\n","  bazel-1.2.1\n","0 upgraded, 1 newly installed, 0 to remove and 65 not upgraded.\n","Need to get 43.8 MB of archives.\n","After this operation, 0 B of additional disk space will be used.\n","Get:1 https://storage.googleapis.com/bazel-apt stable/jdk1.8 amd64 bazel-1.2.1 amd64 1.2.1 [43.8 MB]\n","Fetched 43.8 MB in 1s (40.4 MB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package bazel-1.2.1.\n","(Reading database ... 146063 files and directories currently installed.)\n","Preparing to unpack .../bazel-1.2.1_1.2.1_amd64.deb ...\n","Unpacking bazel-1.2.1 (1.2.1) ...\n","Setting up bazel-1.2.1 (1.2.1) ...\n","/content/tensorflow\n","Extracting Bazel installation...\n","Starting local Bazel server and connecting to it...\n","WARNING: ignoring LD_PRELOAD in environment.\n","ERROR: Unrecognized option: --input_file=/content/drive/My Drive/Colab Notebooks/EnemyDetection/inference_graph/tflite_graph.pb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tAecXdmM0hm5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":802},"outputId":"edeb0c17-2f8a-4b4e-c467-aec616961280","executionInfo":{"status":"ok","timestamp":1579505067574,"user_tz":360,"elapsed":7662,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}}},"source":["# In tensorflow 1.9, you may do this:\n","%cd /content/drive/My Drive/Colab Notebooks/EnemyDetection\n","\n","!tflite_convert --output_file=\"inference_graph/detect.tflite\" --input_shapes=1,300,300,3 --graph_def_file=\"inference_graph/tflite_graph.pb\" --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --allow_custom_ops"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/EnemyDetection\n","2020-01-20 07:24:23.846248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-01-20 07:24:23.850546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 07:24:23.851025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 07:24:23.851251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-01-20 07:24:23.852861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-01-20 07:24:23.854318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-01-20 07:24:23.854615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-01-20 07:24:23.856381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-01-20 07:24:23.857440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-01-20 07:24:23.861095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 07:24:23.861192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 07:24:23.861689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 07:24:23.862134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 07:24:23.862429: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2020-01-20 07:24:23.866987: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000165000 Hz\n","2020-01-20 07:24:23.867167: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5597e2574f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-01-20 07:24:23.867192: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-01-20 07:24:23.955306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 07:24:23.955886: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5597e2575480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-01-20 07:24:23.955914: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n","2020-01-20 07:24:23.956067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 07:24:23.956601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n","pciBusID: 0000:00:04.0\n","2020-01-20 07:24:23.956654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-01-20 07:24:23.956674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-01-20 07:24:23.956691: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-01-20 07:24:23.956708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-01-20 07:24:23.956728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-01-20 07:24:23.956743: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-01-20 07:24:23.956759: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-01-20 07:24:23.956819: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 07:24:23.957318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 07:24:23.957735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-01-20 07:24:23.957790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-01-20 07:24:23.958831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-01-20 07:24:23.958860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-01-20 07:24:23.958871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-01-20 07:24:23.958982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 07:24:23.959565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-01-20 07:24:23.960037: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-01-20 07:24:23.960077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12071 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ixoRtjZCQXRC","colab_type":"code","colab":{}},"source":["# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ #\n","PATH_TO_FROZEN_GRAPH = \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/inference_graph/frozen_inference_graph.pb\"\n","PATH_TO_LABELS = \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/training/labelmap.pbtxt\"\n","NUM_CLASSES = 1 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vW9OOy6pu1zI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":955},"outputId":"d5520d7b-c619-4ae9-f351-ef7fe68f7e18","executionInfo":{"status":"ok","timestamp":1579471308973,"user_tz":360,"elapsed":79871,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}}},"source":["!pip uninstall tensorflow-gpu\n","!pip uninstall tensorflow\n","!pip install tensorflow==1.15.0"],"execution_count":4,"outputs":[{"output_type":"stream","text":["\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n","Uninstalling tensorflow-1.14.0:\n","  Would remove:\n","    /usr/local/bin/freeze_graph\n","    /usr/local/bin/saved_model_cli\n","    /usr/local/bin/tensorboard\n","    /usr/local/bin/tf_upgrade_v2\n","    /usr/local/bin/tflite_convert\n","    /usr/local/bin/toco\n","    /usr/local/bin/toco_from_protos\n","    /usr/local/lib/python3.6/dist-packages/tensorflow-1.14.0.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/tensorflow/*\n","Proceed (y/n)? y\n","  Successfully uninstalled tensorflow-1.14.0\n","Collecting tensorflow==1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 38kB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.33.6)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.1.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.1.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.17.5)\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 3.4MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 494kB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.11.2)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.0) (42.0.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (0.16.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.8.0)\n","Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n","  Found existing installation: tensorflow-estimator 1.14.0\n","    Uninstalling tensorflow-estimator-1.14.0:\n","      Successfully uninstalled tensorflow-estimator-1.14.0\n","  Found existing installation: tensorboard 1.14.0\n","    Uninstalling tensorboard-1.14.0:\n","      Successfully uninstalled tensorboard-1.14.0\n","Successfully installed tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorboard","tensorflow","tensorflow_estimator"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"O_kO6kEYl410","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":351},"outputId":"55b834c7-f29e-4a06-d0c1-ec8f44236009","executionInfo":{"status":"ok","timestamp":1579506224732,"user_tz":360,"elapsed":2588,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}}},"source":["# Write Python3 code here \n","# THIS WORKS! ** > tf.contrib.lite => tf.lite in tensorflow 1.14\n","# https://medium.com/datadriveninvestor/mobile-object-detector-with-tensorflow-lite-9e2c278922d0\n","\n","import os \n","import cv2 \n","import numpy as np \n","import tensorflow as tf \n","import sys \n","from tensorflow.python.saved_model import tag_constants\n","from tensorflow.python.saved_model import signature_constants\n","\n","PATH_TO_LABELS = \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/training/labelmap.pbtxt\"\n","NUM_CLASSES = 1\n","\n","PATH_TO_FROZEN_GRAPH = \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/inference_graph/tflite_graph.pb\"\n","PATH_TO_LITE_MODEL   = \"/content/drive/My Drive/Colab Notebooks/EnemyDetection/inference_graph/detect.tflite\"\n","\n","CWD_PATH = \"/content/drive/My Drive/Colab Notebooks/EnemyDetection\"\n","IMAGE_NAME = 'train/j_313-4-1.png'\n","PATH_TO_IMAGE = os.path.join(CWD_PATH, 'images', IMAGE_NAME)\n","\n","from abc import ABC, abstractmethod\n","\n","class ObjectDetector(ABC):\n","    @abstractmethod\n","    def detect(self, frame, threshold=0.0):\n","        pass\n","\n","class ObjectDetectorDetectionAPI(ObjectDetector):\n","    def __init__(self, graph_path=PATH_TO_FROZEN_GRAPH):\n","        \"\"\"\n","            Builds Tensorflow graph, load model and labels\n","        \"\"\"\n","\n","        # model_path = path.join(basepath, graph_path)\n","\n","        # Load Tensorflow model into memory\n","        self.detection_graph = tf.Graph()\n","        with self.detection_graph.as_default():\n","            od_graph_def = tf.GraphDef()\n","            with tf.gfile.GFile(graph_path, 'rb') as fid:\n","                serialized_graph = fid.read()\n","                od_graph_def.ParseFromString(serialized_graph)\n","                tf.import_graph_def(od_graph_def, name='')\n","\n","        # Load lebel_map\n","        self._load_label(PATH_TO_LABELS, NUM_CLASSES, use_disp_name=True)\n","\n","        with self.detection_graph.as_default():\n","            self.sess = tf.Session(graph=self.detection_graph)\n","            # Definite input and output Tensors for detection_graph\n","            self.image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n","            # Each box represents a part of the image where a particular object was detected.\n","            self.detection_boxes = self.detection_graph.get_tensor_by_name('detection_boxes:0')\n","            # Each score represent how level of confidence for each of the objects.\n","            # Score is shown on the result image, together with the class label.\n","            self.detection_scores = self.detection_graph.get_tensor_by_name('detection_scores:0')\n","            self.detection_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n","            self.num_detections = self.detection_graph.get_tensor_by_name('num_detections:0')\n","\n","    def close(self):\n","        tf.reset_default_graph()\n","        self.sess = tf.InteractiveSession()\n","\n","    def detect(self, frame, threshold=0.1):\n","        \"\"\"\n","            Predicts person in frame with threshold level of confidence\n","            Returns list with top-left, bottom-right coordinates and list with labels, confidence in %\n","        \"\"\"\n","        frames = np.expand_dims(frame, axis=0)\n","        # Actual detection.\n","        (boxes, scores, classes, num) = self.sess.run(\n","                [self.detection_boxes, self.detection_scores,\n","                 self.detection_classes, self.num_detections],\n","                feed_dict={self.image_tensor: frames})\n","\n","        # Find detected boxes coordinates\n","        return [self._boxes_coordinates(frame,\n","                            np.squeeze(boxes[0]),\n","                            np.squeeze(i[2]).astype(np.int32),\n","                            np.squeeze(i[3]),\n","                            min_score_thresh=threshold,\n","                            ) for i in zip(frames, boxes, classes, scores)][0]\n","\n","\n","    def _boxes_coordinates(self,\n","                            image,\n","                            boxes,\n","                            classes,\n","                            scores,\n","                            max_boxes_to_draw=20,\n","                            min_score_thresh=.5):\n","        \"\"\"\n","          This function groups boxes that correspond to the same location\n","          and creates a display string for each detection and overlays these\n","          on the image.\n","          Args:\n","            image: uint8 numpy array with shape (img_height, img_width, 3)\n","            boxes: a numpy array of shape [N, 4]\n","            classes: a numpy array of shape [N]\n","            scores: a numpy array of shape [N] or None.  If scores=None, then\n","              this function assumes that the boxes to be plotted are groundtruth\n","              boxes and plot all boxes as black with no classes or scores.\n","            category_index: a dict containing category dictionaries (each holding\n","              category index `id` and category name `name`) keyed by category indices.\n","            use_normalized_coordinates: whether boxes is to be interpreted as\n","              normalized coordinates or not.\n","            max_boxes_to_draw: maximum number of boxes to visualize.  If None, draw\n","              all boxes.\n","            min_score_thresh: minimum score threshold for a box to be visualized\n","        \"\"\"\n","\n","        if not max_boxes_to_draw:\n","            max_boxes_to_draw = boxes.shape[0]\n","        number_boxes = min(max_boxes_to_draw, boxes.shape[0])\n","        person_boxes = []\n","        # person_labels = []\n","        for i in range(number_boxes):\n","            if scores is None or scores[i] > min_score_thresh:\n","                box = tuple(boxes[i].tolist())\n","                ymin, xmin, ymax, xmax = box\n","\n","                im_height, im_width, _ = image.shape\n","                left, right, top, bottom = [int(z) for z in (xmin * im_width, xmax * im_width,\n","                                                             ymin * im_height, ymax * im_height)]\n","\n","                person_boxes.append([(left, top), (right, bottom), scores[i],\n","                                     self.category_index[classes[i]]['name']])\n","        return person_boxes\n","\n","    def _load_label(self, path, num_c, use_disp_name=True):\n","        \"\"\"\n","            Loads labels\n","        \"\"\"\n","        label_map = label_map_util.load_labelmap(path)\n","        categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=num_c,\n","                                                                    use_display_name=use_disp_name)\n","        self.category_index = label_map_util.create_category_index(categories)\n","\n","class ObjectDetectorLite(ObjectDetectorDetectionAPI):\n","    def __init__(self, model_path=PATH_TO_LITE_MODEL):\n","        \"\"\"\n","            Builds Tensorflow graph, load model and labels\n","        \"\"\"\n","\n","        # Load lebel_map\n","        self._load_label(PATH_TO_LABELS, NUM_CLASSES, use_disp_name=True)\n","\n","        # Define lite graph and Load Tensorflow Lite model into memory\n","        self.interpreter = tf.lite.Interpreter(\n","            model_path=model_path)\n","        self.interpreter.allocate_tensors()\n","        self.input_details = self.interpreter.get_input_details()\n","        self.output_details = self.interpreter.get_output_details()\n","\n","    def detect(self, image, threshold=0.1):\n","        \"\"\"\n","            Predicts person in frame with threshold level of confidence\n","            Returns list with top-left, bottom-right coordinates and list with labels, confidence in %\n","        \"\"\"\n","\n","        # Resize and normalize image for network input\n","        frame = cv2.resize(image, (300, 300))\n","        frame = np.expand_dims(frame, axis=0)\n","        frame = (2.0 / 255.0) * frame - 1.0\n","        frame = frame.astype('float32')\n","\n","        # run model\n","        self.interpreter.set_tensor(self.input_details[0]['index'], frame)\n","        self.interpreter.invoke()\n","\n","        # get results\n","        boxes = self.interpreter.get_tensor(\n","            self.output_details[0]['index'])\n","        classes = self.interpreter.get_tensor(\n","            self.output_details[1]['index'])\n","        scores = self.interpreter.get_tensor(\n","            self.output_details[2]['index'])\n","        num = self.interpreter.get_tensor(\n","            self.output_details[3]['index'])\n","\n","        # Find detected boxes coordinates\n","        return self._boxes_coordinates(image,\n","                            np.squeeze(boxes[0]),\n","                            np.squeeze(classes[0]+1).astype(np.int32),\n","                            np.squeeze(scores[0]),\n","                            min_score_thresh=threshold)\n","\n","    def close(self):\n","        pass\n","\n","detector = ObjectDetectorLite()\n","image = cv2.cvtColor(cv2.imread(PATH_TO_IMAGE), cv2.COLOR_BGR2RGB)\n","result = detector.detect(image, 0.2)\n","print(result)\n","\n","for obj in result:\n","        print('coordinates: {} {}. class: \"{}\". confidence: {:.2f}'.\n","                    format(obj[0], obj[1], obj[3], obj[2]))\n","\n","        cv2.rectangle(image, obj[0], obj[1], (0, 255, 0), 2)\n","        cv2.putText(image, '{}: {:.2f}'.format(obj[3], obj[2]),\n","                    (obj[0][0], obj[0][1] - 5),\n","                    cv2.FONT_HERSHEY_PLAIN, 1, (0, 255, 0), 2)\n","\n","from google.colab.patches import cv2_imshow\n","%matplotlib inline\n","\n","cv2_imshow(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n","\n","# # Generate an Open CV compatible config pbtxt file.\n","\n","# !pip install imutils\n","# !pip install opencv-contrib-python==3.4.3.18\n","# %cd \"/content/drive/My Drive/Colab Notebooks/EnemyDetection\"\n","# !python tf_text_graph_ssd.py --input=\"inference_graph/frozen_inference_graph.pb\" --config \"training/ssdlite_mobilenet_v2_coco.config\" --output \"inference_graph/CVPBTXT_graph.pbtxt\"\n","\n","# CWD_PATH = \"/content/drive/My Drive/Colab Notebooks/EnemyDetection\"\n","# IMAGE_NAME = 'test/j_110-4.png'\n","# PATH_TO_IMAGE = os.path.join(CWD_PATH, 'images', IMAGE_NAME)\n","# PATH_TO_CKPT = os.path.join(CWD_PATH, 'inference_graph', 'frozen_inference_graph.pb')\n","# PATH_TO_CVPBTXT = os.path.join(CWD_PATH, 'inference_graph', 'CVPBTXT_graph.pbtxt') \n","\n","# net = cv2.dnn.readNetFromTensorflow(PATH_TO_CKPT, PATH_TO_CVPBTXT)\n","\n","# image = cv2.imread(PATH_TO_IMAGE)\n","# rows, cols, channels = image.shape\n","\n","# net.setInput(cv2.dnn.blobFromImage(image, size=(300, 300), swapRB=True, crop=False))\n","# networkOutput = net.forward()\n","\n","# for detection in networkOutput[0,0]:\n","#     score = float(detection[2])\n","#     if score > 0.2:\n","#         left = detection[3] * cols\n","#         top = detection[4] * rows\n","#         right = detection[5] * cols\n","#         bottom = detection[6] * rows\n","\n","#         #draw a red rectangle around detected objects\n","#         cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (0, 0, 255), thickness=2)\n","\n","# # Show the image with a rectagle surrounding the detected objects \n","# from google.colab.patches import cv2_imshow\n","# %matplotlib inline\n","\n","# cv2_imshow(image)\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[[(128, 146), (164, 192), 0.9981445, 'model']]\n","coordinates: (128, 146) (164, 192). class: \"model\". confidence: 1.00\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAEAAElEQVR4nOz9d7wcSXYeiH5hMrPs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\n","text/plain":["<PIL.Image.Image image mode=RGB size=300x300 at 0x7F5860264A58>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"tqG0ed98qTC1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":385},"outputId":"1c19d1bc-b07f-4e05-b09c-13828a049d07","executionInfo":{"status":"ok","timestamp":1579503054540,"user_tz":360,"elapsed":5900,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}}},"source":["###  ----------------\t###\n","###  | NEW, FROM ME |\t###\n","###  ----------------\t###\n","\n","# Write Python3 code here \n","import os \n","import cv2 \n","import numpy as np \n","import tensorflow as tf \n","import sys \n","from tensorflow.python.saved_model import tag_constants\n","from tensorflow.python.saved_model import signature_constants\n","\n","# This is needed since the notebook is stored in the object_detection folder. \n","# sys.path.append(\"..\") \n","\n","%cd /content/models/research/\n","\n","# Import utilites \n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util \n","\n","# Name of the directory containing the object detection module we're using \n","MODEL_NAME = 'inference_graph' # The path to the directory where frozen_inference_graph is stored. \n","IMAGE_NAME = 'test/j_110-4.png' # The path to the image in which the object has to be detected. \n","\n","# Grab path to current working directory \n","CWD_PATH = \"/content/drive/My Drive/Colab Notebooks/EnemyDetection\" #os.getcwd() \n","\n","# Path to frozen detection graph .pb file, which contains the model that is used \n","# for object detection. \n","# PATH_TO_CKPT = os.path.join(CWD_PATH, MODEL_NAME, 'frozen_inference_graph.pb') \n","PATH_TO_SAVED_MODEL = os.path.join(CWD_PATH, MODEL_NAME, 'saved_model') \n","\n","# Path to label map file \n","PATH_TO_LABELS = os.path.join(CWD_PATH, 'training', 'labelmap.pbtxt') \n","\n","# Path to image \n","PATH_TO_IMAGE = os.path.join(CWD_PATH, 'images', IMAGE_NAME) \n","\n","# Number of classes the object detector can identify \n","NUM_CLASSES = 1\n","\n","# Load the label map. \n","# Label maps map indices to category names, so that when our convolution \n","# network predicts `5`, we know that this corresponds to `king`. \n","# Here we use internal utility functions, but anything that returns a \n","# dictionary mapping integers to appropriate string labels would be fine \n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS) \n","categories = label_map_util.convert_label_map_to_categories( \n","\t\tlabel_map, max_num_classes = NUM_CLASSES, use_display_name = True) \n","category_index = label_map_util.create_category_index(categories) \n","\n","# Load the Tensorflow model into memory. \n","detection_graph = tf.Graph() \n","with detection_graph.as_default(): \n","    # od_graph_def = tf.GraphDef() \n","    # with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid: \n","    #     serialized_graph = fid.read() \n","    #     od_graph_def.ParseFromString(serialized_graph) \n","    #     tf.import_graph_def(od_graph_def, name ='') \n","\n","    with tf.Session(graph = detection_graph) as sess:\n","        tf.saved_model.loader.load(\n","            sess,\n","            [tag_constants.SERVING],\n","            str(PATH_TO_SAVED_MODEL),\n","        )\n","        # Define input and output tensors (i.e. data) for the object detection classifier \n","\n","        # Input tensor is the image \n","        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0') \n","        # Output tensors are the detection boxes, scores, and classes \n","        # Each box represents a part of the image where a particular object was detected \n","        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0') \n","        # Each score represents level of confidence for each of the objects. \n","        # The score is shown on the result image, together with the class label. \n","        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0') \n","        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0') \n","        # Number of objects detected \n","        num_detections = detection_graph.get_tensor_by_name('num_detections:0') \n","\n","        # Load image using OpenCV and \n","        # expand image dimensions to have shape: [1, None, None, 3] \n","        # i.e. a single-column array, where each item in the column has the pixel RGB value \n","        image = cv2.imread(PATH_TO_IMAGE) \n","\n","        alpha = 1.5 # Contrast control (1.0-3.0)\n","        beta = 25 # Brightness control (0-100)\n","        # image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n","\n","        image_expanded = np.expand_dims(image, axis = 0) \n","        print(image_expanded.shape)\n","\n","        # Perform the actual detection by running the model with the image as input \n","        (boxes, scores, classes, num) = sess.run( \n","            [detection_boxes, detection_scores, detection_classes, num_detections], \n","            feed_dict ={image_tensor: image_expanded})\n","        \n","        # Draw the results of the detection (aka 'visualize the results') \n","        # print(classes)\n","\n","        vis_util.visualize_boxes_and_labels_on_image_array( \n","            image, \n","            np.squeeze(boxes), \n","            np.squeeze(classes).astype(np.int32), \n","            np.squeeze(scores), \n","            category_index, \n","            use_normalized_coordinates = True, \n","            line_thickness = 2, \n","            max_boxes_to_draw= 10, #https://stats.stackexchange.com/questions/297796/faster-r-cnn-how-to-avoid-multiple-detection-in-same-area\n","            min_score_thresh = 0.0) \n","\n","        from google.colab.patches import cv2_imshow\n","        %matplotlib inline\n","        # All the results have been drawn on the image. Now display the image. \n","        cv2_imshow(image) \n","\n","        # Press any key to close the image \n","        cv2.waitKey(0) \n","\n","        # Clean up \n","        cv2.destroyAllWindows() \n","\n","\n","\n"," \n","\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/models/research\n","INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n","(1, 300, 300, 3)\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAADJzUlEQVR4nOx9Z4AkR3n2U9Vp8mze\n28s5Sad4CiihgAQICQQCySQDBoMNGIyNjU0SwmCDwTbZYHKO+shJQiiinE6n0+Wgi5t3J0+Hqvp+\nVHdPT0/P7Gy40+nQo9ZtT091nHr6fetNRSBuwLN4Fs/i6YMq/5y26muEzvwonIu5uRwJh7XTatPe\nNwM4ddn/BTey5lfyL39zpd9AV3R/+yv/ZR6A739sEAATDAB4/Z4UALpjhU2bdgMYGi63c3ntoL8v\nETzg//zmFQDedeWP/QanbhgIth8cygU/3jmmNTuyXXHkyt4xRzOoAIQQdoWpMQqAUAIIIcAsBkA+\nMkF0AJQSYjFvGyBQ90CF3xyi4UmTwP/ys7eGXZtfDGD1xpu9TaR+l/AqCRykdsB6bL3vUgDrz/1j\n41eE+Fdbu/7mRwKEAKnd0ZP3Xdak3Rygd/43AxeEkUOvc0k4GwYCoJTMGQ/bY2AjWtAPwN9emhna\ncheAnnUXwCMb4yzIRgAKUQBAAWOBy+AAMFZOz+vPDg7l+vsSc8XDKY+zafMRycMQ/SQu6rbRkooS\n8rnYVdawLQxCifslIX4bEmwd+EBIHQ9bMLCxUcOnur1bMLDxmIZCTFa7Du8NAUL8ozWH8L4mxLu5\n2qFOOvdWABPDIy6Z/ReQ8JoJ/z/5tXzXicDR/R0BYPTw6xvuhMCXhMcLjg4DV8xTbn6y9NxlMQCj\nW+9WVQrHAdCx7iJX9DVAURT3yAE2kvTiedg/tzycEps2H5ECsxku6rZb89CuMi2mINBBESXH0EAB\nd1O4ZZCI7mprBhIjVncGuUbCW+o2B1ZjCm321pAwFAIQk/Hg4eQNklYUbDw5iGjYIYLgjRDev+Ev\nRe1RBd8sdeeenQQ8PtCagT5kT4ipXIWjEgpCJ3feM7blNvcgglnMsphl2VZwL8WD/EjSi+f1Z48Z\nAyWmPJ0UiU0gAFTMll/Lv5KCNUWuSf8l/g4u7zyZE+pkfnsSIjUhYQbKjbWWgRYxhQpfytQv/mXI\nt4qhNHRm0pK7Le9OfpgYHm3aMqSoBzV1/6P7hiINakFIvD9rmHkWz2Km6F/0XV8XFUKAiJoS6jHQ\nbUowcuh1AHoXfMvbQgCMHHztcaaOPotn8cxESOQKQULCLozA9y4JLzntW5OePW02mBvzzHSsoycv\n+VKLNrqmxOOtBlQA/rT5VQA+ff23Hc3VOWMaAeDY7mWkVp4PwIi5Jpyf/OqR4SID8OLTtPb10tt3\nF5p9dfGKtFxptI42ovX4UOLWg7UfeMeYa+pVuMOoamhcCEEUV1FzHCVgiyS2yWMqOPOsw67GWdOs\napDKF/EMOQhZQYj/UQ4Idzx4OYA1Z/8B0faYRgspDEoRMoLUY9M9lwI49bw/1k4ZkDuEoOreSMBU\nClD/luqp4Y7qhCCUbLnnEgDzl//Qv21RW3GvZXD/q+p3rTtWvfUJYRbWM7QmCTvi6pzw8NigzXEg\ngIFuUanwybLSutmPnlRetbHu0TjegHly170qeBHoPvmSYIOFa08HHm3Gw7t254Mf5elZ1EBL8tOn\nYmsMDZdb83Bef/bV/fjuw/nQdkYDWo8AIP0TDIrhbpSECrFNCJ9OdV/4dGnJwMCnupMHtgV5U2vj\nMdDfZeqfW0AQ4RpWCIQQJKbQas1w6h6dB403deQQoIQExpGH91w/5UmHDrx6yjYhjBz6y9CWOnV0\n9jycG1+FqrQWhu0z0LIZCCYnXZ50dCRasPF7D9UOe9U6nkkqAKq2iGkEUKq2GHviNgAXLQSAn2xL\nARgTKbUn7YwOyb1CxGuEAhHJwzYZKCFp30jFef3Z1jsG/A6uh9Dd7n0ZtmQQQHhiJMJMWr+//yFw\nfyQWaxACriknJA2Iz+o61FwATRFgmeQhAEFcHtbdSmAPEtqbSuNS+BV0bBAeE3bEVQDHs0hsn4ES\new5U4Ii4QYA6NgJoQchfbXXN4q/aSPIlBkDXqaopAFSV6TquP7k4/NgfB4DvPdrc8hiFEA+nRb8g\nQlQMMfDVZ2akMFzdTXeM8ZBwYnbNRw+5nXg84A39UIio90ZtV0QxkHif61ntW1JJw+YaDFrTGCMQ\nMkMG7LsgRLgE9P7UXUzdPu5H6lt7nxYCAs38hNMSiY9u/6u5u55p44mn3tJOszOWftFfjxvEZ+OU\n+N5DwnfkvGojAJhVfP3e6REvEjOmXxC+MtwoBn0e+gyU0sDhKkXNDeN3UKvKCCHhHk4AQYQQ0mvQ\nsp9G2OHr9T1fQQ3KyvBuhlInjhveCAiNT+saCEGIa6CUqqlBYfFwY/dFQOvOO3MGkhu9Q0Q5Gvxv\nmzVo4ax/Zg0Rp4WK6T7wuEFsj2C2VertiKGlePz6PXPgHrxwRWb2B2nEps1HEAhz65/XAwDI7xjn\nkoGUEgBcqAAEMYjw3yNSQSQ1cdSgeXo8ie6odbLQPwDx+jrqWFcn9EISMIDoM02pmkLKbSlIvSFi\n8OySvzR82qAUnDYbxQ11TGv8FmjVoHXEzInEw5Ltvg+TWs2lWzGFFYiYGZms+uu9HbEgG02rMvtr\nOEr0C0JSsb8v4ZEQPZ36+KRNfKJIBdETNkSJSQ5aJm9ySJeTUhhG2WdEFA3rzJ81I0yN5y1CWUiE\nttnEQNoIIZnm8bAu6kCIRvoFCRg0gEZLsEah18iu1oIxClP4Ced+iDhr2d3WYZufxWcjAE2tEbLs\nhVYmYgo8Qpqs7jfTlBZjo6Y4Btzz4Q8RN23aLR0VYxM2pajZXQLGQU6IdFD4hIiphDtERJthXKW0\nZgchTYdRwlOAebVKY/Hw1wEGijB5YTKuu1QJ0aMJA0Obic9DyGOr4I50TDQQP0IARg6AyY01cSdX\nGrf4LUNtIuE3A9Bm2Jqk4tygNbXEDTOJ4AneUpN3VV9nNqnRoBgEYDvcdsISoFxlJiNyCX1lMyGX\nNq/rlWfFX3lWQxc8OujvSzTaS3eOiwADScB5QAQhimIQQkAgxWBcJU1tE95+QrgjKle0EkIaxSBp\n+BOQhY1RbLOEqC1CeLQSXhCLbKOCh84kWqigNSvqDbV/p4WWyqd7zMBh22LX1JLwGMrudiGPHHgb\nJVNpAEkAQLFSLNdlFUCyMRavS6qYGTTFjVf+ySPiNefQlf1OvsR0nR4cnyLdYcZopN+pp6744uO7\n5TjQ7/ZCuCJKUSwQw7OJEBDEpZAXvuWiuU9C2j7qHBHhJk1Nn+1xjhAiGvyVDZfR7CshBPGDCHzV\nVOXcIZ7vMWB9Ctl12rq+KTHNzjw1Caetix5l2d0WfKnYZK9UPJWKA0CxUvQ3ts9Am4mQauoTL4Tv\n3O8GbbzmHLKy3wGwa2hu1AoZXtMK71o7JyeaDVad+qugJGxT7gU00mhMRRbXQ+gqz8IdF6rgNqHR\nDKyTis30Xq+jIiAk/S0I9PygaAkKnhAFvM45RYeYBgPloVtbiiLRjuyeAXxJ2PIIqXhKriRSsVq4\nVtvoUHxbv2UkUgDGy9Ea/g8f9FedF65nmaQyV2w8rhE1EmvSzpNZ8jMhwnMIN8bwRKAutZF4roya\nFJafVcFq8rBhx7qRZ1AX9ftPY0eacktk36vf2KofHCPT6NFI4/BfB95LIRl3uVGqRDNtugzkpgVg\n3PvYlYBZLgLQGU2lE2jORgC/fVLaXZ3rz4JZYQCMGHYNG83aP3PRmn/1NpBIrbWeLHUacoB19XYb\nUkslFJ4UrB1dFdz2c9hn45mYOzQl4WwZeNRkd7vnCh4EiJ+yovL4bjSwsWhPz+1erdTc3Emt1lnG\nywBACEnpKBbKAKRqKwlZqEY/5x8+CBlVev1GtrLPvZKVgeRAR/B943Xk7O9LfPnJKeJgI/D0GaVJ\nQLEklNZss559K1iKwv/W5MKglPP66MWmDIxw35OaZHWlon86TXCbUKmzPo3c8xHROWZCv2Mou1td\nQMuN8VNWyBXTNPnWg0mDDhWn4f3rjCXyxVxwS8l2f8EgG4tW7WdN6UQSkgAdHWkAE6Vo2fDDh2q8\nciwGQNUVACqhqxewcoWrbuAx+cJmiulzcPYO5QhEDun9E7lb6u5XyHAygBDQwKBa8KaRcSLwb/22\nwDGb7RhkXs0HQeDKQ9Kw59NDyTAJTxjvfGvQdQuPPLizzcYZz9OVSWWly0+y0SehvwKIlF7TQn1C\npnQyOVmA1yVbE/JHnqB71WkAYOXtREYrV9y937pOqsDknXhmGKXrhnpAQHIFXPeutPSsuNzVJylV\nGA+Vxpl6hBk8Yx3zXGuwu00TsOuurGatWXPurZEHln/yg6OAOLLvlQD6F3/PvYWAvCe+Tbq2Sjzv\njLvJ/++pbS91M+svOe1bmCkDn97Y0T9rhNjVaIJucyV4tGYfm5098jjPlmuIwuJVN6GOj6gqlcEn\nXlV7bbfPQMHrlmfxdOJYOZSnd9jgUP9Z+CCEUEIJGSuPjZbGRotjcrOrjjZjYPscO23V1+p2PMrq\ntU7x4PY3AjhrzVdDX1WqtXvRYu4Ndp+2XK6MPbY31F5K8lNXfiW48aRLN/rr449uAwAmOAGlruZR\nLbd6NIVSvmhFNwhF7UjITKs/bX8LgBed8220jCOXkAUBZo5jYpReffqvZdjatnsvBbDuvNsDjaOj\nTVHvVlS4I0R9ej1x1dkn7r8cwMnn3BLw+oX9F3UhBSS0pQaH0ijnfW2DDNGTF5ZVAOCBPz0PwLwl\n33ev1tc865XRscJoT6Z3/45rAYwW3bJRVKFaTE+ntWRSHwyNCZ9BYq1JDweAuEe84HtF19QjD+6k\n1E0maI0gAwF0nb42FUsA2HffI/6vHIsTANVK9Lsmncykk+56iJDNQsn9dZlmJdM7pkzsCOM4M0qj\nvlcLtyynG17tVyEjtYbeN+4WwqhKmQM3NA2Nr3dRO0dEJqQIxAt5PI5go8q5DLFthqwSbUltPfCT\np847bqq3XbWTnSkAmawOoFRy7eFuf30G0W9mGLxvOwEycR1A3oxI29cUIoNCe89cMZyb8Lf3ZTtr\njVgg2JYQAHqCyNLAVrXpE/QJWSjlhaiRMBhK3pDbAYAlYsrIZFX2Fo+N9R3lmWCUrv9KeH88L17N\n1EI8agKCSPdeWyULayKy2SkDgjXQNsRGLYqH2UC5VgSP4m3rSKgCSHd2yDMNDk8SL0aXgOSdOnO6\nHtcl/QCUSmYy6TqfnvFBGxaH3lYUOgDkilY2pWcMV7CE2OjzMAifkFIYhtB/1slyZej+J3x+Wk00\n1XQyA8Czr+aDJAyu+yh7xE7ElJHJmj+ztyN2fPi3ZoM6o6lw9T3fWurWqJBUDOwUcdtNH0TNYi08\nwRrJRu8sAirjUi/tUOoO4f9xnfwieGwBoDA+IVv193QELyE/nNMTdW7esaHi4uVdw8MFyUApDJ/x\nJES9atpSpwjDZ6OP3jNXxI1Yxaw2Ni5WW2X0Jk9dXvuweU/t2poQMpPK+GxEPQl9h4emuqMNj40E\nBAlDmZw4pqWHZ4Mdj74o+FGODOcWTz5w+Zwfs31s23pd+41Lh/4awFYAwFhg+4lAwiA4B1pSUQrD\n1geJ18q2o5GQioCf5DRWGO9OdwEwTROAYRgAkhtcQpY279FjFBRgaJY1m0nVxOP2um+I7QiAgMhg\ncVd3cizmAG3HQj+LZwBONBJKTEnFRqTjWqESUUw+SEgACiEQUDx1ZEHvvErVAtCd7RzLTUgqWrYD\nIJ1KqqsXyGaGYdBHd3PVFbxWuZU3aKAzCyBXKbkCUCBQlonoGoIMPGP5VwF0J9yNNiMgSGWMiXpb\njghXxyKvOYMApCoAkC9tSTTYBkXg/+B3TckfFadNAFlwDdvvvRTAmufc1vC1v163f6j4mmubCU7A\n4snA9WffHD5tWIsMnC7qAt2wVOKNzAOPylc8a95/gVIuJziXMnDN2h+4Q9t6q1BeJzGDVis2gFhc\n2/fwXwBYeuYPZBmtUsmsFKrlw38jG5+YJJTgPJqHzYRhOq7RfUNy7GWsWVLb7kXMUHWKUkdBFIol\nuaJr7kPuP2s9pFq7eZ/frBkhs/FkNg4AuWoZ7viQACjJF0V9jx2TkasUANI6KeYtmbmYShkAxsuh\n7kcAfOcRAYi/OFmoCfUtJ5VdHtZMgN5a3ZZoNKNfVFPPriFQz7JGbwVBky+n+AGaMLB5Y9dWlNSU\nWgZF/a5udqIAgFIuV09Tl4G+f+RAsQBg3vxOALF4OIPUt4guWdG71dt4IpMQzXk4JcztT/nr6VPb\nSsyTuqgUhkFIwQgvVDIVS2DD0trXm/dRwcFE1YruMNlYAkA2RgDkS6WSXSc1SjYIkNBqcdIFyzU4\npnVSLFqQoeSEpJJ6Axvxgy1Uzvz21o1l5uCLWxJB1k23uloE90jUH9cSWhNRJGKX4McZ6t6hi/cE\nXkQbaZcVjTu53HJ3kgwUvJZy7EtmQnDEtGzLXLayD0ClHKFVVSt2pVCNp2O+XVTiaJGQBKbGeAbB\nNq3OM9YAKG7Z628c3bRNrtA2eoOkooRLvwbUDyCXyi2x7Yfkt3qSSk+IVQruLgCSSSa9ejVEXpPs\nVGUbnvGPJPUAGz0nWUzDZNGmQEdag8B4hYbCMH/4EAfI35xWDvHQPWzwl4xweUc9lmZSrrYlyvNG\najcFhOk5dX8Skat1n4PaqfAeQkJTGvyP3sf6+FKPgcHDCQhxxLQALFvZ59MvntAqZTueqAnD/GSp\nZ15WrpdKtXScE1wSYvrCcOKR7Z1nrEmdtEx+DLIRABNCqe9VJqsCKJbLhhYDkH9s9yErwre+tCHz\n3jRNn6W6ptI1C0IN9KSkYqRFx+0E8zoS+VKZUFLyBKC/AiBlAIAQpGIBEHGdTBZsAsII6U2pjYLx\nJ48Jl4ce6ogSpl9TnbPl18GGvmfQ3yF4+GkKwBYM9LcHsjX82uJJPTD/YU3EhSvClXKTgotIdo9T\nAiCd1iUDJ8YK8xd1SQaWSpavgkoG+h99nPgkDIExDmA8V+3KRhekADDxyHZ19aJ0KgFAWzlfbjQM\no7xlH1DXT/bf9QhJxqx85ZClbFgaB9A1P9XV5LAP3vmkXFl+6kDoqyYykwI8FifgACXR0TkCmWQC\nQDoOgBQqlcAblhTddZHUCAiRhieLIxHDSNEB0JvSUD9ovGmTGKCVIzRep5TW0W8K7vmrAsSdHrSF\nuunX6G7JQKFqxKmbNzKMKGtK5LeBjfWV1Woz8YKQyBcA8TgaPJy7nk67VoaJsQI8dXRirGyzOl/0\n6GAung53vD8XErLpJM5XTScFFIo1d5yuKQA4CAWYEAD2VT1xV7EAZcPS+DffcdWOXS7NPvqbPeGD\nApKlAB7cdATA6WcvbaavBkB7z14PYOSBJ2LxWkXranQipEjH42mvvFuxWvVISEo2AJHUicUJCMqm\nIEDCoKNFpyetdiXERMVNglUpBTDAq0dorME0WMObl09MdeUuvnxkftPvSHClhQwkaM8g1rqNa4FB\nMJdXpDQarLvWqh4qQCgRLExDtT+WLdtV06lUrFKxAqCzO131LO1y+Ce9gqODOQByWKgpNXXpxCfh\ndA0zVdMBUNy8N7Vhmb/RshngahE1+gGP/Hd0taX3Xbk8+DHEybOWxh/cV3n0gX3rAyKxNSF7zz7Z\njxaoPL5HRq4CiCWaSEggphsxAwCpmFbJEiAuFQmIpgIgZVNkdVgV+8w+sk01xkukJgnkIbwN7VOu\nEX89cBjAuwEAbxo4LDd+5ciCuoT6VqormapByJoZLQYjhFf9emv6wRsfU4XygHCz0grKNgUqFWve\n/OzhA+PzF3UBiCe0wcFSNqM3Tu0RYiD+HEjYPiT9fIR4KCEZuPV3/wOg8uQ9wa98MdgIn5M+G89a\nGocnEiUVfU8GAFkSLFwr04NfIkAiZhBCKYBKdPkcETf0uIGKaZVsdxgmZ15MaKg4WJihgFibMLfB\nQCDV+M3LZk68KfGmAdcK9dXBhQ1fkoaVlmjDABg9WnRHg1PTD0AplyeetZgQKrzC7RNjhe7u9NhY\nobM7XSnbnd3pwcESgGxGz2Z0AFbV8TXSRkVU4lkSuggxUKK4eW/XGSvlekcm/XB5EMAP3nrSjM/y\nviuXr165/nWf+ZX8KEXikwEqImCDpRBBHgZsqjXTC129wDCMyua9BCTulc8BQaEYnoItbuhxgxCg\n7NhlEwDKDpIqAbCvQPoSZLHh7De1q1ZMu+D/wZwp4/9C5SLkEzVUOM1Z8sZ5BwEIxr42ssTVSsPu\njLoZ3QKI9ARGiMEWFC1ZPOWFLu46NA5g5YLaiH73kXEAKwZqW6QwJBRDgWkRChUHQD5n6jGts7Nm\nG69GxX5IJKt1X/25kzCSe0GMP7JL8vDhu3f69Nv0i68A2LP78Aue/7xpnW71yvUAvvmOq4I8BOBT\ncUp4NtXwy7tz4yoCMpqbBAHdOZxOKbJNoVRnGBBAQtUSGkZLNkD6EgQApWRRJwOwCBFP41DONDx2\nF7yY8nSspuXHPOOi/ywNtfYvANW72MGc13cDMwfO64gRRXnjvIOCsa+NLAVAC+M83V27ZmkxUXVi\nt7TNRKGFmVR+uX88zx2/uKJLRUWlvha7+/C4AOYnVcC1UpkxFie61BMUVZczPfYPuLUzfZ+EJKHN\nWKXgRj52cggZzFX/6/35knBK+vkYf2TXhJoKCcA9uw8D+N3v/yA/TpeN33zHVQBCInE6B3C7jTuS\nDA57BPiqPrmaTWSwaTeYAEGhfujYk5TWPHbmgjqWHpowU3EyVhYAypboSRDJQPm0JPdMB6GHl4oT\nAJqGYkXIBpY3v0BXOjD+odS7ShmRRwAMTlYBECYAXKXtECp+m+8mhVGR7pn6/ltCCEyWyxCwTEfO\nXatQAGBMUIUCUHXKHU5VCiHAiagZgATqZWC5UJBfmTGnUHGqHq/KubKRVFHvnZc87OxODA8XAMTT\nMTmadxnYgD9fEk4LnU6xdQOfjctXNDcGNiBExdbwwwAiTTgVM6Dh1NRVkT51RUc8deC+TckEgeJO\nMlguusS7dAVzpZMnmhSCaonLhOREjBCbM8ChFAHJVruk5lsMb7Idu1YFC8xTUEFqgtRhAoDwIoqI\nI67sGhMqgLHfVNfUHX2KEJ7ad6OTpe6OpNxmmYwqhCpEBCzknHFVV6QMdCymqISqhDlcUSmzuTzR\nrsNuqsPK+d3lqgMImhGFisMDGXCSgQAmxgqd3enJXHFgoDN0WR0OH0MrzCim688Sf/uZ+9tptmf3\nYbm0edj4+vN+9MV/h6eXAuD1b/mRB58I7aJratCK0w4WnXtqbVYwQhJJ9ZyBwjn9ucFcBYIElUMA\nQiFCo0KjqkIUnTrN7ctyV0EwVuZy8bf4C7M485LNVM5VzpnFSeDyVYWA1hah0RKhZUZB6JXGjitj\n26+MbZ+WtWa8UBYQI+OF4fECAKoAgOMli9m2EByKRgXnnAvBBXM4s7ljc0WhEFBUalvMsRkEIEAp\nGR2ZAIRl2LlJUzJQ112ds1fTACTTiWQ6MZkr9hDVHiz4V9Lh8I6GGYcacYJLwpkFjjbD337m/v99\nxzltNo7kYXBjUIP90Rf//bq/ea9c31GmqxM8GCIX5GF8Q53zQ9fUjkxqtLFmhwAIcuVCNhGcmE1s\nSHg2T0FBKLgAMFoFgJ5E3UH8gZwv3EIDQjE1HQCAGpR4Yy7FK9DqlLmaoHIFAAEcTzYqKhJ+r5RT\nyQt+ZcxN8/pNYal3e403DACjuZIfTa0Z1HE4AFafM63q1E8rYQ6nCvFdiACsamPhBVHS7LiqmmAA\nsh011x+AZDoBIFG1E96rRfKwmfLZiBOchM2QiM3wxqfFw9aQGuxyz7HxviuX/9j7qpGHPipuxnAt\n+kr+6e3IAihWtLFcrvYNQa6c74inAGxITYBQgFZMLlnkCHfO2p4E4OmKft5jOkUBaBqRwzx/jKer\n1B8QevIAab0VI0XDO0LRiKpRAGqWVnMOAFW4syYxB7oOAJZnhbFMAIgnAODK7H6ZqPbzI+ER43i+\n5M6NJoQQ0A3KHCEYV3UqOAGgKIQxoekIcFhQhTDHNZbIZhKUuszsJCVwxPUEgL7+VC5fAUDz7piQ\ndSQTk6Xw/bZNP4k/OxJ+/2v/5a+/8a3vmcER5pCHLbCjTNcmBMC7Nq4FUChWANjbnvK+9+wbOw+P\nAxA1id+dzabiCRmQtX/o8IbBnRh0yxxL4eYaV2wAbneH1+Mtk+sGBZDypGLRM+f45tBCoJqO8DSN\nYIkCf8RktZzI0S4zZtdLSNvloWUhlaF6DOMjXmytQStlHk9RwFVvXjJ//JPyOKVSnomMAiGEEDJz\nUlBKmMM5EwJgDpe+BT9qyjeN2iYXnrqkGwoAx+Ly7dBJatSy0wkAyYQGIJuJD48U/GGfMlMGBjM8\n/1xI+PPv/G/jxq9+4eMA1ocy2tvA337m/n960aI5uKxpQlu7RGb6h1KNKWP77nhEisees11jRnbT\nHRsAACqlpgNDhT82k309lXEpFOzrAHQd4wWXSbo6K4U+JCGJRgAIO5qcikb84YN/Sak0BVAscN2g\nzJbNvKxtAMA1CyYg+Df2dRBCHIdLpZJSwpgABGeCOdDjim0yTae2xd3qUgAAI6ECIqh/qjrNsmJQ\nBQkyEMDwSAFAZBzDDOjnnrSd3U4AWMzSlXAib0KvpQt880v/BeB1b/nHNg/4iV8fODY8rJitnGNd\np64BMPrIdkplgD8Zf2j7/IxnG6BUBZjFYwnqlKMZaFW57Og+ilGRN5o/30ag3IcvAHW11m1NTwDq\nU80uLoeFaE5LH8ErNBkAWns5EIDQ1y/Lg4uv78tyJlSVCgHOXb1U1YhdZfDkHgSId2GOzVXvvrKs\nWDugh0lKUar29aZbXx7aY2Aj/SROZOuo/1r94Zf/G4DFLH9pbKwruq7o3//KZ7//lc+2efxP/PrA\nLK8w0p+x93f/I1e2BZIbLGbKpRw5jRQliZOXJTYsPzlTODlTUClVKSUOiMWZxWNZ1WcgNaiuQ9cx\nPuLIpcXlzUAMVkssRoS/UAVykchVRK4iqoLIxZ/hinhM8E04qTSVS+MpJPPLPm85B+cggELetDL/\nxhUFW5o6VapoVFEJF9LMCdWoueDdBbAt3qtVejXPSRtiIJBMxkplu+S5ASUhg14IwXlrBkZyjwbC\nR48iCSMSr48btCbkseRhJHweRqJsmxYLU3H5wS3LDzwBAJQ6gMO5UCFUxLJqNecoGlE0Qr3Il2KB\nw+voLU6kq9xfxgtMLqkY/MXnmCNEtcSqpUa74hTgzF3yjruYzF1awFBqYlYlRCVEFUIVgglAIW9Z\nWwSEohLB3dEfpd4bWYBSEAhA9KiVHrXSowRK19V32A7Ok0lX7R8dnnxq34hcDzGw9Q02MpAqCq0P\n4D6RJeG0EOLk97/y2Xw803oXiS/cOviFWwfn8EoqT94TCA13f6BsIp1NRChFjmCOYKd0FN1xjuxr\nnMuuSRxIBob2iqRfwRJy6UpDLnMOXSFT6qi+OSeSh/IKg1uIRmqC1OLE4oSLN60pvWFJDi6tPG+E\nzakCAXSr1R61iqkoJEeDAEaHJ+XKU/tG7JFC0x0aEMnAxmZ/LmPC9hGUjf/7jnOm9NGXqnYypn3h\n1sG3XjZvuudq8CWGQ8N3lHF64GMjFRfv2wTIcREAqLVJasFsIQddU4644FamaQU9qqcEj9xI9Wlh\nSnJKpHUS4iFnoAqIRoQtFI0wWzBbqBog8NerigC++GSCaoQqhABZViJKc8EjImIBSqVqPBmrlKoA\n5idjM7a+oAkD8WciCQkHmWmd/za9EYWi+fGfPzV1u7bxpJepWNi0p7ApIkW4BgKFoGyLcj3ZggzM\nO6gKMqWal9ZJWieWDbkcSzTUYa5DCx1VDjhzFSHloaIRNUHluhxhvmZREUAHK2ZZkQSiN6akk1Yo\nawVXWY0nYwNxfWYMdGLNai24+DOShJKHNndNEara7r1LHrYQiSUvM0Xy8D0vWTKLywyjUnIAHLp7\nK4B4UgXQdfqqxXsfBc6EdLgLlJkAkI3XOQDk7JqFlmHqfrdu7W23nJoktAIHVPkUktCpL0DeyLSg\nTGshDA3FvVSTNb3UXEW4R7AQDxjCU2n6KhRSaXrT7jYY2CAMOzifpLRjRvRjse5amdTmOGElof/K\nWzE/OpPS8dDmAVs4JArlYJQyPv7zp+TS5pHbR6XknNZRXLxvkxLQqQzFlWDyozQ8NgaptAvBLQdy\n8RGpi845DCW8IDBSbb2vpJ8/nuQMgpK84wpDOQC+dkWNSGQ6AY0zYCCPd/sM9IPOLSUbueMJS8Ig\n/vXG92qaLhe1SYdyApBbfvqpG0JtmvFQVqBpxCx5KDXSQ2rtrf6cBVUHNDJHtmCJXEVUGmy90hYS\nKWSkbPG7u4TV7kvpWCDIvSAzI9F4m2md5B0ULOFL0WtX8CAVo9FOllRoDy58BvJED4v3uGZZ1xHi\nJ5nBUrKCM7n4u5/46qimK7ZVN5gI8tCJ6nQtxKPk4Sd+faBQtkPck8JwduYJIKpMxte/9B9veMu/\nXrjIKlSRitd5xuPhAIQ6hAZRvmyRHyP1Ol2jVn24s3xC/jMLvsRIyyDunaVUaMuuQjK0ZWU6HPY1\nXUiNVwPsll5Nk7k6raHgikXs5gMKoXS6QZ6RkPQjPYtZpeLOv1irxx1RzNTSunR7PLh1ViRc3qUD\neMxbV2nDO4RQAKYXs7dvfNqZ0XOFycIEgI50ONfLJ6RcieRkI/7pRYs+8rNoKWeLOeChj5+99aRr\nvrDl/z78rgsX0UKVp+JUMjDkkasNh+rR2tpRsEQjD3W1NingruJRcFPUY1chyZtUv1jdWQ7elC+3\nm8H/Sppw5MfQEeTGtE6uWMR+/1Tz3ynKTBrdkAvSsxiuwBN+VGrLgaCwtK4gPaNJKNnViAaaieZf\n1WB4A5g1vbXhmRnIsDxm5JwsTCRS4ZdxECEhqa95mbX9/0W2fP81S6bk4VxZaFTqMpAqLv1CVpAQ\nAy0mpOxvbW7RFVIzzBhkx1jdk3Ga/6DHBjsmIiaElNApXd3dVIQGBX4zY09aJ89fInSF/LKl4XlK\nkN7FknC8XBZTsq+Gejt26EtPoM3RDyB4MIc6CCNgWvDJefRk5kc+/tH3v+d909pFEnLpyvVoUknt\n/dcsARBJRVu4384S13xhCwBNIynUgr+awRcFhkJaWDJ0hRwphhXFI1NUDjju4L8y9lczAJZmo28g\nKB59mAwWE90JMVbG1cub8LC5MBRckN7FfjMB8PK0q2PVVS711+aYfjNCo8w0GZ8BIX3T1/e+8J8f\n/s8b5bDQ0AwAjuU0s81E4qz33PTgx69dvXJ9s2R5n2w+G+eEfkFYNpMBy9IfHfrWKXPDiHjT+WJw\nx0RCn352s8rJnAvD+UnXl3O4FJ6uqH1E3su+XO21MpAqNmqtoS1pnYyV0Z0QBZO8dCV+uqu9c3cv\nQj03PQbWld0I2GL8z95KFLHd7ri6R3t66dcMhkIlIWfGRgAK46w+SKLNgZ/ETz9zAyrhAhORmHPu\nBdEs6sVpmAlYvvKPlJJHZmvycHk4P2mvSc/WgHETAGBjjyePepoGDTw0pBwszspUIeW8Q0Wj1Ucq\nCGmdeP5GYVBu8iZvqABnaGYe1/SgndMHTcR5ue25k6N4+Iyxjko2Sn21fTYqmvruf33vx//zYwA+\n8JEP/tv7P9yspWRmpJCUwnAmFz0XuH4g337jZuMoi/M2heHZ8yKmCj+W2NjPlibC0ToVz08zUaYH\n234eQWNsiJBSMMqoINviL1+Jn+yqf1PHuoMfVV1vXuK7KaLLUjXw0O1zP7r3tW0fORqzP0ILXHfe\nd+WK1FclGze1saPDXKEnNVITpk69H4ZHOSfqhaTkpBSGL3j+8/ySasceMgm9UReVW7Y3t2H4aOTh\nMeNb2piVklUJeEo7E7wz4YrlH07nID4hFyVqbJSRQKkYilW8fCX/wcHeZrs7hRIANZVoeifTusV6\n880zRhKG4I8el3bpLQSjqqiqovoaqa4EDIB06nv3Ofk0CkN5Cc2udXuulbHXx8KUszQzK5VyKD/t\nNCUfR7xAlh2DUxxk9byprE8N2DDPFZubB91xZuuh7IGy+8SkbJQ8bNNK4JQqSjI+dbsmM180s/U8\nU0now1dTm1HRF4ZTIMTJejn540++L76ma/muJ9uvZTgnSDRMk9DoAW+BM+f7nX4avsvxKL7Nbd26\nZohkaVG4NOvtaGXO8dkI4NHhqTv2rkJycczNS5Ik/IuFIy2EIdp5iFH097c1232aJCQ3egcOh3TV\nfdusQZuHbX2WKETab85/7rr//d43/vr613zwgx+94aMfoAr50Efe96H3f7StIzZwcuv2cXi58MeY\nigD2WGkAaG8sHODeFIjk23GFYqCG1chku5kd5/W5Sc/3DBstmu2vpgGsTNVSBFt56QkA8EqFxuNB\nsgU8CmGzaGC/OoTaTJOE4oY6pjV+C7RqEAnZXh6Z3OgexD+Rv6U9SDbuHHNHO1zwL//wO3/7qtcD\nUBTaYpbCsuMASDRLraAqAH3dddbWHwFYvmL+0eOhnK8CwMZ//MnV83Ktw1aoF8I2P2b3Z1q9qStQ\nKvlZeV8Ho+cMngaGq9GKYl9s5kFGkplBIRlH7c3isxHNCbmrmJY8tLwpBVrWb2x1MW0PDOtOIqe5\niJJgjeKokV3TF1ntYkYMbATzprBqdFREolwfNdrIyWPDQwAb//EnaCNwbH7S7k/KnzO65wSlR6pt\nlXI4epa1o4Vm5AQAsETr6DsAgdtc3NH0Js/rM1vwEMDiWOG6+SM/OtzbhIfuNlE1iTclQavgtOgt\n7j+sPOpvb7hiv/ejXrIFtwRbTin9pHybFsQNNXk4CyjE/fE+/92vffCDrhb6oY9MI26m7DjBRW7U\n1103m6tqH+tSTZlwep97MR4DwxiZtOUS3FjkEY2HK7xxmcVVzz3KJgstzVqmqBjPM39pbHBenxmU\njSFI7XQKkODEvo1fNqDOECpYaYyVxli5bnIK700v1b/W2mb0aadqPzMiNWN+e1jVHVtwymouuM9D\niRYaaUjolaMSKcqOU7CqALDkyotPnb/nf5p6HWeJjf/4k2YMPK+rDCBqCjOgjVHT7Ak2Lzk9Ew0P\nlABuVDtbysCmiORhqsEo6vOwK1PXDZqJRO6I3XnX7hUtDAncOUXrJ2mjiQQvtfDXuxfGStETw8za\nOjrniihQex3M4KXQACaYpGKbGqnElJy8fdPhl77rg7Ii09z6D+PrzwN+0rj9xUuqAEYb6gxNSbwW\noqMF+uJ1z2pf1Q0k3NOks7Wuty2xoxxOsHYEBbA+GT6o0FUAI/mpLTH+3ZUbrtnHeJ6FeHjJPBPA\nbYMRVDwzVXm4GEeIh/WMbCEMgTqvhFMabdFQogkJfTMJUGcp8SnhMyQ4LAwSJmhuQUuuRp4reJCZ\nghLqC8PPf/dr/vYP3fjeD93w79M6lM/JhJoCMFQuArh902Fg6TnaPjm1y47pOzAi646e9MJ/CInB\n+UnbD/jqSdPRQu3bFgxsn3uRfNt3DCNnniw1BBu4HnXXTb+u05U8rWnpy/lGNkqpKKnoR9peMs/c\nPkkbo+R8HgZACAJlPJtw0N9sF0ZaXGcIKlDf9X0CNNJmyi2RTGtHVM54x/YgheFHbvzEv374PQDQ\nXmGvFuhPeM46QfZhw8vffsNDn3q5b9XE7HwYIQZKARjEeKnVa3hK7vVmNGIzBITbseTbzLB1wmVj\nQtUALEm3q3WH2DieZ5SiPyAV13TwNR3WrQejc/eCwnDKHEMB2Pnh1hcWiWe8s741pDBE0EyqUMZ4\nQmuZkT5N/ORzN+4Dljqb/S0hEdcOJ1/1v0/ib+tKHjbSr9GXnSK8KGg7xHuq4BrxnyoAmF4SQ2di\navukRqZWRxdmmh5nX66twWHZIQlV+PcC753SbKw7XOFBHsqQg6E866+/koUpZ+qocQKfhqEYiurh\nve1cfPMDH41B3bN4Fi3xrsujAz/LTbLsAQx7IZ8J1W3z3XteCeDV531fflwac99ZkYSMtCcFqRgU\nhjql9xVixMuXl7YYUBBXHyUA9j5+FYBlZ93SDgOPHHozgIEF/9e4ESe8JHwWxyc2DTcNG1jVFS2l\n+7wgWV1RxssRkt/XrkGwNFYNUVFGGoSo2CgSfZybrt5fiAGe1KNAgIG+JJylDJRwSXjdc74940PI\n/IlWR2iSXD9L/OieVyOQYBHEcIk4jHclVUMxF56yHgAXnAn27te9TQ4LGeP/eeMnZOOl5z8KYN+f\nTg8eQdakaQY95vWINqerBQC8/J03/OTTNVPTjf/6wVCDH953HYDPvexb/pYjExG+CGnW//K9bwTw\n18/5qtzYFyMR5g0AnujoakOl9CEAk5LdQ65sWdPfNGp5+1CrpHL/h//DptcCuPTUb/9x0xTZNjvH\nw+O9IC11haKNe9lXjYEgIcJG18ESjxSJaUM0pnoJIQghIJ5RJsjAhpjeaYHUWyVOTElo2kKhGC85\nXUlj96O7V5y+ghLKBPvkNz/fpqNCloRqRkWr6ulGGgDotK2g6iADp4TMWqAKCfrZGr1qo8x9HYxG\npfBK6aE3qb5eDdBsxuBcUK/G6XTfta3b+4IsRMuTeuv8CkFChiRkmSSAMBUbRaLMtLpyWeU3e8Pv\nGgEQAUAQQgIykNCZxrOTKKPgCUjCK685X6HKl75xByB5qG65f8dJ56xWiMIEu+H9H73xo+/TdOX9\nN/zTDVMFc4eqszXlJK8rcNIOJxvFYDNIHk7Lqd1Xn95kMS4FyJywrhEbnn928GPRbCobl10spy3F\nvHNWBbfH47G9t2+mwNrLzth26yNyY2Q358CWkaYhLz4hBTDhETKSij6OTDjpqPypeyd1Qj1pKCAg\nCHXFHyEoDc1kNq5IBuKEJKHEW17/XJ+HALY/vHvVGcuCATRUr68aGoiB0JrYTo8eJwFcOL/qGyuC\nyXuNYdOTPEI57IvKK+SaEsm6UP8On2CFO7NNb2cGwMhDO5peNECno5C3wOorTtl18+MA1l52BoB8\ntY7Jh/+0tdmOkpMr5iUAxFjtuUmLbpCKyxPV0MPkzQMMeparo3sdQkiNh4wThYKQ8sihad1aM+75\nOAFJqKsxAIzbPg8BlKts6wO71p29UhKM24w2KZuNekKiJSdD0xuW7QilsIGTxvvecyPqCxYtzNR6\nTwsGNtJvaZagwagY4J6ryEVKFWP94uDH1lMCP72Yf/46fz1fKuUf2x/ZrOop3obHxiAV95RjFhcd\ntAJgsMRDMXQPjSp+NvCBTgMCPcvU0b2MENdACgCEVNpm4JTc83FMSNi88OHRg0I1yUMAX/rGHY4Q\nOsjWB3Z9mvyf73YNskvT9BD3fPjbm7HRR0Krk0eRnATw0Y/f8L733GgFyj/PT9jmVEGdkQLQPa/q\nUtEbPtloIF736auL5nHvlW8PmdMWt25gUmIEZoboTCi+SJzkccnDIEYL/HDJNa4e6DQAqMQZHysB\nSdlX5OCwfQYCEEy0ycMTbS6Kq192kb+uUE2hGoA3/eUFKiEyW2zL/Ts+4tlFP/jRfwnu689XIZfZ\nX0xCSwaXZs0WpqLDsX0xOMnjQQYuzCghr/emYWvTsOUbMKj3uy65eAOA7tNXd5++ejY3Mi1UKtXQ\nMjaZk1/5K2XT9JdZnm79FWdEbjcpMQOz4nQmlFDIgT/MHi3we8brDMvjY9XDOxgAPVtyw0SFMCen\nPRWsaCOeFiekOsq4DUDSD65IZK9/7fnf+PafZEGRN7/93X09hFtMU1u9qEI8bCYn20eQh+s77Scn\n3Cs8WFSXZmoH5xyUugwsk0QwMLox4iTS4bby0lMA2FHzVE4X+WLbxfxmCsnDyvTL57bAziOVVQNx\nlRDTkzJSMMoHmK+mqOOOEeI632fWwso3cYGxKoBYtw2gqzuJbgzugZ0fmsvrq8eJJgl9SCpKyFHi\nm99wGfxZhwQA2I7wB3UtprCXmBPZ6ON17/tYi2+loirNehKN0k+CBn7C1ZeeIpdpXUnFtOTS+NUx\nYGAz5Eul0DLdIyinrt45WJHThgMwKQkF1vXFSDxrIFCJeJMIOwDHx0rArBjYjjA80SShHArKdcZt\nxplkoM/D//v6rQCGx0RfNwHw4Q+/D394FYB3/9MHABBmf+K/6+ihK3PJvSD6EnTYK91792H9gvk1\nGgSjPaaUfiunz7rpXWhrHKvX+LR4KG22K684xbLEU7dvXjUv7ghRJDQl3AfL1VRcL6BSebTgJvJu\nEkimdAAj28cAEL2DEC3WXT3w2ExisoPwediddPvSWKnuJzjRSAhPEQ1S0VdN4fFQVxHpsheKJtno\n45Of+LdQm7mi5T9++MZ//Zem3kIpBjsTii3c2OgqiZCEzRg4VixkEmHXyPFs/5wliFMzKQu17kEt\nuXiDBey9ffOK/pjkYSaGfBUAggwEUCpa5UNuvqawJqF3lA7Mqox5b0dczr52pH57d1KHSv2g/hOK\nhNe8/DJ/3aMiQxMeMofZXGje2F26E4PoSqrwJKQPFfbHPtFKk5wW1qatbQWX0vtKtZeCz0D50RaE\n1YdorL70lD9GHXCs2JDze6JjPBe+5SAhfcw7Z1UJSO474MtDn4FPqAHWBmtRmJMzvqrejnbKk7o4\noUjYCMWbyihkrXnbG5//g1/8vvW+IVpKTjoIi8rZ0PJ17/uYLwz9kYmsBBM05T05YgajN3mDxWX3\niDto6YhPXYr7aCMej56fHEDCq4/kr/joyqZnq/YF0URJHhnoGxgcgUAmhskSNnEHgAIVQKVoAlB7\nE85IbSQ8s4lEp8VAHDsSPh2uwkYEReKyVct379jtf3Xu+SsUQv90985m+/qcVD09NhOjiKJlSIN1\nmKMqTZ/zf3zswyGldNSq66BPNkRpBYNUxoqFycocm096Mxm5UmEWAHMOjKxTIM9zXUgDSBmuAXlh\nNwAcHJu6NkQkVvYaHfEsgBFrMvSVcso6PPZE2REHOmNdMAAcfHxU7W368pouD6fLQJzwkrA1NEr0\ngCuJCX7u+SuCDVrTMl8N/zaSliFOMo5P/Gc4aTNIy0Ye+mKwkYFzBZ9pTzvyPAdg38TBxq8Wdvc0\nbpwWM3uzHSO5ydDGIqEUdSprUPrNBjNgIKYgYdBc27qyTbO9AlDqi2GxqPJ7s0do+BdT41Wn0qKB\n1dyZpgneVS695rReC2RE1UqaESei1zKf2j64p8yHLFzUpegUAApMPJZz+uLaKl0crLD9FvEfgqTl\nP/1zXf6EQe2PfOwjwS3/8bEPA7gJWxCIQvYjlXs3rsaBaUcMx/W6xLxU7Ghpqkw4CmnVkQ7noguu\nSPoF8dBv7tp45YWtTxfJzCkRj8cqlSqAg8OjA4TcUmFd3vNYeErPwcdnKHKDmBkDESZhiyypKROo\npplhpTSftWOW/AwN/2Jq3OZO0G0IwOYOAN6yKERciJN5tcqEILhEtb5VcC4yHJU5i5akX6aR2x1t\nCZxlCp/IVe4dtcoWF4bYmNF6NXFwhHPvaeSrHPU8T8YUk2shWjaKSgAU4JKB00FcCw/JZku/Nn6N\nnWP7/HU17vbF7t5+ubKsa/XtAICi7ppnS0pl6+YxAKvXtlHqsyXi8Vibha/j8VgwQGd8rNTV7Wq/\nQnByjIdLTk2N8kg4uyTFuUUkP6fLTMupAtB010zvi8SgGBQUpIW2L4QKkXc4AFulA8KOMfZ/4yKR\nij/HrK5V7FssTdXskhE70J8+a1XCMNRcYbI34ZhHcj4JjYbJzErVOuonYwp8UfngX/jbt4yYFDDW\nLmzzfpOKgSgGHgM8efMjAGIb+0Lbx0aGJA+p97ajlkvCns7MyuU2AG6B6u7PHTurr6O75yAfA+qK\n4HTYc3ZT3R3ZSqX6sy3j8mPp4NQeCM7b6nkzFoN4Bo0JfWa2YiOHAo1BSkKFcVayiskGHrptOefN\nK5pIUGCeRhghlCAOUWYipSkdmbgoWVTwuKEqlBEmDENLxHXOhapSMGzcuFhL1IwrZ6xZJiMEIhHi\nJIA9Ob482/KtHPgyrsVsaw4mdRl7tGm+kizsMCWqDw0nzugBwEslJRYjjAGYOHQgNyY7+vpQ+4GF\n3UcOjgE4vKcwf3krefjkrY/Au2mZ6NSIXSPmyvpk3/2Dg4vnzYtsfOW1Z//mpgemviUA7U1nFWLg\ndA2qzxgS+mihx7oNoAFgXhZPySoCgBrTqBoUgxvXrRAHd1e8LTzw4Py8aQ6MOWJcYIlGRhmWKuSi\nGBdWaZ4i7q/AicmR8tTKkIyYC2IKWmYpBbSTFmIO+BXGSIBvc6uBCaIAKOQs5Etd3a3E19joRHdP\nZ4sGjeAABfyUXwDASU1bzxHaEYOzZCCeiSQMQXKyUTwq0BRVk0opAMup+qppJIb3PtW3bIlcl4Qs\nCzxq0U4ICtxUIPs1oyTEAKsaFes2B8NaPKlpO0ynygVVCedcCLGbKZZDGaBw3roCQoiWjNtf/ead\n/sfNQ7bq7T0ykQfQVb+72tIQEgQH9t77WJuNZ4nKw0PxM/vbbDw2OlHMVQGk0rovDCfHRjumaXd5\n6vbNlKBFsHpvtkOu+GZSaaFpB9Ni4AzoJ/GMJ6GEpKKmqgDsQMl6GTIqqdg4JgwiZYQfuEXpYEeH\nn76SASzgKSQchykKzSoK53xSSwGQuhQhJJ9KIuUGCEomt1mMRKHam99w2e0AgLe98fkAvvT137az\nYyRapL1GItR3VvTXCbHdg1N0Wd90lC+WATudrQvry3Y3zeHq6k+MD7m+gRZK6fwXrD/8uyf962z2\nQB0QtV4rCWmkko37KxEZSZFWmTZHg7PHCULCICKp6ItEHw/ecvO+EoXjmsuGJswVi+p+Cd5k6hgZ\n5MQ5Z05dA0V9mqMR8o/tz7fd2GeacXJ4tIaA0xzA7l/f1f41TAyVOvvbmsG7ES146BenAbD39s2R\nbQA4AdE1eP/Oeees2j84KCN4fHnYlU03RrpF4pjZKk9AEkq4VOQOgErVnsibmWSsUC4LQVMJo1Q1\nt4wJVeGO7Y66ShabyFU0TbFtBiByxTRtQoiqUNthuqowh9sOixma5TDOuGFoFnOEELqmmrZDAE1V\nBCeHh3MxQ6uaNoDGFV1D1XRASExXgHkAKlUrHptGjHg7Qk9SLpJvc4xZGPrnL0/39SSBmvHMEhEm\nx2UXbwjqky1UwMH7d8Ij8Ehucmwyt3bJklQ8iXrbzFyJwZnFuOFYkpBxtD0n0gxRKhWTybqBn0ZV\n22HrDz7yyJHqkXjn87qtTUfKxYGlZ7LB+OLEQ2PVa9Z03AwA+Ou12SPmeEVLLlLKIxahRiwlShPQ\nMormVEoFLT5PxWSpXI6ll8WcocnKMElf0Ml2DJf3WsnX9vJHhyo7q8lX9bHNI9W9IvWyDmvXuHWI\npM9JVAf3Tqr9ff25kXFHiXdls+NjFS2ezcTzw6NId3QZGBoa13p6+4gJrAFgcTMyBDkSB5tXQFrR\nHzNOXb/t5keWXLyBA3FleqXvjyqkVeahe3YUCg68ciyn9YSNmSNeiMLC3qXNDrXs4g17b2sqGxGQ\nnJnTFu8fHexKphEQjM3QmoG9HfEjUdtnxsOnP55zblEqFUulYtUKRMlYZlqnrzslC1XtNJRr13fG\ngYVp/Yo1Xf0JdW2Pa9c+e1Fy5bx0p8IvXpLs605mKb9qdSaRiqcpv/6kDqZq3Zr4y1M6JzhZGMNr\nT+ksMnQbeOXJHVRR0jH68vXZpKH0JdUrVmU6NKzsNM5ekunRxWn98VOXdaeEfeGS5PIFnQluX7kq\n09/bEXes60/qiKXSaeG87tQuUzV6FZd4evMKVC6Ia7VvxIr+WOa0xXIxTj36cg/g7YdSNUebZSCa\nYdklG6Zu5KkM46WCdGxKNBODLY7Tk4me7nfGOKHU0dPOvBjAYw/fDqBqVUARU+O6WYprpGCLTkOL\na/aQo6WFFVfpU0xd2puJew8grtJDVWQIj2vawQpfp3NdIQfK7KROQQmGqqK3g9hc2JwkdFq1ua7S\nuCpytshq7r49OuIa3VMhPTqJqfRQiXSrPK6R0YoeZ4W4SoYcpUvYMVU/YtKTFEchxmCVrNcZ46rJ\n1JRX/EsN5CtqumraTSYEDcAv4znSULKl9Wu5WRymjJ9uE34CfvBSbYdrczdIPjiyL67VXBrS5956\nl/VXnBEkm8Tgn3YCoMA3v3Zzi31biMEpGTgDYXhCkVDitDMvNjQDwEOP/qHqVLLjhxMpOmahS3MS\nKtlra0lixjWMWMq8pBpXXfljqGR/kV3WKSjBobJ4boY4XFQdpDRacbhOSVyjRQsZFXGVHjFJj8rj\nKt1fIZ0qj2nkyTw6FBZT1UNVkqUsrikHK1hAeVzVRhy6UmEq1Uctda3GhYAplIwG0xGGhrhGK45I\naohrU3XZqK4RGiC1xsySEs6+5sLc/Q+12bizb3qBI+m0KjXSacEvGCXXuzuyAGS5w0Dl0dq7SQ4O\nffgUmfFocMbeiEicUCSU3PNx5pnPA7Bv1+NjFjli0STsp1hsnGmGKO809UETiwm5f8gVHQ+M8aLD\ni1AfGOMaEeNczU2IhCJGuTqWR5cuBh0FjuhU+QGLVhg6VL6nqgyayFK2o6QdrpIs+JY8DpbFCoM8\nNiEOlsXCLH1wjE9ywg3jiZJCCKpG8skKjVFsyhEzpmepKOrJooMscSaUcISnTjQ54TndPYh5dZ17\nRX8sMqk3EpKlY2Y4WvppxNjoBIBlq3v37nBju5976dLGZgsW9xza7744EobRrDRb8DUUWfJfsjFE\nxWaYjRh0jzBNYXhCkbARClUyV/z1HY/f7TBuM3s4ljQVR032PQVecIoVpfu2x913/E/GjbKwf5nX\nAJSZ/dNJDUDZtofHNQDlqr2HawCqprOFqZRSy2aPMIVzwYWmOorDOKGGMkkshx0gcVioCueWiooK\nFveltqR6AJTs6mOJHo2qOaeC7r5HgZxTqcbiAAqsmo+5PgON1v0odHfYr7X6iimKysiU2Yo19VzT\nbWL7kcqagWmIuLGRIoC4HiZEiyiZ22/Ze/Hly2Z2eW1i2cUbWrg3JFqIwTkfCvo4YUkoKAAwzvp6\nOp936dUQ4v4Hfg+gM50BYHOnM52wqtWYpwQm4rFEPAaAgCfj7qisxUrcCD86qlAIJL2+6rdcPOCG\nu3SmEwAYt+Ne/ns8noipcf+rEEpPTGParWb57KFZH2YJZyozzMRwhZPpxdr5Gukvf74LQFdnAsDS\npe7TW7DYDaCpjk/3YiOw7OINKSO++fcPoIkuOleYUhgGyyOcUNZRQV3uBeEwhzGHELJx4/MIgSMc\nk1UIASEwkhEdV4A2Lu2cnTNuMye0AJDnarY4wvGXpkdued54PNaiosTcQp1Otk2ljcjyZat7Q1vG\nJ6Lza2NdrYaO884Nv2tae+SbMfAYOOg5F4fGKkcmair0CSgJG3kIwGEOgDPPfJ6qqPc/8LtpH9Pj\n4ULVOide0okAYAk8UEkedFr532zmhIJ1/LI3zSDD67iXTwig88wVODT1hNstLDTNRlOZ5NTRLZOV\nKQaT5taDqVOXynVDy0yUW03tKGF5RQm2bRkCkMvbAGiUNfXQ/lFfGAYr00xZunvw/p1+tfzGkjaR\nmIGDXnBO2p4mjXNxZNIEwpmDJ5QkDMLipsXNyC3SYNMIm3N/aXbYg47+WDWxTKsu06qPVZMHHCMo\nMGkbcdWMs+BiOdXGkDoJmdErIzMdIXxVsCOelQVUZoxMMimX2RykGahQ5KJTlTlELvKrnVvancth\n374pqjMGa0Z1ZafIDJ59vf0W6YKRamfkxiOTFkACi4tjKgmPdtCMqqhS4rVA2S7p1Ni48bKHHmqa\nTASgkYcEMBSqUBwWxo/K3QrBmGJ0KOBCMA4uiCPAGAhRQ8MmhcSYmMKLEOQha53w3x6kghrXNVnk\nojx8VGrVjK+Y1+0V5bGL4W8dJtS2ZyZqAV8Yxrqc6nhEjx3PFbqy6SnvUGoKKSOaTmSqWZdbDPPk\ndikSG9sEhn9/HvMTtsNDi5uqom7ceBkofvbLVlQMghIQwnQFSZ1YmqoQ0U0dAApRLAdVB2VLmCA2\ni8gvVEjEmG1KZhonRaTVZ8/ZiEBWTiOkWJARksXKrGrXAnCUKR5mseJ1fgWQ3bvhnLmce6eprPsc\nit6WhQuzBw+66m5XRwzAug2u8tnd03lw30zm4pxLTOcdEklRzsWRnGembnK0E42EPuTsK0FC6tTw\nFVQ5aVnCqNPHtIBy3ygJFSriKrJxZBMiGyeGJjQFArAdVrKQrwgQ4tjC4sRhiBuqAIQAF3hkx94z\nVkcY3yOZ6WNaGoOMhCzq06OcE0g0CZl2KszW9BkKsXRPcu9Ot4ZoXGurg2UzWi5vj46We3pqVmLp\nS5TYv2d88fIuALEuZ/wIyySTwYufPQgE4y0k4SzlOWlYqcMJS0KJkGCUk+b6s3Y6VtMfUqsfbROC\nhCpSBu9MYqAD3WmeiouYCg5YDnIlTJQwnBe6QN4UFRuCO1zA4bAZGEeuWAWQTbVlwwxabmRGb2dH\n08HblIHIEgv7eg4O18Jl8qWSP6bKPhVRazCMJmPkrt2Due64YkxxX529boP+Ja4ttHNe7Y4m82UA\nuXzEIDCeSlWKRQCKyvfvGc9mEgAUDaVANVEp+Z/87SMr5tddBudC3mObo8HegBtwNC/NJ/LTrBg4\nmHOmoOAJT0J4FT5DVLR4USfT872qFCmD9qQxvxP9nSKdVhRDvf/yBzf++ox8wczkhEqJDmKURdki\nNofliKoDSkjVO/O0qNjaLdGae0OTE0OTEwD6OzqfvPkROYNf/rH9a+aFh0OOaO4YqcdwoclItRvM\nrIZ42NldO1HcmCoePYBUMvyjxFOp4mSroqDbbn5k7RVncBIeBKwaiEvFIGEYUs43sx6ThgGE75en\nXlnamQeYBw2hTRw8JyAJW5S79qHTFIT95e9/YzqHRdxARxz9HaKzJ/bSd+7524J5JzHPG4j3ZOMd\niWpctz75nUPv/ItFxSqpOpgsOsUqBGAfhToxjdh9JCzQOp46Yj51ZM28OHt8K4AV/bEWrvbxYivW\nd2bmeGqq2KYxAI8Fat319Liy0Y+qeeieHYhyJIbAgW03P6LSqeVVpDdVMpA1KY8h5sBxSJqs13AC\nkrA56h16dIp7JwQEIAQKgaaKdAydKdKZFZlO7b0v+dM/jZH9p/euSmr/fNHt//nQZaoRm6eJp0ZK\n//uTQ+953YKKibShjZdFrIwz1i6zHPdVKoXhHGKykENgHpiOp8JpbkHitWba9HDqfO8KcgDyQxPd\n82qZnLpnBJ9/xATsXx92o13Kt+zEv50+rfPs3TGiaSqAjs5ozaUzqU+UpvBnTIneqJC0kANwBkHb\n404qlkK1OIWj9c+KhC6Gcvn+bAaBvtIMhECjMFSRMkhXCt0Z0d0JrSfWBXJEJ788NHgFV5MAelIw\nqpqGzT854+I3PHH3nXtecuXyyaIghDiMaypsDnCItnXREMpVM1ToCYGwULZlR0fUXnNJuSbITUZ3\nr2yHJzmPmABeNL/rh7M+1+SEKceEjehM6qi/364URSBiO1gdow5iLmYzbgUCgNTmtPvzloSqogaz\n1Ydy+f6OOg9vkJAEUAgEuKGKpI6EgUxK9HdgoBfZbg2d+ljOLoGu47QKfqHQhK6jUyE6JXGrWGX5\nsrqwHwmDc0KZIAmdM05tB4y3NbRoVopKInf/Q9sHK2d7teLZllr9wmPAukiUJptOdX2gx+joit95\n+x758VHP4XFnsaIF8h16e11dtFgyg0bRZsjlyz4hcwvj2YPhC5CPQpJzomT5cduRbDzaRDSSXk9r\notuesBEzU2Ko3OBdBgAoBLqChI7uJO3P0MU9yuIeZ3Gvs2TAGegn+vwEulMcKDmMjNrZJJ7sxL8t\n/wlRVJFOiXkdE4XKk0fYDV/O9ffrC7t5X1Z0xklC55oKQtsdYTw+Um3xw6zoj409/KBcH51k/jLN\nB3CMMDleY0hPp0u2ZUs7li5td0aaSEU0l293CpfOpN7pTZG79/bNMnobALxZe/tmUTx7WghGDc/v\nrP3Cfy6SsH1QAkNFykAmju406c2KdAodHch2q3p/Cp0xodBH1/V/+as/W3bG51949h8vXmROWqlv\nv+POF777dpvZu7ftu/i8bYsZFxjSnLJe5l19y0xGGBeME1vMxtDm4ljy7eqr3CFcOWoCNjEv/Z37\npk7SO+WUgXuiti9dmtm3r60Ccc0GhACymQTWJ/DkWOsj+Dyc8QByulmC444vAMNOinnZuk5wQpHw\nHf/kTjD2mU98uEUzOSAcqkRH2SsUMQ2ZOPqzmNcpFvSIVIem9yXQoYqO9Of/7vDN20Y/+bnv/+bm\nX9/z7jt+c/+Zq+ff8r6Xx8byzvc+dP6EsaTXObCoo4dzoQ6kO7kgdunJrbfvOCx2H2b7xjBZwOtf\nffl078vechD9MQCDE3PpofYJ9jQiJA+L04/wkSKx/VBayca1wLaxplp0M0yLhx1aAcCkk6n3Usjj\n1KlEJxQJfUg2tqIiEf2J1JE9u/2BiUYBAgIkdKRj6EljoEPM7xUdA3HaraMjPjr6sZ98/Zu/23S3\ngHbpS19y9vIsE+TlL9zbv2jgS789fMFp/SWTl+nETm3hZMrqI9X3vK/88Q8mMxW7r2TnSnyiQMaK\nolgmn/vqLQDe/sZ2qUh3D6YNrR3pxx1B1WiF94UvquUBq2Qajrsp4RtFxwZr6v3605cPHZnJxLsr\nVnXt3+0eZ2jE7u/VAExOuN52fxzYaKG57LI1t966vf0TdSZ1jFUAdKeNacm39nMmqAAn6FDzAA55\nO0PwgYbE5hOQhP40L+/4pw9yiM/Vz5vr4xvf+4pC4T/ShA5CQAnSBnpSpD/LF/eI9EDij0/9TWos\nedL69ZmMGj/0M11HxRTPWdXhMDG/J25CedHZa7/048M7Dxe6M3ErkWU264mTXUPmlWf0/N+nJt74\nN/HOgtM3SQZzJDUuNFXI1+LnvnoLIeJv3nBRZGbTKb2xhwB7y8HeuIG4YbXdSyQPg5R7utA/0HfX\nHS4rJiddx8zoRMlfCUa0LVjcAaCYq27fNp5N1xmQtajAt6Bhxselz18T/PjH30/ByatXdvxy1+QU\ntzE7yGlT/PwoQum8TMRP2YSEUlweBbORnDRiykld5gSSjZKKn6qflBMAIRBUxLych7TuqApRFXQm\nSW+W93Yi1Zuwq/t+97vvnn/elcVC4Te///qpRLn8uS88Mnzgwce2XX/l8356811nnty7cvn6nv6t\nw8NHOtNxIYSq0Hg6WxozGWeHhlTalciOl3o7edc4ySZEwoCqEMbdOVe/+PU73/bGS6IvHuiNtxvT\n87wXrUV7Im5uxeCcQDIQMrz7SLvmlkbDDHEgAt350uevkTd78++ebHGcsYLZnZ553Yp2FFS/s/el\no0cT3lW3EXAwh5jBNKDt8Ja7xt46zY07Air+4V8+8N8f+2DQX08AjSKuuYftStGEjrgmOjJiXpfo\n6VEta7exqP/gxKEf/vRLVdPcfSD3O0u87Tq+b3AslkjuPrjrHf/4AWNyx/ozLrnxC981Lei81GXt\nGU6sWtHfZ9nOLx8ffukZaZLmRkemOzPelUImSZIxaCrgwP/hfvGz+waS/KzLzwte8z0Hx4IM1Clt\nJgwl/Z5GvHDpgFz5zmDNQnOGoTxiur/CPz5/A4C3AAD++crT39T8UNu3hStYDI3YgP2xV5/7uds2\nNdvrZWsWN/vKEUwliq8X/PbXj4caXLWi41e7J5tf0RyjGclaqqOtZ7s5tgjxtiknG2tXqwDAIf7+\nX26kIP/9MVc7VRWqKSLh5Qr0Z3k2SVJx0dlB0p263htjIoUMm3j4QLU3kxH2KQvi9+0oLFq5Yd2K\nk7dPljMxdWLn7Weee1U+V3jl1Wd9+Xs37zhgdi0YGMgwyzFXz+8nW7eueXzyuld2/OiziXhGjSWq\nHWmaifGYBs6DznYcKdFf/Ow+AHj3Irll5J4toZsI8vDy568F8NMmD0ppI2rvGOAMQzn7+Rv+6/fR\nhZX++crTP3tL3VeNDJw/r2azefslp8qVX+6ZxkQ3IUg2+lQctUS3RuDl+w1XtHnJOknVTtZ8s/Ql\nGiTcVPVX3R/sR3e/unW7KfGje14zyyO0wHXnfTe0JVKWUu5IWdisTAGH+Pt/eT+AT3383yiBrqAz\n6T6BRb20O4NkWle7DHSoyMapM4Fkh8g+FcsXHIK84PmKvWP7Q2aldMemHYsWdJ2zpG9oYogSpWqW\nqzTJeJmATHAyX4/BsW9cSP5tkryFjCK2jCTVgZ5EIc8LJRycmKIM2k0/uUONcii+5Joz0MRVcAyQ\niEdEqzii9sp74wUny5Wv3v2Eobpi/J+vbGqA/bvLNzAvql5R1P/YNg6gtz8JoCOQNTJ8OG86pn/A\nq5e7cu87j22b2Y1cfdXpv/zVo2qgh4wXTaakAAyVNBAQQvridW6MadWwQCDsu00cF2/NOQelAgDn\nhBOAodH28ffv+UDWwIIu6J4k7M1g5RseRazjU2+c95p1+NdbF5155rWKorzznVfdd8/vvvjT+53D\n5XQqPjIxrKrqCxezH28aHt+937TNCdY1Mjp65tq+vvKRLjKW0SgXbHhw/5JO9dBB9s8sTq8ZvvuL\nikXK6Xg8EcfS7ti4QbYemgaXXvji0+bmuQCoZ45EkAxyZTZDR5+N00Jvk7mc+uZnAJiOCe/y5LW9\n5rS1f2hoHBoWQt4sq9MOHMF8BuZMCC+2lkB60wmAkaoBQgghvTHXMOtLvGmxsU2cmCSU0BQwIZwm\nuZpdaZ4wKPfCJkjp0KKupEHpP/zv9s8uyNxwwVhs7+bv7Okb6F2UyAysX2zcdv/5AHntNfsGh4qj\nJfbv6w995mF6559Eb0qtpOY9vmXbvJR6SV92crxUGLyLds778L6izWKmwy7pd4yF8xP7K0O8XKla\ncS2jUizsSvxp1+iSruhgyCAuvzoi0ko0/G7NaCMJ5vfCFgw8HjA2Xuco3LNv9IzTloTayJGe/zEk\noh3BTGeKBMLLr95wyy83r8yaX3vCfxUS9z9IHjatKhesZBGJsC7aBqZJQnKjdy03tPq2WYM2D9v6\nLM3RabAJM9wXVSLAwRueiyVgMkG8p60b9MFvL0C/cfVrUg/vGPvbn5GbXlPYtk9dXNz1GO+97f6N\n4z8+1PWKhd/+2dK/u/LxR0rOI0PKWGp+bsIatsjW+x8hBBNlceuOkgByVZIx9nYkWKJQOpIX9+g9\nr39L8ZNvJgmDxGN0x+HJnUO8N911waqmEz44VKicNNKvtS56nIwGZ4YQ/Xw88thTL101RTZTCL7u\nKtH4llGJcvnVGz7whdrUyAorMDXjSUIvfaZ5lOE0XIsUmKrxNH82cUMd0xq/BVo1iIRsL49MbnQP\n4p/I3zJNKKGqclwAdVR0y094z2flu6qnLY4VzPKR8cqGNX2nbVjzePGJu99tr/4XdWky/5LLNwsz\nccZducn8ocfHSEwjvxvr+fz7X2tZ5mMP3v/H7g5RNjdv2+NmP0E4leq3Rsmbu9jCnriycdnDd92v\nq90xncQ1EleJqpC7d441IyGltEsVZ13uMrC1ZhjqcM+iEY3vpkZ1AK7sk/EsLguppgHTTj2jlEw3\nItu7vkbh02KLj5mKrKkxpwz0oQkwAU4BgDoOoNmeZ//Jj+kr/2HylMXJyTITRyYMY8cjJr11n/qS\n5667+vyVm7ff8dRQ+bd/2J3pcs5eszT31NCBovWn+25funjpF/+wMx03ShVn55Gr/mHNL1k6tS2m\nmI7y0jOS/3fXyHV9UPLFP/5qeXV3TlOhq0RTQSkgcPeOsQtWdwO4a8fohaunMVF7Ip6I7EaNOK5U\nzWMDlSitHw5jTqTKQO280LMgpKaYTgdy1hAyI1dfA2f93o96yRbcEmw5pfST8m1aEDfU5OFRALVF\nX5qbUMoWL5bdH2w0L/Z9KQYUNywU81L08P7JA4P5ex/P/eLObT+6Y++e8ZWjRfX+J8+45e5zDx4e\nOzhRWbqse2K89JaP/eb1Zwycu6rzRc9ZBojB7o7Vq/TT5+uWw3eNVF921Wnl1QOOwy69bpRSUAqF\nEkoJ9d4Rd+8YA9DIwHEn+rdMxBORVso5wdOrzb7nylP9xd+YzdTlN8ztO+Xf3npReJPHQLTNQgEh\nIEBBKJkZA1GThFL9a61tRmLK9jMjUjPmt4FmYjAISwiFo2yz8ZIbJHVkDNTgP78hccN/m08Udc7N\nPoMaRnbLgcnf3rXJhLayV8pMUTTpgaqyiPFU7/L/fsuCP245snp+596Dw0D3wwfLk5WYqojOpKYv\nXFAxLZpIjh2ZOHlBB6E2UCFu6UQs86o5+PIwiOe/sJWBsU0xOEs4TWYLVtWZG059k0mITsGPobsL\n8dBvczRCfzyFVBoKArkP9WExIpAIM2PiBTFre6uUWnMrsoIjw6kQchh2GowQRS6svqSKT05hqAC4\nAKVK0XMIHRzD3sNi92H+zrfrP/44ScUIV9j/+2GHUOlz1sTWzRN/vONkgAPaw3vHBLBp27BmDt76\nwLYVixcVmXrwSBEQ23ddkK84fSkhHD60+1B5Iq+qysGKMziRZwyC6gJIGEZnohYe+dxVXVIeHhuY\njmk6JmOOvyiKKpdgs2YMfLrQeJH+Fc7gUptKVHPSN8ZQVe1Sank2UuK5cm+OuOejiQbim0mAOkuJ\nL/d8sRkcFgalYtDcgpZ0ijxX8CAzhUrVxmk/5IZKWc+kmcOY6fnN94+IkkPypsiV0VvEVz6gx9Jk\ncu/Ilh91KbqhJBIo5JHtgGqcs17bsY8YWnxk76HRHEkcPjBWtCbLZVRKKJWdqnV40K4QI6FSRSG6\nqkEglkk5tuPYYDQmhBV8OewfN5+7qgtCMO8dUWhjHpV2EOxqcv3YiNDZ47UbFwH49kPtVv71eSil\ndOthoaKo/pP5t7de9OnvPDCar7O++BYa3lAKfW655yNAwhABGmkz5ZZIprUjJGe84yyQLyqUKH5R\niyPjKFVFroiJAnITiGWEFmfplKarVipm9aVLRl8nSPVNb9wq3bvLu7E/JywLe/aOZXqSdz+yEWMT\nmMR9P1178kt3WNXCAjXdCaiamkonMmzQMrNVGyZD3qE8qosos5783Vf22lfVoseBxwdVX7tx0bEJ\nN++uq/IU7Sk5SvSTeAZ7lpohrZkFuw3DvQAPuCgG88hXMVkSkwUxkSPxJDHiiqYLlYrOJEpdYn5l\nLKN0f+Vr86598ch5a51uRsdNuibufH9T4RyDgtmoUpRMZ7L8xG/WiWJ1zcv3cTE6PjSxdEX/rffY\n/1IShYqoWsJhYb/R/nFzcVftgl/+kpplorEXPlOk2dMCx2Gth6x+BFwzG2kIR5V7tbMcbYHzLJ7F\nnwk2nPTNZl9t3vK6YAPBxbyLz/3D/7oZMH++hZ6exbN4WiDLLPLAXBquRL7ugnCaAtBuUq/Mn7ju\nvO+0fRlzI+J/dM+rAVx33ncb05p8dbSdGZF/ee8rAFz9nB/7V0e9RVbGWtwpVi+ip60gJ6/VteVd\n174uPIk8gJv+sAyjFUw4Tq4kqkyhKhhnplMqs/G8GM1hcAKDeYxPipECRosoViIewi/vvRbAVz66\ntbYpoHtKRctXR9/0vnWhxnJM2GwcFdRj/TbtjAlbKHjt68b+1TZediQa76XxUt1DfTh8qNCDajxy\n6LCf/t4DkS1bIyjc5Ho7kAwcuOQ8xzqhZ+qdLeRYMbChYqNiimoVvOqgieny2uftBXDTNwdUkRC6\nQzhE1RFV27JQKGOsgOECxidFroKKDYe1eg39/FetMsFfctX6yO1TRi37UIkyRbDbcdAp/Cuc0jaj\nqsosHSrvfNXZM+PhdOGXGhaC00DZ1afleYu5nRuccRIShqPlVhl7valW1XUb4XBYFiqmqFa4UbVv\n+mX/tVcPRba89nW1KvQ3/XcHtWxCuWkjXxG5PMaKomyRqgVnFkV6axR93zr/o+9KfuGVtanbQ6JD\n8X7r47DCxSwRKatbOCqCvv5gsuLRQGON7/nPuxCAYH/edUdHihEUDW0MEpUJ2I6oWqRcRbJqqu2Y\nXgEYClEVSmzGULFIrswny8RisBuso7OBzdhfvf3dejz+uX+/IaZrv/2NW2PimhfPJKnvzxBH6ZXU\nqr6+ACEgjZLwGZdZ3xqZeN2TzVemra4EOakoojMuchUlX6KZQvnKKyYApKeaVeLat4395KNJ6Ydk\nAqaDYhVcEC7msmbI86562Sv+8q8ADB4+/LNvf0U9qtORnxDw5d7RiG6fcm6Lsbw1H0IIkECm+bMu\nimfxLGaOoGHm5HXfaNbsia2vBzCw4P8AnHzNpTJt+ObPrpDf/jmqo8/iWcwVpjWtkxeYyIWgwZlJ\nnxmZ9ZHqqO+iQH3xtTFrenaXmx+4HsAVZzedvWtFl9aXRl8PXz0Py5fS+cviSl8aaX7ty0cA3PTj\nfuQFytyZLHDTEY4DAaooL3pv+Rvv0o6Mib2DYvdhtv0IDk4Vp3375lcDuHhD7WZbKL3Sn3H1c25y\nGOdCaPWxHS3GhG2OgkzHnHFyU6Om95YPbgDwpQ9v9lf8r3zzyXTTl1//3tUAvvHvO6Kahw8+Jdo3\nkE53PrWx0EzgAiHv3zSHEK2pNbN0isi8xDmK4Z49elKGECRvOrYtqjbMiuBFGwXryqsPywbXvmJI\nTFTtoVxpnB887Ow9hL2HxYHD7Et/lzowjMFxjOaFzXVNN9KpWHBZ2Dd1ZmChWG22+A1UhepTpRcF\n0yZkIsWUyyyf2wzQmjDNrlCuO4LJZcZnf+erzo7cLrgILdM67HjBCqbWrb/6IiHLGgUOcwJm1huK\nas7RmLsnZQCYrDqqiqqJfEVMFvHPN5pAXR+1J8r5CTY8gUJZGytajAtDBeNW2STjRYzl+HDOspzw\nizxX5vN7kwBGi3VH0+MqAKvS1i2kU7qc357QmjHpDa/YMINg7hMDs4ytncNZQ6UAjExuFaIuAe/E\nzKw35iJJXDKwUGEOR9VBvsLHixidFB//S/q5twsnMBX9+AQbnsSRcbFv2Nk7LHYdxo4j2D2Ip4Yx\nNCEY4rmKGM9FyJZChRUqTJ4oBD2uNi5VEH9p3KU3pcll9vd+osJXByK/nSsGjuWtsArqn8JNSKyb\nIO8EzKyXmKU89BkIgHNYDkoW8kUxGiOa4vQw+ul3aJrO4prqmBiewNiEGM5jZAKjeZKrck0RABxO\nbEaqtp1OJkfy5UqxGjnGkzwMycMZ46oX1grj/7mJwfbh89ARzB9t/v1rzvnUd+6f8TGHy4biRM+3\nF4SAIKJORM5aYhwND4f/OpjBSyGAnpQxlDcBTNd5FmQgAC5gM1Qskq+AjDmqoloCeoKolKuwAbVU\nwkQRo3mMFfhYiRRNhQkOQAgwAcbJRNke6E4eGC4VWvJwxnf6LGYDGU06AyvUcCWGQBZoJAOFqNdI\nBQehAiCBHU/kzPpChfVnXB62jxADAXAByyFlS1Rth0OhY3yiSowY0VUKxphjM6EVS2I8LyYrJF9F\n2SSAYtfnZQ8VzHRKr5hM2lQaqViYfkTB8YmnpcRbm/mBs4Rf/mmorMvPIIRaufaPIAQIOABBIsPW\nTsTM+nyp5bQPDWhkIDxJmJ900inVyXG7bIqYoetCU6AQ4piO6TiEGiWLlEzYXnB2T1IfrZ+Z2WQ8\nbigVwLFZM5E4J2jTONF+0ftpWTuCZGiHkK1TJdrZq30Ea1v4x5F3J2lMqYJAYYvWRdcUOw+0qNbt\nwpd5a194HnzZKGqxiye+sz6uUEu0FawZyUAAhNBcyYzH1WJVKFVzSIVeqppaTHXnGFWrFScec+NC\nmXeqXIVNi4d+EHZfXB+uzHBedYkpMpVOLDT6D2dffIB6MWXNKm23M/ZrhK+FhlTUZ0aooUJF4xL8\nqvXuehtphc0YCCBfMuNxlQuR5iYXxHFQtQmpmLkKJsuYLKPC1SOjZtUitkOCBrZchXUl9dDRJA9V\nTQHgu/uCP/Zk1emLh/d6FnOFxtJyQbzjVRtb7z5WskanOcCpIZDLJGYeMfNMgC9hgj1bJ1PLw0gG\nFopVI65yIbqUIhSkNPcVNlFWdVgF6r2GNXUiF6FhRh4zJA9TiTDlJA9nKQ+PZ9zfML+8Cn7mZeue\nlouJ1GwbZeCYp9QQhQjWrjNDAFxNex8IwAUBAQ36KNwA7pc35MUHS9y01nllBkZ0bn4TKGj3Hlrg\n+3e/BsArLwhf+ZEcSadikYpEJA9l2NqzeBZPF54Z6mj7GK5qiqGONPG5Nap5fc86Bp7F0w1XHSVE\nAERAoMlsfs84jJbtnkQ4diSk5vWljNwzxDEg48uDiZH3bX4VgqVxANR76tG2YWYOraP33vKEiOpC\nX7vj5QD+6rk/8VciLgNTjBfOvqI2V5xKlGYB3O1cbaPZ1n9Wn/7OAzSjw6jdxci+sBlGMPHuJ+4h\nVAGhhOBd6S8DeNX3FsK3lXpmCLWYB/DNN00CuPivNsEdDwohxJ3fPMNt4x6VAALEj+5uZz6H4xhJ\nQymZrBkP5coMGXhU80haBO4CAGIRavwc6DJzUsv03luemP1BWuOBmzfDo6J/zXNeiPWdrzn7cz9+\nDKYwNa7HFQC9A6mRI0X5rRwNvuvxe1wrZyAfYt1LX+qt1n4Uj0efBvC8z38teKI78elwawA240Xh\n5OFUed3As2Q5E8yeJHbOtK3jbJaCZkgaCpoUm+GOsCrO4OS0p54Djn4eSeOJyI0AKKnN5dQC0vRn\nqIZcpn0lM8K9tzxxDBjoQ1LxqEJkiMgQPVCfoa8rBY+Bf//YHRAcAkIwwZlvfRBcfoQQHN4iMy/c\nBm4WBg/VEnMloaBEcF6k3Dk/oS0yyjdNxB0qJWtRYdXzY2SRRnTCx5n1WCV9mMVmMTXPUcXJmdIT\neXfCo0h5WLVZX0csX7KLZasCxA0NaCLBjqc8kp6UNhpVGudpx/4/PX7sLQsuD983c2uqVD6lHu4I\n5s+NI7+1PBVJjyswBTExNOJqpO946I/gEJRxDhBQoGi4KWne1OscAkBE7W7OGQhIgzbjPj5OhMl4\neQFNPa8DBuF5zgAO2IxXLomnrupU0oozyRJnpYzru/Jdc1cj5ShgcaxmlQnJQ5+BAFIJ3bFZxWzo\n2cdlHslk8Xic7vPeW544VJ4bBk45IDyqCCkO2RI5oz++klYWm8V4QcQssSSbets9v3/7fX+A4Jwz\nMC4YEw7LqzHuxWdwxgX3F4fLRXCPnOCCc84Z58GN8CUhp7xEmXF2h5JUJn88mibEdrim0IrFYmvi\npV1l/r0JdZKPbivPe+v8Upogf6wezzSRUEnewuKYub/qPlNfHqY06jNQIpXQq35G0nGfR9KT0g62\nLOUYwlGdteJY6p9PC/Ij48GPL/zlD4TgEOAMhIITAKwUS4LVfhFRP4jzhoMs0MDTS+vP5ZLQtHml\nj/ZuTOfunrQnbfOUlD3Ok0MsFdOG7i8kz8sUTjHYsJ04K1XZWyETHDhO1VEfin+jlGRiak9aR1Qo\naUyb9Y0cqzySyaKzsC9xcLjcetejlL7UPusIEZEG0iBUcCekxKrAjIT9AzdvJtQ91FnPO2la+/oF\nSBtnHS2Wapf3/J99W3DOASKrFXJeiiUBENsGga9OMqfWuwiBzxH/WXCPsaQ+hMv9MFG20ld3swo3\nHy6pHWrfW+drF6eqnDmc04OOmlR6X93f/44FmbMzfMRJ2s8A7+KCuAm4mnlfWqfA4ZHoWa+iEVQy\ng5phKI8EnrbpC65gg8aNU54ruAVhMZsrPw1K6WzsLkSBCu6rmi10TsehDsLLdE/34B+2zOw6Q3jT\nq0/315/3428KzqUBRjCbM5ZXdG7b3LGZw7jNuMc9btuc2Zxxzjh3OGe2v7gNHMYdxmXmTYCxriRk\nJ8WS65PVQZOuNmJ6XEBoC/Xi6cZTD+QHXr3EKbOhHw6xYTt5Qbbzgo7Cjmr6Cf606vBT4FDFAGoM\nlBvTqVhjjJg7XAzS7HjNI5FvzxbC8AUvWGE6ZmOYQjPZOKUXcf+fHp/ZkI8oUORIaXYasc9DVeXL\n0wLAnokIGSs494Wh5KEUiS2cgS3w1R88AgDEAHDxt77KmQ2hEAoiOCG0pOuwbcjQM7BgngV3OAhA\nOGozb1MEJaEkHkVIkXSvKTbP4CbXOrWuK7pBIARiC2PiObyct40Fxvjvxju2sKwRG7ytIM7OKGtj\nEw9OdhrHaZDxITMGiBADpUswxMPRsp3QngFSHYGZbZ4WYTgtKDKXOQpJb5CQVEQzguahAAiNZx2H\n7inw5WmxvLMpFWcAxhwGdw5jVUvItKY3/sUZX/3BI+f/3+cJpZzZMs6TcEaoUjZ0OQgkUHgd2YCA\ntinpRwAQBjSwlAP1Eswlobbbyn1rSDgQgJMm/X85r7S9XP31JJ10eJXHVsUnT6rk8rZ+UoImFT7q\nJLXjNPL74YkkEJaBQae8z0PJwMTsx4QnKO695YkZ+B5C8w33dNU9Xq0vE1ppRDfASyaAfN5CQBg6\nDt0xgdWdLJKBJZsmtVrPfvAPW6Y7PizZrn6hEuXcL3xKMAZAjgMF4dV4CgSwHVcGErdSE6cgwnMx\nSEFHQKAIn6KIYmlgI3wSZpjCjjA4ECBj4xYhhE866lNsgGqTN43Fz0/3vW4eIeAmL96XJw+UjeOy\neMmYWRPOAQbajZ1JaqHPMnAO0Zp+M0Amo6OBijsnaWP0f5mpAEoBU0WQkNPFlgv+kjAGCgJGuEIo\nqvEEHBvS3EIUn4EgIIxKkQiAOQ6R1+kxUACC1ujGHDtESwkvt1ojiq6jyqDQziov/dshrSp0TdEp\nFQ9afMt4iXKiEdVE3IZuUaIc12FtkoG5iv/i4T4PC8Wqrqs6kPcmObvqnFr4ZUdSGy6aALppBUBf\nIvxbJtQpbvzhyQQAGd3Sk5SXUadaNcuptzn73f3Xob4MsaHQksnKNsexraE2XUvMnDPQh09Fn4eM\nEEURrU2pJZve/tutF16xqlWjKDx57msIc6hQuBCEE6KgoseIY3tjP4V4lHPphhrJmG0TSJYGWBbo\nL9x2/I3BbuRplTFKGBE6JSoMpsXKAjaICggkqEKqSHAihKCUUEKOc/dEAwMlOEALxaoeq5noQsE0\nhCJXsftSxvBMC59JBgLgQsj8DO8yai9pxVAjeajRiMdqMl62OYCRoj2bWoZKZOJo1KCMiWmPOSUD\n/dHaHDLQRyaj1/GQkTnJhmsEcxyqEAhBuEIUUtF1yUAJAl5bd6+lFk3okhA2qFILiwkoYcz29dU6\neFkUKgUBOBGUUI3DEeB1fhuFkrmdVPAooQkDAWCkaGYMFQAoARcZXclbtaC2muXD5aErDNuHz0B4\nGVKNorhQrOqGyprLw0Zk4opMnpiSh02DRY9mtG9IBsbjR/FcKjjzXeBe35e6aCSYF4khvCaOw4K1\nPxpLznDmQChCEYQIKgh3uCv6CAVAaEAzkscO5N26HAOC0pIEHr5s4F147VXljSkVQTQQlRADRCZx\nUFlM6ui8cI4OWjLQzhgKCNKi5j/M6G5QW6j8heThGJ9Gh2rJQAleKFYVQwWgGyoCtS3aQcCKe3TN\nuQqZhsktxMAj1aP4mpaW1dAZAfTGZxVSGwp5P3vzL5njcMfhzOGOI1xPoMNtRzCnFovGvMVx/Nnn\n/W+ZbcuFeyuyAbNt5tiObTu2PTwx6l+D+4s+yp3h4ZKgnCgABaEExM+Mms09Hmu0w8C0qAJ1PGyc\nNlTycGsx2c5J22AgRoq2Yqj+UFqPNeVhYwHSjoQqldJC8RgVvDj7krVTtjGdOrVzrhgoTaORaMFD\nuczJBUiSMMdhzGG2xRyL20wwm9sOt23hMDhOfWSoF4wmp8OohY/WGOvemuNw2xmZGB+dHOd2g7N+\nzRcvcorWIx+4a0Vezegq0QgcgAqIhkC34xWKnmpLBgIA0qJaILGgXtqo7Hk8xOJYLdQm0SAn2mRg\n0lA6YEKgQFyO6TE1X2XVohlKeows09iRUCfLDqYpP2eANseEIQa2CZ8+zMvCI/JtPwv+lh0lobo6\n35zw0HEshVPBBSeCERWuykkIBQEFJQSUUAYQEBKsl+IVnpG+QeFXFvUJJOnKGfN8/S7cPvX4RY/2\n/H3H6v+6xClWH7/61pMHOgklIOIZlNvblIG6AoIutWjbdX29TR4C2F9NBnnYDM0qZdQYKCF/EwIA\nmZiSr0aM2JqVpVI1JTgHRhAvuWr9lFc4LZx9ydoHbtvWuD2SfkFjTDzZVKFdsO4UuXLBNa+3zEqp\nMJkbHxo5sofZlp8uqTQbKg/lAGSAfN5ShPDHhI4QeZtmGnwSay9Yz7zcV+LUhoVTgtu2oJQwhxDq\nUDmpCyGUEpeNtIGT3o6O4wfJCADgREAEYma4wwjxSdhQbW3ewCr2PWfsm1s7v7Jo1a3Pe+xVd54u\nEiAERLj+jmcgXAYCXWoRgKbZfq00iU4U95dchbMZDw2Fmow346EvBn0GNr4L6hgIpGEWYEDUeBhZ\nAaCRhzGIZgyMRC1abXqBFbUf+zlXnATg9t9EUDEINlVFSV8Annf59cDdAC644jrLrJaKucmxoT3b\nHn3ozp8rRExLIIaU0nzASdiOLt0CzLYppSCEENiEEgJCKQilhIKAEOpxUoZhU980w7kNUNeA6jsE\nRW08JxgXgGAOCERAEnprClMUesWq85XXTBy8af+6r5/7cNZ0i5Q+c4RhEDUG6sU2d2k2PpQE218N\njw/bYaAcy2marWl2Z8KRy+JECah7tUVWAGinXKoPlSihpf19ZwB3DKa2wUCAam7gxIp1blWVA3u3\nTYwNJpPpZas3UFV3GGsY6DWF9By2gKIpctHjur/4phdpifGTehufGLdtZlvMNpllM8tijs1sm1mm\nY5mOZTl21bFNxzId23Jsx7EtZrsDde5ZdBhzOGOcMWnd8QUy5zbndlciI7/1L9h/SWoCzvhkfl53\nb+w7+T2Fp076wpkPvOJPZ5MM/Jf2MwftM3BdtrQ157GLIGMoeTMsbSKdh+0w0HQ4gF4t4hoWJ0r7\ny0kIsEDGY2Oz46H66MVXrpXCMDTiKlkEAAj6O1t2D0GWrD9XruYmR9EFALf84juGYcxLJHsWLn/o\n7t8dJ+4vyUPmWIRSQikhXFbrlQZjmU8ouKyKxiC100DVEcd2CCGEeP4MhCvkc0d6OzhnDhrHhBR4\n8ZpVT2zeZuhGOpFa8RuyXTy17qvnbLvqnrU9HUf31ucaLgMp6VLbqlXu8pDWRFMzI83+InpjZQQZ\nGNfBBBQSyUAmohkosThR2luuq8TR2EaWhxutPs2FLaLpBwBQRKvkUgFQVdtw0UuAOwHce9uvsBwA\nKo/e+uBglRDS1TswPnz4zEXJya7+0L5cCFcVa6mmBseHcwLOHAJKBQGlRCHCYfCLuZC6ohWCCwRi\n1R2rKhVX4mqtLs386+fMzT8UjKFxTNin6NQwVEXTFUVQJckSnd/UKxdWOr64pvqew0l6nIZr+ygy\nVxxNl4ES67KlrYWkHP1KYdiMhw9PRuw+WQp7Gk2HoyUDJUIVcSLb+OXhnkacdMkGAA/8fvpZhQKJ\nbHf/4tWShE88+idgA4BzrnnjGWYlP3JwcMfjtp6Y6OoLlWQRgrziTTd0dPd/+eNvh2CyHwsBASEE\nkimtUKgpCHJ8ePbzT57NPdZOLUO3KSVCCMYFcwA9RD8Jzh0IQhVv4gohBOOQafdEWk9pnTffkbEG\njDsswjCzxDD+309+GdONFUsXWmVmCzbQ0bv9HTsXfn1gUzp3brGrnVJfTyMEd+eLlgxM8nbHgT7W\npafkIc1VWFAvlaWEJUnkBUhIBnZNxUCJIA+bQQVxjlfj2JRBatmeBZruGjxPO/tiYAzAWde80aqW\n88OHDm25f9utP0gVhw+l+v0uJoQwEumBxavuuvnHVdOK6QohIFQ598rrT3vulamO7smRwYdvv/kr\nmE5IE2m3pi7nDhGCKpR39gtmC84jGQgCwYTgjk9Cb7OnWwsIwRGoiciYJcPchOOIRnX0wUcfo5RW\nLbOQL2sqVQhVNCWZOHn00d0nffoU8y+fiuvHuzAMMbA/HvHcQuHXI9W6nl3joec8CPDQfWQ+D4MM\nlJA8lAxMiulk8dcj0liqznTQZDqmHyvL2NTGVb3JXDQzEYMAIFKdvf7Q6ILLrgG+CiA3cjjbO79v\n6drOgaW2bW393TeEqFlHhcDKk85VFOWJR/8k1TYh8LxXv+3MS1+8f+eTTz58b//CJWosjnoSPvD7\nJ+ZMGAomuge4wwTnnDFmVlUj4DghAMBMU3AheFBPif6NfBuM4AC4gBCco7HkoZSeikKKZjWrplRF\nYZwhnjj06Wryy8YTE2Pn9fXNyqV6lGE5fAYysDcWvqMzO8sPT7jjvQAP6xyAwzkzb7F8pdJIFdPm\nINNmYEgYJo1op0UqoRfLTY00jWWdjs1knS28gpAECoiRYn4SCwDgvp99edG6s9Zd8CLViK2/+KXb\n7/g5F0I6KYQApcqGjRcPDx7MjQ9plAiIVKbn1ItesPOJh7/8ifcIxgghqkrx19fM8uJNx0Rg0sJg\n3r1URIXDBLedCmok9HwPggsZH9P69ci5CEyLItx/6mVybeyoKioEmczlOHMEc7p7sgSY17W+eiDf\n8ZZufpxpQ4w33PqMtNBGnNlZKx6RiSkxiGCQSr5k9mQNScuQPdNiHARJ7jKwP05CS28svCRUdzm7\nK1yxItJYerQxXTG4aNHU9YXL+XG/7zxy361y5dAjN2+++dtmuUCAeLoj3j0ghB+cJRKZ7r75Szc/\ndIdgjkIpBFmwdJ2q6aPDh/7uQ5//j2/c/PYPfW7+4hXtX+e0QAho70LBmOCcc5szzqwK4Aoq+ceu\nVDhzpJxsNoehhOCOPyFaffxZ7aXpkvDk1Suxdq26fi1VFCYEKN1WrUBRFS1+4Cfj/Rd1TpbN1jRU\nOG9/YZzMcgnPSdgGA6dMBfQR5GEwyDMdVxb0JORsZ1JS+VSxGAdqDJwBgjxsUT78mQUCkhs55HvS\nDuxzZ0SLaZQVR8oVEwAhRNHjjLueQiGwfO0ZAB574DZFoTKMOZ7MEpBzL726mJ/ctun+hcvXXv+3\n75/+1bQrSThngjuCMcE4BPfoB9/vIBxHcIczJrhtl2s/XLDaBQDm2IIJwRtGAYIHC9K5JDzztJPS\nmgLDUE5ey2w709XpxDJQqRLT2SNZp8omq9VmjJrmk5h7jJn6nMjAaAg36SEdV+DNNyhffj4PXQbO\nYhzYiOOHh7MUL/nxoYmRQ3J9xWo3bO3OXeVDyvJEMgGAc3bX1uEnHj0EGVtDldPPe/7goX3lwqSq\nUKnLlks5Aex84pGvfvK93/7Mh3Y8/mBnt+vSCBFr9sIwlukSzBFMcGYLLutZyF+cEIAQmPmC4G4D\n7nC71LQIr2SgH8AtapXw6+CS8A1vfdVyqd1qatl2uno0pgIERKFJo8euFCapJdoPanjmIygMASzs\nTR4eKQUZKNGT0DIxZQbjwHbg87A6nWi1Y4Y2k3e5Xd1016/l+mnnXCpXLrnm1c+//g2xWIILMTl8\neGTwMCXk8YcPAiLT0dvZPe++O35FiZABmwQ4uG+7Y1u6EdM1RdcUI57g/q8wp73yD31nuQzktk8e\nEDiVKvHkodQwObMFc4BWY0LBhWC8ZrypC/eurbokfOPr/4EK66Vnna4SJTeRuy9P3FgeRUmmu7kj\nnHRjQvAMwY5CRlyJpub2gK55RgBAX8YAkE7phWI1NAAYLdsyArtE20p6mi5WdsVTGgVQtVkLqwyk\nD23KBVMtDbu0FixTHlAqctsevEW2z3b2yJVrXve2U846H4SU8xOP3PyD8xZaMj5SCHLyxksdx969\n7VFZxkF2/cLE8I7NDy5ZddLf3fjFt7z/s0tXbxg6tC/ykhihW+94vK2nEbXIwqGC2dxxJGeIAASc\nSkG2qE6Mc2ZzxxKO6zaqKbn1x7LLFcFswZnwjdK104haQK1vHR0dm7jsoouefHSzRrXshRuJqGnB\nMSMGQsyjWVN9luhLaMNlu0RT3UpQfM1QTy47Yms+6YetSwYCAKiqKcWyFayYCKAnoXXE1OGyVaLJ\n2YwJGzGQ1BGsEa4pLXjYji1UiaqgUQMFa3vKrfZrWBAQVnUHC4f270I3ACiKUsqNjR95as9jd++6\n99cxzwOjqOrqDece3LfDLBcMzXVOExBC+E+/+vH8y950yjkXq6q2bdP9v/jWZ3D2cwAQEo5fnTTV\nZjfiRFUZcDyS3NazUXBRoRp3TPBaRUM39QGoTkxy7gjG3WEeCQ8Cg+tSERXcCUhC/5+okofnn3PO\nOWdu+P2td5y/Zt6fKlpQVnIIWq3ox/GcvpNVR/JwjCXqeTgTbM3XQkn70n5cKAMQN7QKIHkYrJg4\nWXX6EvpwyYrVVTGd1WhZMvB4CJeJRKfhABjXutpp7A9kbv/ND3B6FsDPvvOVYiGXruwf3bs5Rpmu\nUkKIADr7FnZ09d3y828RCL+iCiFQKHEc63ff/9yvv/MZLgQlRFHmvkNeMvTQLV2nCsI5E7WoFwAy\nA5xA6qjNGBgko10qeQwUvDYmjFahXRJef+25k/lqrpSHWLZgnB3qqnWgarmgWlWlIkRKHCcpFWHT\nqKRBWh8uWLPk4cPjCcB9nCEGSkgeNtYsnaw6fUl9uIRudXqVaXw8MF5LDj5OGPjIH7fOyXF8D/OB\nnQ8CzwPw469/hRBQQgghlIAQUrHoOc+ZP3hg90f/4WVcCENT3WBo7whGUtXcKW7rAkqZZGP9G2/n\nPVtWnTe9uqMSVrXM9ThBfdVQAhCUR0eE75AIMDDSfc45F8IfOgZcFCBoGMa6r5PBweonP/WlTDz+\n/359Syk/tmgUi2JdiqYIRSmWx7gtUrZ2XPCvAQXbQKBM02zwQICBPnIVO/QLSyVJ5igFMVl1+jLG\nmD2TUkdBBh7/WDUwQ2OI6kV4veS0uKZQhVKFEsnAc89bABCFEl1TYrqqqjQUHCKT+BRKVYUolFIv\nBGBlJirw3ZxhgBclMOyaV9C/AkLAbbtNBpqFguBcMCG4Lbjw+49fjSZUsMK91v/+7HcHFmR27Tyg\nUmVwdLhcKS8Anr9m3a/GdxbJvpQjulUj+oTHASQDcxV7NsJQ0oDBfToDmehyaablyGme8lUnumJi\n1hjOoVubhjwMMbCZGGxtmHlGwO9BCiVXnVIXr3RAeskp1ag3EGvobiTw/9G7QiGQ4NWKEnNPSaTg\nrZ02zMAaU70VzgVjgjPOhOtmBACYuYl4V59oGKe4EuS5l6w+dGhkIl8EJZP5/Jmnn3Tvpvsf3/L4\ngiPV3utLNre6EsbxScGgDJQ8BDDGpidYwjQIM1CCm1aNGJmYioAfr65iYnaG8tBHIwOPRQB3fd9o\npouyuRiMNUsglDoqJdMPkWy4qAdv2z6DC3tBcSelEAIpYpIGYUgIKA0zMHSlZi7HXQYy1NdGoNQf\nFtbFjnpz2Tywa/f+w+CwuSqY89Nf/jYey9y76YG9R7ZWRTX3XaYdhXHw0YDPw62Fdp0W7TEQpsWB\nulmQfR42Vkxs/wIeHkso9T2ukYGW4FxMm4QOmFxA0WJxKPMXAdVfpnu64xDB25GLAqPZ4u8lK1II\nIdIPPSw/yzxdQhAYo7pNGwUzcyw5l73LwFA17qjKaW732bXvEGesZJlJPUEpURTlrI1rJ4q5Hen7\nBPiKweM9lSmIIA9LDvwlEm0ysLHmhYTkYeO3hk7BxZQ8fHgsIVmtECK10GcxA+wZrgLoMGZlx1L9\nOT0ppDB0AwV8jZS6i7jrTiDAwHpmcNvmv72lcfQo4VRLAS+qC+8dTgAQhRiKgpgWUxQlkU6WrPHU\nC83qQ2R+5vg1G0TSw+fh/so0nPjNGJgvucUygGB2mPuxaWWarCF52Owt4DMQQF9DzoSPyLJrRxuP\n/nFzs6/W9s2BxzhXQC6QdH3A6JvN0a5YqQGYtNVZ8lDi8twu3zB76Fu/IIAsT0ioq5EKIcQtd4Z8\nGAAcU5ZmA7n84poqW+9FdKoV2YeC3cgloWEYEIyDE1XT46qmxy0u9BfmUCLLHupVonIajx/MmId1\nXoHmMtDQFChgtWF3WJ+oUTR0AVmjsbGEO4UbAI+BkQ6J9hn469/taLPlbDAnA0IA+Z6+fE/fAcNd\n5uSYjXjotnYn7iX188tcPLmNUMLOPHnt2gWHvvkLSSdKKKF08J67URVCCH7znR7N3Gdil4ryWCAQ\nt9weaUGliuQfcwq52kb3D6EMvCMdI8wGU9auXvmbTT+MrRXWH7SB7PErBtG8RBqCPCxFxJS1ycCM\nrkg9RVMIIwAlwWGhv57Rlegy3lmj8S1QN4niXDDwWcw5Lhvf6Q/1D379ZyAclA/+6Q5CZJKxEELw\n2+8MFnpidhVwVVYA4pbbERKEUpACEBCBuQrd85RKJUL0TCJeKFcuPOuFD+94uHThfr6dnsXmK8f9\naHBqHlIS4uF0GSihKSSiNF+Ak9E8TOtBHgZlYAs0MnBh71EJT1Wfjkm2yNh4cOkqDncVh2dzQDks\nxKxHhj4URT3wpZv8vn/ga78YvPsuBGwzkoik/oVcGTtc82cQiFtuD40YCYFVyAnU5VW5JCxX7WTM\nMFLxt77yQz/f9NXxKx4Vo+TUnfMNlVIc3yRsOaUEAjz0idcOA91jBvrnmmQRwMmZ0rp0cV26PnNq\nymktPB6GGNhMDIYYKK32g5NVAG3O5YRZsKvFgHCWIGPjcoUVreAyOCEAzJ6Kk/YcGHVlfOnXfviI\n/Lh23QK5Ym+fkCE+k90q3KobsG+9vebDUFz7zdC9d8Ez2ah6oyOREVFHKveit++9FsAm4Fd4ADde\nJzfeMp1L//49r51O8+nhuvO+2+rrlqXsEfDjR7jFmZisOo0BN6YjZ713X1frUiV4PJzBNcgLeHii\nbo+etM69BMUgIrXQnqR+cGSK6PBf/27Hi19UVwzfn5bQD+8OVnBobNZ2/PbcQ/IQwDwMAxhPzXCg\nGIqVeei2LWsuWOl+cOrESbq+jID/ZKLncgQAWNvG9XVdvkFUVAWJofuxLcB6AEP33j1wwUWDd98Z\nlJf2r25XX3RpLWKNgCpyGu7aYZ8Z7qAf3fPqZl/d/OB1x+ACbj4G5/DP9cD17Tf+5b3X1n2ckyu4\nYd2cHKYRzJtVii6ZF9wu2WAdGAIwOCHmdZKu4vC0eHjFSm1X09zaKUAaZv3131n7Ht6+9Mw1wa/s\nbeMDfW6kHAH6O7v8HF1CxeA9d0jlcqxT6Z5wX2nOr/+Iv7lE7kBAiQJu15VKfWa44J/FiYEQ90LQ\nF/Xri/rhScVZqqZhONMYVQX1hZBlxUf/QHf/QDdQS9WlxBsMBv36wd29ubVZKT8LSUhudFfEDa2+\nbdagzcM2nCWojvopFN+/+zUA3nnp1+THWjV7bz76ULVCANm4ciRvzmsciXlhUhaXqj4/o6NC6h+6\nTIoFatNzCDnGk6YaLoLRjkIgbzkA6Utr/gUIIBuTc72SYmAyJunYFUL8+oHrAFx+1g/keaQF3FCo\nnJbQHw3mC1VA3PHEawBc/Zyb/INDiKuvXB8qWS3TDhhz5DZKVXm7keY22wEgHrptizfzAakL+KA1\nJ6Gswzse7yNA6FhCZi55dgeSG88wCwSFvoGIUzZAX9RvHRiS8rCd9kcD/oBQYt26BVu3uhU6Bvoy\nhMClHwBABHx+jY81uGHnj39OQFZd92Ki1M1+M01J2Jpa4obpcU9CUq4J/eqI3RLrsrUhU8BGUneD\nuQrr7evc27l0b8dSvmQNX7KGL1rBO3o4VbgQpsz76puHpWtLA6scXivowahaXLS+uHBdNdEhQ8iE\nAKMaFi8n604Xy9eLnnmcUi5N11qMLFudWXMS0pl8wa0ULABku81Fq+2BpTmHhmqFiM5ea8lqd33p\nGjF/KU+mBRcaJWWTwWOgAHg8RVesJcvX1Q4r/128ii9d8/MHJmyHu1cIcC7G0/NHMwtz8Z6qoHK9\noKVYQxicbEwIv/fR4eqSddVlJ5ld8xghnIvGsiZcoJidNzFvbbVzQDBHscuaU5ELAa/2LKx0LSh3\nLyh3LyjGu8odA6aiT3T3cz51gRQjnhpYsmbZKef2LV0riLZ/61NwbG+xgsuFz29Xad9+964p20QO\nlUMgBAN9mRZmynWxLHGjvd2XXIiSy5JpADt/9IsDdz7w1B33+9v9uqPNe38LPrQWjLOBPDK5cVpH\nDs7uktEVy3JCU8On4oqzeHXv33xYdgcCAAKM8UP7yt/6jNi7nVKhX/Ua7TmXDRbG5n/gxXJaEAhY\nqa7D7/wiBDI/+mTnvT/TQCoDK4Zf+d7EwEooKjgXjs2e2mX+6Mt8x2baPz/+3v8BVcTX/sv8469l\n/huE0C99kXPFdWx4kH3ugxg66OfqCCH4xVclXvAK4OsAEu/9DASH49ib7mM/+qJ1eKjmihKCXHZN\n+sq/ACAbuzVzhcD5V2gXXSly46XffyQJrhIKgclk38PP+0cBsvC+H3QPPrn1wrdYic6BTb9Zvf33\nNCANhQAXPJfo3XXKS4pXrRSqBgCOTfft0H/0Of3wXsWdKcxrzMWu6240+5bAsbtv+q/uPQ8ShUgP\nWLVrwf6//FjtJxECnA0WJxOP3dL5wC9UtcVLn5xyzhWXXvWaZLqDUsps+8ihQ0MfeRcXxcaQyflL\n177wle8EPhTcuGe4uryvXdNxuklxRzSpUeAy0NNOaya7ukZYF8sSYKuVR5Msp6XJ1L5ygVBEha3V\nDnRj7d+gdApuCbYMSbCIK7uxfWnmwpeobTDQL90plwVx0w1NJuGp4dNxBQJlh5JUhqazvFp1SgVR\nrUA3lJPOTH30K10nr+9TK4jFSSrLExmbuWqVADghPJnlqayj6I4QZiJ75G2fNVdvpLrBC3luVmk6\nq516TvztNzgKFQolqSxJZ4WqqbpSKFYEkIopXDOQzJBkioH6VTYF55bg0A2Syrp3Xy4K2ybprHHJ\n1fRt/yayncmk7sYbZrvImRfQdJam3ca+eGH/7+vCMumCpbtPf2nV5oxxm9B9qy+1Y2m1NJE+8CQU\nzdGTTixlEdVhXEAw5shFCDHcueLRS/9+ZPk5It0Jx4FlIpHmpz6nesNXy+dd6aAmugXE6Jrzy0tP\nYYksy/QU1p5nEcUVrAKCUJ7I8ERGCIFqGWYFVLEGlk++8C2HXvORUiI6E183Yi97/Xv+4q/f29U7\nYJrVYiEXSyRXrT/5Df/0UT2ebRSg1775Q/66xeqNyVE0T2tGOq4HF/8rVQmLwUapSIB10lFB6jb6\nhAxtWadn1uuZxsuQtFyaSIfC2bzziRtcsTNdwkzZfmZCshnz28ACwzxkelNSG6plOgDScaVQqfO0\nV776ifz+p4iqphYsSvzFm9UlK50X/xX9n8c7NUfqtS5P6t9ncn6B4sYXOD0LAMS+87HDT+ygMYPM\nXxq74IrKH35GAu9Rf2iUjlEuYDtc8wZv3vfEEuFIwsLH/gF6LHb6ebFXvElbuyFx6pn8oTupDNRY\nto4uXA7OWX5SNuacU0oICMpF+5b/Z7ziTWNrLxzb91D/5L58dvHY4tMBZHfcm6yMivh8j/d1vVoI\nkcsMPHHRm61kl1ItOTd9he7eQpgjFq4QV70WA4udl7+lenBPfP82QokAHNU4dMVbACiTw6yjz1y9\nsXx7h14eC8mr+G0/jG26i1BFixnF0y8rnf8Sa8Xp4xe+CtiKhudqWdbg4f0TY8O/vunrT+3eCsd8\nwUvecOZFV/TNX1wqUpVCCbR+0Wv+YWDxSv9jbGAVH97dvDvMFnsf3r58o2sgrV2FJwrD0aF+M0IG\nFvQcOTQa+l5qLWuJtg0NETMzh5Rac6uO+lroTA+7wDD9W9cNVTIw1EYc2d81cSg1uFc8fKf1wG0A\nRFc/S3W2kzPE0p3uQTp6xYHdYteT7M5fFz/6Dv7AbbWUb7jFVeb1JLhAvuw0HtiM1HwO7aX7trFf\nfEuYVaJqdPFKKe2EAD3/chKLm1seKd38M/cMvfMlpSgl4v7b+NBhJ54ZXH1hycFTay+zkp3UsQae\nuMVQKVFIXX/wroYLPLXyIivZRZiz8Def1n/z3diuxxP7tsbv+qX6pQ8DQGev/fzrmRwdCkwuO9Ps\nX0bL+Y6ffgoA7x4orXmOFK3Bu1AnBtNDuzqGd/bufqj7D1+Jbb4LgLn2HP/J1P8Y/J4//PhD73zF\nfX/86fiRncXxgxWzCKBaqVSrdenRa0+/8PwXvArAk4/dJ7e86p8/MTGn1VlDVhkfnT1pd82XgKR+\nEl3/nkgdW0Pr8st1pOZJbkLCoJIZ5IMv93yeSG3TF1zBBo0bp3UutCFmm8CVhAQgsEzn0Gg5WMre\nR9WyBRdEUWg8BQCOLSyzsVkjko/eSgsTAKrXvj3zye8ar/xb7fTzlWy3QlyxJKGtPTV7+dXWOVcU\nzrgM5z+fLFoR/HnMJnWTCSExldq6OzWNKBeFrK0yb6Fy5oVgLPfNz1mPucN6cvJGJgAIAkKGDjp3\n/Q5AbsU5B9deNrbiXMLZgj/8X4JXNVWJTEYTAqaWKHYsBBA/vD0ztldXFUNVNJXqqhLbu4U8dg8A\nnHGhLQiHcKg2tv5ioaj6gW2pbffFH74FQOmiV1QVI2R3IQAlRKXEUGmC8PTm2wCIVEezRyq4rass\nndR1TV28Yv26054D4P67bh85vN+/bk03fEX0S//xTrnyq0/907LVa8NK6VwjxCriK5/BJMOGXRpM\npTUeBr8KqL8hAjRKoSm3RAqudqTZjHeMgq+LArCqDoBM0qiYdqFYTSVrA3e+aCVNpI14PLFug3PB\nFQAwuJ+WcsxV2VBhQmFC4Q06KYFxcEfn196fe8lbnaUnqUtXqUtXiXLR2bO98uWP8cH9frRY/LIX\n47IXC88Z7d0XAJicKTT6DUhWbSgnMtoFzyexuDArbP9uSiAA9do3Ed0wtzxqb9ukxuLAOgDqxous\nu37LBacUFGC//zG/6AWYt+jIc64XVEnu39y75349rioKbTQUyBtlis5UHYBWnNC5IwvPS1u7QgnZ\nu1Wcdh5iCR5LcqdcTfcVVm4ESPyJuxNmoeP271VPfS7rWZA/+bmJzbcQpU6+uanohCiUxHODoVM3\ndllNVQB09S182V/9a3fvwM4nHv3mFz6VFLZvQLr2zR9KprMAPv3ht199/V99BkcAvPy9nwfwq6/+\nN9n9a1UAaHC9N4caHdgXUlmI/09nd2ZiPF8bBDa+1oI3FqWmCuIFjc7cT3jco5GB0joqq6QVSlU/\nkrrj3f8uVzhAOefjoxPf/MICAFJFVDUQIrxnyhWPR45NCSgh2S13xh6/s7RqY+W8q8vrzlN6+rST\nzyTv+vfiP7/WrwUnxodFMe/LB9LZTbNdAGzOlagBp0T6I1/xzuXYD94pdj5BCcH8pfTM8wFUH7xb\n7ez2Z4HVTj3H7B3gQweooASEVkvWtz4bf/d/CFWjttnz+C0xleiaQiPr5AkAUByLOhYAJ57mar3N\nkBAMLAEAs4pyQeh0bO35dtd8APFdD7GOHupY6oEd9rKTS+e+xNxypyLsZro8S3XWfXZstwurdfF9\nnb0LX/O2j/YNLDm8f8+n3vPX1cJkNkMJswCcfenLTjn3cgA3//Tb1CxkuxcARwDs37oJwCnnXab8\n7I+AiFD6p4Ov/fDhhm3CUz8JgK7uzMRYHpHP023mgYuO7vTkWCFkzhGkvtkJRkJ/VjPUM1AibmgC\nqFQt+bM7+3fDMsEYnxxjB3br9/2Bjg2O0PjA4D4AIpV1Fq3hR3bIsY65/FQAEEIZOQhCKitPddRY\nbNsD2V0PJnc89ISxLPnWD+obNqpLV4nufr8bODd9pXzzz6WGKiC0v/ib2EtfP2U8vLlzi6hWSW6U\nbX3MufdWzTaJqtBzLiGaAYj0tX+Zulq6KL4LAKqqX/8W51PvExRUutZ3Pu7s2KKsPUWfOJwd3mlo\nCqV1qqiQThEhKKGMMeqU42P7CwNrqgMrJwfWMr5JykIhYK3YwM+4EIB49G4CcD1+5DnXA4DgQ3/z\n6WGAEypiSQCsd0Fx4Xpj/2O+FJGDWCHAhbBVI3fyxQBIcbLFjacy3S9+1d/3z18yeGjfNz7zAVbO\naQolXrZB34LlcuXw/t09/Qu2Pnw3nhsDsPvhO+T2i87acHD741M83AAaxWAUAwFg90PbVpy1tvaZ\nYHR4rLevO7IxAARne2mgK6n7AzxDSRicF823d2wtJAH37e5aRBsSDuK6ZnppqcXP/xsdPEAAwhw4\nlinE/LQxUnGO/One9DVvhWZU3nCD+rUPGkd228tPKbzgjQDoyCF96CmiqqPXvtvuXxJ75I+Z3351\n665hiArRXQnMy2Wk3BG85UBTFVWhAIQfUSOaSEAPQx94W6dB4TjUtjQKSilJd2innQtKAfjOCR/6\nWc+1Fy7nh/fJMiiUO6IwAYA6lsEsNRZOyRZEqXJFONQbv7KF2/44su4SZiSfuuwtZBz8zl9Ss+Kc\n+VzrurdBN1Au0N98V6Vwzn2B6J0PAISybG/dMePp8ppzsk89FsxhdhgHUIpljlz6huLplwNQdz2C\n04Co+48l0n/5jv9YsGR1qZD7/EffNXZkt0YJF5AhE4TgV9/+5PL1G+ctWvn6d37og2+++hVv+Dvg\nHgCv+Of/AvCbb352z69+qzfmHFMAeOiOLRufO5MypHX3CLfubmdXZmK8rUDVhKETKQyDaLh5l4Qv\nveg74AICRBABoaOuzm/rd7fMn3jled9u57JmPxFFxMyE7TEQQDaujHi/E6mUtGrJ7YiUEJC8xfsT\n+uDIYOXmn8Zf8HK+8tTcR39GqiURTwEgVtW4/cdacYz1LxBC8HiqfOFLyxe+tMOsEFWHooA5ldt+\njfxEdulCaSXwgyeifbtN0IsqlVMzqC59xOJVWLYWwOgNb7ceutv1m297HQCRnySZDvXiF/Hvf55C\nUDds0Rv/e5EbwfOPnH3NyNnXuA+BO0v/9O2FO+5YdfNn9l74OjvVhde8q/IX/7+9Lw/Xqyrv/b1r\n7f193xlzkpCTQEgCJBASwhwQIqMQUURF61R7bX0ut1fb3qfPrXCv2qu1t7a9tldpbx8ftFVrlba2\nzl5HhAr21pF5CigQM0JIyHSmb9h7rff+sYa99vB95yQ5gRzLS/jOnoe112+943rf/wKtYYaVyXF8\n9dPx1p/TwHBy5fUA+u+7ffFn31eDEkST0YAmeu5t/7N15mWtMy9t/ctnhRO+x9/y7vE33ggSXGuA\nCCqVWx8b+s6n8YbzbdMERCRe+cbfOvGk1QDqff3v+fO/IxcV8JXP3LLpJ182k1q/9LEP/M6f/gOA\n//z7N3/4prfgi68GcPNbLwTQmhyref/eDLrYzNmgoafutszQjAjzFw7vKTHD6nBRYGThUH5DEVCu\nRxqnh+GiXD7smKaZI3D3ZMe3lCAyJUdc4REi4GA7XVxD5yufmbz1o2Lr42DNfYNIk+jJBwc++8fD\nd/5TA7qxZ/uiT7576HN/Hj/2U046VO+DlOnTWyc+/6mpz/7VopFG5qQgb0MjEComBNujEM6cFiQE\nCf9UDNRf8x8go2Tb5vShu2MpalLUXBZd9fiDAKJ1F/CCJS621X69sfFWaKvt9kW1ZkF0wq5HTrvj\nloWP3IkDeyEj1OqYHMOPbqePvq9+xxdqpLH2fB5dik57YNMPBqUeasihhhzoiwbrcsEPvghAL1gy\nfv4rtEM7x3VuDHBcE+P74p/fO/TVj87/u98fGN9V/TBE/c5wGse1waGRgaGRweGR4ZH5Ua3hra47\nN2/6zj/+HwAnnnTqq3/jJrPxdz/zbwc6yATuo4BAQ0/d/bh9NQCM+QuHzZv0mvRuIdfFfpodxR8A\n8CsvvZXZjD4ERo1y9XyPKU7oycxvevn6f/YD/TQInOgA0JoTpbTmyY5aMtSoMNwLMVAXuw+2VKpP\nXqjV0EJxYPcAEikolhQLIiLNnCq+b19DM1P/ECdtJB0iLBpuRFJOtFSSKq2ZCHEkBQkitNJUaU6V\nYkASRdKU3jOue46Inh1r3/f4rwN41YWfD6N759XlM5OtVHHSSk0KajNe3PXwrwG45oLPK60BSCEi\nKQQRM6daG1EwEuL6V6+TghjQSk+1kk6S6kBkJKI4EvV6HElSitud9Kd3Pa77B1lIGj9gDJuRFFIQ\nMzqpUuBTF+m+WESSCDQeDzFYKW51lGItiaJIKqVSxQzUJyYAaFLp4DxJxLVaHIn/fesrALz37W5y\nWBQD6Gx/ttlRetF8Zgzu2zMxOABQsm/yqeeSkX4+ffViO66lCsDb33vLaWdfDIDwhwD+9oMHn7nn\n24Joy0GJ7pMlvDh6eAg0tOqCNa7dLLaiKAbwqY+fBeCGd2YaqRdFWu0OgFv/9nwA111/p98Fwte/\ncqV9JPMnJu5kbHAOElVYYjx5BAIgQTFJMOq1aF8zLZSGJyEATLX18fPruw8mW8f06fppIgghAKRM\nSoPADDw2NhBHAIM7UwAQR6NDdSZMtLQgiiNpjJ9mSkNbKSKSAkJEdnsAs0Ykd493Itc7yunfpYkA\niJhKe2MpIiEAV8ASIKJICEl24ze//dhrXrWWACFEfyNu1KPcJyabXp6IhGApRV9N6qTJzFSLiCCc\nTMuEeiQZ2HEQaxdr8xRkXlBSf4OY2bwWRzbGrZ5GADQoacRElErZLadvbdnihbufQfMAAPTH8WAD\nQKeV9Ncx2NAir9R+6WN/8J5bbiPn4Nn8o28O1OQdTySrRg8nk8DMEQjgJ3c9/JIrzoRlVoXK8zOi\nyjMsCJkRE9trzy0ioMoW6mkoQKA5nJyMNtwXFVLZexpv8uKR2u6x5OeTg+uGpwqi/KNj1pMuCUwE\nxuhwnYCDTZuTLXTZt13lrUxBC6guxZ6JhIgWVT3GSCPa3ewYGHQqC254QxwDgbfcb2Tmr339kde+\neh0RhBTCh9JlRA5RRIKE8Mfk5jERYMLWqORxNM5AY0ZwzJ0Aq9IqIi0ECKJnzj7fMuNUo74BtCap\n0t8NjB947gsf+4M3/c4fm9WBmgSwarSB7mzwpOH25P13+9W6a8ihOr9jHf76kUNAr8GhC2ZHkiZx\nVPHhKsm6N1B8Kx876nwhc5B6I/C5AIFlCnFIee/52JReNFR7dqxNhIemBpST4uLAMqQAiQoztCeP\nwEqqS2FqjFYOBAaBPU6fIV2xaGLXPblQrL6qMn2maxL6UR4qHBEAjabrNlHSq+QGuZErTpsAEpm5\ncBnuvdLcC/5olwZaeGbn2rUjSivNqk0xu07qw5l+ctc3T157Ia4EgN0zKwm5/YAedA5c/5132XpJ\nh8ZCC2NQmuaC5goN16jX2p3sHY27v3DBOemiCKkHAgH0RqChnvxQAXhkbIChpZuGo7SWgWar2GeL\nKvbs6RBIYy3VTqvjrWYLgQD2T/IE5zrKYKm2HFzXPCEafzodKu8NaetuXjH6Ao/X/3TLB3Dla2d4\n8HMHZjO49JEfP7buoiwDSFH6KK3W67Vw0/yFwwTsD/wW1SCcWwyxGwJ7YyAkg8NFg/Xyrv44mkpS\nCaECtChkODxyBJbxP4sIPCqkjxYOL14iABxcUDEPqAdNpb1MMsPI4kp3N2cnxDRuLExaew8PJ+ak\n+YHfohqE07iTjyXyxasLNHMEGhruiwozgD0tHq4/O9aWEKpU1KobAntTbwTOOu1uMfLy5zSF4yrG\nohIdBRwa7M3bN7bl0T0nnbFo2uMN9UYggImmzZFXeOvlCyIA39p2OOacECHd71xyxGRLuV2/DJyQ\ntS6oc4eKQEO1vrgSh+NNZXAYblTQJw73oQsCezxAXdJkuxcCv/GTN878mQ/p4FmhG674olkYiVNg\n+hHkQFPOm8F8918cjBYsAIAHnylOZHnqyQMrV430OLd3DqfhRvVDfmvbYXrLzrlsA4C4vjBp753O\n1pQj9k5jYMuabEqkBeEvU9K1w0OgoR44PH64/sxYW4kcMzw8BJoqv88DDzwa9Km73nDkF/nQ3113\n5Bcx9Nd3zsLzHBIFRT9OCrd/8uNn9T7xs588v3L7LxP6gCNDIACAan21ysmHB5vq+OE6VGbS2FZ1\nWI8HGGumHoGLBuOCx2GSXqw88e+U5rx1NKQjRmBGlfzQ8j3FuXQLM3uAsWbaHwuPQLORhE1aOVE1\nxX4aeoHST3px9KSR9o6D9aWLe0lkUSvZ28S8+TGAqUYdjge+5+3fmPZBWjsPPr67MzQUAzDiaGcy\n17w3f+G1AN5x5Re7iaN9TmyJqWsMyo93HZrhdPWGi4zD19zzsX/90Wkb1n7mE+cBeN8fqWef3lRp\nJP3ELWcCuPiMv7/sDW/c9fSjW9asIuCudw0DuOIvxn55OOEsIrDWV0OQISqkoVpmtRB5r/ehItAQ\nicNCIKaD1vOSfvLEedWJCFpNNv/C1c6k8igyy73/mSPHx5N2B+GWGVJfoDgk3WNbLlpyCErBqRdf\nCMBk6dHMmvn0Sy8KUuFh9PheycuvObMPrJccvwb5gInnlRPOYuBogWYRgYZqfbVOs9PNXnpIDzDW\nTAdjkSZq0WDRkDuelOBXycGOpfSTJirnmb1TTz+H00frDz3RvPzMvlm+o6PTR2uP757GVfPk7hYQ\naglFWndCtf18x9jh9BmGDtkqAz/7wSbgPLemR5es3r3rZ+EpfgCYOu1awMxVCkLeqDISai7QlMpa\ntnPo9dxnQrXuqSk9HVQJuiDwuMGa+WcQODTYAMRBpcZV6v9NMygdw+knj1/Yf/zC/oPqKJZVEyOH\nUGW5G3kE7hhThX8zvMJ1Zw9dd/bQNWf0rXzJejMbWrt/rJmZr3FjEENXVpR85ixrsDGZshi44ED4\n4XnO64Qd1kfPpXLign4ABzsaJm0pAGBckfcXEuuhQTnUM+5pdKSxY6w5rjqotIMJ2Kv5keTYTj+5\neU8mpUvC0WODs0L7p3qB7ZzLB/ggn+3CblVTg6EZgrPPkaROWmEw5XLKMeGEJcubS1bYVa0JYC0y\nZkjYdVZoMvUzvXDhPvq+2zrnQdibRvtmwQ0wrya0s8TsGGvmBrHuZz09lsVV9mJ4evZmrsy6IApk\nw8FhDAqO2q203jgmetrZZ/WhA4rZTJ7l/dqEnDNAwQwvHX4yAQBPNNagxOhOWLJMa43ArM0AmbMJ\nAHadmXdasCtcwbmNx0TTHAaNDFh0jYaxZj00gyMjoXhbsy00Z9/GyMBShGCD4WpmuoAgESZ7cFN6\nrzy1DiDWulmSXe6qvLfp/YWUkIXskoUtBcD4c6dNplx5r/Aic43WnNeP1I10DEwqAJzA4iC2Y6vN\nZJMCgCBEDQGA2spMugFhyZKl7pIBVrUC+SQ4Wf4L1hhdvPqhxcXIoyDrcu7Tz1UQVpOkQ8JhZaV4\nTxdbKQO3bVEh/DaeEt22RQEkNOdgZpLwoutYcOmqCEDKCibIo3JyXdj15376yReejDTqaz9Ih0az\nms8OpyMIAII6mgUhHjCld/Hcgst9/TMwGHYeDZGw6S7sLjZopjwr9cQGey73gN/+ywDCsNh1pWbc\ngwzSuDIBpatbe83KCAIQZoorvrMpyWEP8CWOeoidV5xeT3WFfkLua6TpXDWSHct0x/fHN1455MsO\n0IDMShAwaKyTpYeLZQ2UEkAQAAiJYhCDoIuGN80AkWBWAOr1LMdfyAzPerZdZIZWFM11nqu2fW+u\ngtADr7LcfJks2IaLBk9OHGoThgCZYjIGbyJiARJgcp4mxnfvb3usFMuLdacr1tQBRCYxDJHSGa9k\nAIRIyKRLQu5jk/7qXa//3Zu/rBjXX/1Ks2XfwZ1fue2BwmGDrn9ONlkFXblTCve76qV5Dxu3Adz+\nLz9LtUKbLz13Rbhz/bJVAG4GAPzF770+3PW7N38ZwMZLhmxX10DLwMJigDwbZKBWS5I0ktb1TkpH\nQ3FqpFAAgOpoIqMLlr41KxsImq/s4RhjBTMMVMKADfYozz1H6eJTawgtWo4sdKZSALWByM7Z1owG\ngWCyOLCwTcemsLj/YAlD2qbeeH799nvb3eCndcX2i89ohBE2yjBYO5ndbSXqaxxFc/8s0ss39IMx\nv65vfe/1+7MRCQvmLb3hTUv3Hdy5v9NLyP8oAOCqDacUd3AbFPANqoPbG69avbHqIvdsNyUHzwEw\nv67Dx/ird70ewNd/cHsmdnpeJzQI1HIYqwkQ4oY1ojDANZkqZYPSCSCYSaRKpUQitG3aHAIkyCRX\nzb+JrYXnmOGp2/YDIwBydQL8YizmKggvWlkz9dnPX5Ebb4rwk2ZqNwkBAzYQpUJrM8UsonqfhMuj\n4MdLcu0lBHTCdvK8+6IbL2woScxIUlcRzLhfOVO9jVTsZeOma30SiCOXNkIAgIYAQRMT4X2/+WUI\n1GrC5rExb0boq/kkhgBAhFTjvX/2WgB/8p6v2av5A+xqkM/F7Na2CrGvyibA7ZTAYA1Tetd5YVz1\nYbPik1ozIAlDAoxb773jbedfPb+ut+7PzROP4oH5mDwwNsWN6b2sReJ8/A3NZEoVAMyvawDhk1x+\n7gUA7rjnx6ZBbF1EAkAc+zwIHGgDliSQIO/0IiiVCjMqB5kImQmkBvuHA7bGADGzy2JimWGGPcsG\ncyJP3JizIPSUqhSgqCatIcsWJyQHOSCyC6aQJQiaWZIwG5WxLzMJwcL0erZRDWBo4UydCft62Vpa\ng1hNChgoAjYMginS7MWONBbkEB4JAiHVrGzcIdUjCjADEOrOWGe7PdkPnlKGMctmHFpknWz3CC+V\n/9UpMcNmBdRZDyTiRpR1IS0okJI5TV3V69geH0WWZUgmMD735J2/uurKFfOHQ0YEABhZMA/7Du7c\n355Z5oluxDMqzmO44vplq1bMH0Yeilevv8gsfOveH9fqdpRt1cg3uCUvlRAA1EzNAJ+cA1A6CTKY\nsPVvuJW8XcYtw6YCWbV1X8aKPfzCbEBizoqjTZekhAYkCdKW0TGIhBTGgmIRSCCTIJ7swBSRyJqB\nAYaQsI5YU8GXXU0UD6g6mYxKzCDTOY1swjAJtu0KwEyNSICQaK5Rlm7bxCbFRADZ+IKAd4FQk8Rk\nH7s4wcwdqTRqtZxVlSUpZ6oDAOK4FkDRVDjVZEdwHy3F3lYIQdCC3SvYswSJWg3hRusj02CTWUcI\no8OWEJgRtakrP5wxl5ueqA7gnh3bAaw/cZmBYuGp3nLpKwB86+HvAtTpKHIiRqMuQZS0tCbOhjxQ\n3XcYAIR00hizjUQEkGYWRh4FFzQQNkqMa37NoakwG58z2jp+4VwFITnJiQZdJi/TiK75REzkeaPL\nAkb+B0ScyZxAjgEycxQLnQLGEAZ7gAMaAGM2cydadAunKhCAuIbUSYIeFZFTDlM7anJH24G57aBV\nj7Ix2P/WIoAsT+r4jwwgzkmqQpJyLxsbLseohcWSGKmiEG9KANbqZN+lVrODkd/CCUwFG84ULc0C\nf7/5X161tFJrw4J5S4GdB8aqJ/FTa6bJOw5JrPVQNAJqAYrXnvlyAF9+4Lseb0oxwDKGyRAJYiPE\ni7r/zCAgPZgS2YSlVuqByiep948LmKgagvvCQWOzGclDRwWY52zY2vfvs8FTUb/IwAabkI/iIBm8\n5XgsfMyRxRuIiYRpLcsavONVu7YRQX91C+4ohiBYmze5mlfCiaAg6YdSBxvtPr8gozGKWsgPgax+\nkvsVVmzONtYlvOYb9ecEJ6/jELO1P7iOolOHPcHMwg45MaRtkIwZ2iMZDHZ74cYTs+h+GN/efvu1\nyzeOTR0of6O4NkA0BaBTYpbJzI1QSQdArfvxIgnwLAHgvm1Pnb9iJYAFjQoo/sq5LwfwrcdvrxDg\nfUsSZXlpCGnSMWO7cEcyCxCPDB7nBU9YaVP4Tkf2yKw6DENnAmkgpM5VEPrM2d/7XlMDr3j1gNcJ\nbd/3eAODTdJLI49ZicAKl1aGRHYKwOb4IvyydpNCIGEQhHB1XgiIIo8l/3UTZdhujrNZKxFB6wxy\nVj0P06o7dAdXRCQZQOzYQ9znjguflpEkQQuYwYE8dwOR6xk6ONdxOdtADEEh68u22xsywPDeluH+\nkfJnGu4f2bz9ifL2Q6WOQleGWIXPe7c+BcBAsWw9AnDJ8gvu2vxTb76KjHScfSYyoo7Zq7VKkoQA\nlhJGT4H6xdLV500cQDBwWwqZIVMIvJwwmv2dm5xwd0dQlA1vAvju1yevecMQ4LoyOAuSyGOJshEK\nTjQN9hppxG7hYLsAQzrDiVflOy0NKXQeeDCqk9H0BmCNoZRdC2SkFSRJXjNEDoRxDdzJOHn4nNmA\nmubeMU0yZlhAiz/dMvIATpUYA0O5MSrAYfmy9H+fuv01K6uFUkM17aRKZ2uJ46Dn5vXDpFMtqXa6\n8EOuSt9o6J7tTxqPYllRHJs6cMUpFwL4/ta74dsNcOyRQeDISgDnnLzzwS1LkxTGpmPqRbQPPgch\n8wo6QJrzzDB0S3g7RPjEY/sPzj0QSsEhAj19+8sTr/sNUxmGvvLpcUH0mt8YBGyPiWoi63BBnzQN\nkrbzDMH+zcSIOKYQJwZWogbRcBV1MskzY27thDuaAMgo1A7hE3HXBkKYAUBu1EzBjMmJ3GceGMy/\ngLLLSSdQFIPjswXD8sX02MtA6wzCXDglfGDO9bMynbLs1M3bn6BWZ4baXVzreliX+/Sy8dyzfTuA\n9cuWIe9R9Hz71Ws2fuPntxeGQlPaSvmPRSCGUmlKQghi5idGRnWnyfVBQo4VZrIpPDMMnt/LVAz/\npecSJ5T5AY9dFlBtxh2lhcbXPm2T2wkiisTX/yGzCpjImDf/9ogXyQBOlTUXxn1OhQ5vwtAuGkd7\nOwyhPij91xJ1WHM1UTvNUAYCiBs1zgIqCsKt6dwdALmSBmmYC1gBjHo9EyM7B2iymYPa5HOkdVBg\nN9yZY4lMEeWxxKFFCnCRj2yUPXdThjcL+3NJW4GfWBtMfn3Td1+99uUA9u3duWDhUnQjz/QOzzpK\nQC+8d6V7tm/3OHzq6WcKezcsXAvg3w5sysQkAAShwVIA+NkVH8Av/gZAknakkPSrbz85VSSI77yL\nSeQa3TBDttqSb0i705rU8fDxi70Tmedo7KhKlNcJbRhnKRiaqzJb//MtB9742/NEw7ZQbN0NaI+7\nuKRCHgQ/EYrQGPYW6pzQ2Go7U2LGTwLJv8B4gRCE5d+IiLW1moTPMmmy1taLl0tjjSynPOAtA4TI\nOdlF5HDorJ5SBsqee06LvWB70smzSgDMMZGLSLDv6qV0Y57Zt3cn8jTS339gamrmzLAXHTEOV55w\nPIAyFC8ZWQvg/+3dZPUHMrHfDAIr5YtPqF95K7fbQgiwYGZmbVwXgB/GLCg3jc4DiRPH9/tbmMZ/\neMloLsSZ9ZwE4dLVskL0mhn98EcTiLLPeOFFA2CIfrCbzpIzTgIgJG0AmJxSIU+LG95iTR5FrLz0\n5vsKIQlM0mHJlswN4G4mRSbBsO1v5nv1xwJg5cYK/3T9cZbpZrKlYKYNGOEAGA75jRMjpRRuvGCr\n31AWDwQzeDNUwjLi7EQ21ySwmYpnpFtEQvgTh/tH9jWrHfQHxloA5h05CA+dyNl07t3+7PnLFpvl\nlSccX8YhgEsXrv3XvY8yWcnSFPbRShnRp/O6NyNNhSA2HkLWzKJKGtePji4gYGKsXYgsfXjxImMM\na/TNA5owbTjr79yNZjHBjE6yN1u80hUDIhCw64le4+QJ6wSn7Px3IMK/3TkV19mreYFCCOWTeHlx\nkEusMtjj/ncsunxcmKXNnGXYVuGauQvm95RiU++9f7I8I+q8swdEmgLgNC8jMMM4xzK9zgbpIRQ4\ngYgokgQmh0A2k36E5/FEYMQiUxL2Hdy5cvT4fcVnOQpEyAfThMsVUm4oKHh+iO44vGzhGf+63yZN\n04plDJWmgjC+8ZVCKSHALKBZa/Xcxo2L7rg9qIvFxHhsdD5IgHFg3zhCoQh4ePFxpqnrjeHAiT93\ndMKQdIfDZVOWCyAmHj2Zdv/C7Q1wsOgUApC0Mz7iPAucpiABERdxI73CTUg6TsY3ZHqkyFbdd6DI\na48F9dL/Brt04nlrNbaz5cJw619R6ZRFtokA4MH7JkJODmD9mf0pMznxO7wEh8k1GKIu4SeIOKym\nHQ2AUyecOraZsgYzO+5d2aePiLpGrtW7LE9PM8Lh/LV3jj9mhub71r6jnibjV24kzaw1k2DWIGKz\nytlM3cdGFwAg4OC+CdWaBAkZ13M2GNZgqjeGmLNsUXNVJxQBCEWbAXQos0LMX2J7oAa8qSQ1UlJo\nrTIeZ2kKZ0O0YacyBawjcrEmETKrjfB45DxUbNxMDqtpIX9McAWEnl0wAF11cBGNeVKKvJtFEBuL\niZ+qev66PgCJ4smO8u4T8yKxJI99DnRY1UoLxk9p4moRTI0ltJIUbE1H3t4w+9TDfnMEd8zhcOmK\np3ZuLR9z5dAaAN+beEynamLPbpIRoE2aJw0hTMono0Rn8301SOzbtfeUq66CpKe+cxtrlQ9b41pt\nkFkTwD7H2hx11usge8/kpH3JiUmrH+cncjEEhoaChnCuAhKQUkCDBEOQIgNIkGDpIubDhKAeOTmD\nT74r+ADojqJK3mXEUZ3HlZRGs3QYdocrLSoQmL8su5bQZpFw3hku8xKBUwEz0AbMWbMmQCWB2dY+\nmwujsZohgTlVWnmMOcaolNNy2dpsSGDBvKVlk0yRPGebWXD20SPruli+EsDKpSvAnUqW+LLBNXdP\njJMU0Bok0J7i+iAZLzwzM+/YuX3ZicvNwce9ZEM6OTVvDTNrpAAMPvnR0ePMAbVo0PBA9lmfgQMX\nXz4nQZgG5V9iQQD2jzt/XSRE3i46f0CjaCg10iRIa0giYaPJSJu5vNAqEw+9FjftyOuiKwBAeruK\nIT9oBFch2KhuVpmUKAKnkwyfm6HzPNZehFkxzjm9Ya/oRFwZAwyt8rFrBK3yEY8WbwA41QoBLBmw\n1eBynkOwcqzbCaXMEFGFUdTTll1HVVU8fDzfs22T8eb3IGYmrRkaBCLJhhWSsMkPmX923HxzZHPv\nPiEkCTJRPKuuvXbzd29/ZNGCzBthhjMSDA2XJZDninW04CSsB4WXzXKl+x7AknmZutUuWDU0WDNS\nhiASTNJlBhGWJZr+W8BvXL6PYSPCQzsggtJkuDGQzaiw+zKu5kwxumR5seIf5Q4L6JzVfbmDCani\nKHawD0aQVAVSZkEDdagzzM1rMQV10ey1mjQ7bwFBCFy0vFfm6ZlQTRQNpx39fFRoJLINuGrpKU/u\n3Fw+gFkxC2INDSYBzSCbdRTMk2ee4dO0WdGUBZhhjte5Kb9LzloHIoKAgE4TYBMA1nMEhAVKddaL\njGR0XF91eknVPSlpPawnwZmM2ElBNr0FQ2R8w8xtKNeZtgywsN3P4g2+AQE60+ACMLGz0FSrfwEH\ndH/PXd33ebOhzSGwpdA1AO2S1x7OTp+phl5fzuAHAExNx9/8zS0wGTb9NANAxMbeK6DRL2eUWtIj\nLYRcR3fKCPTHHG0o3r3t4QuWnwkg0VRpp3nv+KYPDa0FaTCgtZFLGZqhWfPgmjO1SoFtAJi1cV2A\nCcys9anXvernd3zzxHMuAh4HwEadhIIm7VSduQpCMwXFL1fATFQ4EiMT+OdQkRZyoimYziUlQTAL\nMvlmKHJ9NX94Icy6t7TK7oRCsC9rq0cK4ycIrukd4vmr8Dmr+oHA9pI6fS4mhOo+nNEl1fDxWJRd\nKPdOHouMKSdkAtY54ZczoVSbRyAwOsyXrzq9x7t7WbR/pLqgQCUCZ7gXQF+QZ6mSmu1paqImNvYX\nKVdfis0YTRpaozNF9X4j30yNHRCCyJoQwJqZFFgaBDIzszrhrAu8bUYzk1IgghCpr4AwV8TRkJJ8\nFmQg31Mr86YF2CsQldMrGaNqJCAJRn/ORyaZAImK64Xuvm4VSKi0JikPBei24aq51zx3VT/XZQXU\nFQAmSexg6aNY3UWDMcQKt+C0MKLYv1qSmVrV1joHRZg8HFkYgk/nQTxTNghgsp0UFp4HmhalP9vz\n5OpFVjNctfCEJ/c+XTigde99jfXnkRaQGhrMrManIIWQ0gqoAADWmmFkUcXMrNT4s/udL8wcoKwZ\nQCmVWg6v5yIIu/RuoF6r2pfv4CFpO1W8SMLmfoFmEEMQC4bM5FIuSaRCZObmintXP1HFplzgqIPO\n2av6QEgYaCkAUZwfZSKCn6qfu5a7ROHNIwIjFLMNKQ4sSYwaCRewAyYQg2UQl0deXqUbLtvYwz24\ndcduREe3j7WazfLGHlMrKumBHQ9dMHqqWS7jkLWC1gwJ0pCA1rKvrppthpExnIDBSjMEE1iw1pMH\n9oEEUeZQZqNPEoiEdpywOTk290Bo4459n+u3ijUp5Ud6swcwgV6WyOShKLC+eAbTSxOGYpMHMU/C\nmTeLomO39KeqIq8h++PPPqU0ZnNuXgXAqUpDJbE1GRTns0EIpcg7xwzrviobwXBO038kQQas08PP\nwZKtPM0ZSs3vW196dS8HfVQDQGkKoO+4WajuMnOipOtYDQDy0FA6dMnlJETSnICWIE3aegihNZTw\ndgKttSDBrNoTkzAcUGiwyGahaYtAhtKJlQXik1fMPRBaci/mq0w57x7Q6ZQZn0UgwjgXAMBM5CIh\nHGP0PMSPbbmHqcYeM4COznyOZ68oFlGR5qkKUqKRe0sPqDoBL/YjDwGAqDlXDXJQtJGuClmIX+Z7\nIXe5vOqbpjm7qFdaAyj2DpHZumVHj72zRodVFI90sYvcs+vJ9UtWAeBGvHLpiqeezTz4WqfEgrUm\nAnTEmgEt6pHuJNA644Raa2hAxI1GZ2qKCcQCpCG8TqiMhqO10i4hAKs5GLbm8li49XZC9ThTwTqd\niuzyVGKA3hUgSz4HVdYS3RYZFQPPHHVjfeee3N+0s1SjjHuXQkALybmtzFl5TYIMJrdK5zPRBplZ\n9oRALSQkU1my03AhTlEcsApcNICcN4wSg6V86eozqp7P0gM7dgMwHrSjwQanMdccVg5XblQrt5wq\nCBMuA4CRTCHuJwJrJqRMbiK5ZlDKOgI59U9oZpArocBKM0EIqCRRqR1c54yfMCSGG489tRNCkA2G\nq/xgBbCFa2l+LC3DEkhDT12eVL6eQU0IBNhrhvPE/YHdZSXrB0mqE+Z3I+14o+4UTxQ1WWFDIsQu\nN1X56qIheTLJtnMmlPqW741APyTtB+YX5tED8FtcVFq32fS9SJYWwgeYmbRZ5odles9P9wxfkhAL\nGdW1aoMVtCSlWUDGsU473rbHmfcCUb2RtlrMMFC0B7AGtFZCJ4nuOBAqNfdAqEo+CRZMSkMFQpjh\nJNO3MKA1RNfj0u6fsoA9T6cvrycJj7XSysoUcdz1XgPd66o3y8zZURl12a7uB/QLASiOA3OrF+8b\nkjUQlpRz4w9NdMzqhrVndbupoQef3u2Xh48f6H0wes6m70aZolXyYdCMXYsFrN6zbdP65WsBEOSq\nxac8+ewOGCFTpcSChGYNkIboA6fQAmTMAd46amZ6Wd2AlYKgME0+K8sedZLotGPHj7kojhr7eCba\nsXJ6ERFzLg8JAwWWEkKgZCEMdln8mNZJAwwk7V4VI85bNQCgXq+4brutASRV0B3p0QMJAPq6xAMB\n6Ovr8gU7erILdPvd21GZ39Yk2tWoZrZlcy7pyQPhBFFDK3ogcBZTj+apDMuZE5UY68AF61mlJoaf\nhGCtydpXmIUWkfRud2jNJEyQJAGyXktbHZDyo7zWTKTB0EnCaWpAyCqdeyAEwD5+BaHwyQxQx9vm\nkQVWhWfCxYNWuPir+7pJ72ugGNcrjtEpAzj75Gp/VLs7bqeFX/e93Xd37O0GquTqjqBulqiaLPa/\nfE4U4BARCBw1pB2aA+LIbqVSZibNJARJSVbsdJ1LEGfiKJONYbMcljkFi0zo15oJTEKlbR+3MWci\nZpQmHz4aUamDhowxpzEaBhk4LmSXvtsFfiFFlbqi0gBERGcuKxk8bUZR9FclCat1YTgZVSlyQAl+\nZYm5i3SdBNcoX76MQHjPBhER3nb5y6adLrh1x+75wH63uuKEBV0PPWps8Ajp7m0/v2D5aWZ5xaJl\nW/dsZ52SLTYvwMyCBCcmRN/YyUl6w4y2pmdXwFBGseqkRC5CTSkIAiudZgIzqzkCwiKVq3AGQMs5\nC5FxvyIAOZiNwcEpM9Ek8zLqOStzPLA1qQAkXTjOsC/6k3+YaYmrhFJ2b5Vhs0qRLT9LeP94On/6\nhlPXTIPAqOYdEsYiOtwDgcc8JXmDDbOCUqyEcc0zSSFrVuV3MTCwRm9t1n2MCOvUxxKy1mDBqqPb\nmRdN8xwUR2PGuacNAvhifnuzzUP9rj3yXfy8Uwb8xvuemoSfDBWGa8Ia/4oxoqWrQSnkZ0NHvs21\nBhD3YbwiisPBr5KoGmMzpBx3jIqjSLO78cZQj+fasObsbCWtNnhsLYigRxuBR1kWNQiMyEacBm2r\nATBDtzscaRFFJCMQfGgo6xQkwTkEs9IhSolSlSRhDHE6OUGmEvKvbrj1sB/6cz9822Gf+yK9SP9+\n6BV/PQgSaXNStScB3PnfGwDW/1ln7nHCF+lFmqNkuKIuCBR6NlwUM+Gis5Jqzdtm1p0+BOB/fPK1\nAP7kP30td5DLfBHXMxNoUlQT88uaq2weJQdGlR/v/s1Vcqcj5QOyq9TNKG8NaqdFxU2KXnEfX7nr\n1wC87op/qNwbSXFuEInaymuo5ZAdT1etPafHTT1te/owRdDr37MGwFc/9NhMDq6g4MGvf+8aAF/9\nX4d7qS50wahNV/HEnlwY9x9hkRUsRcMGL9hoPrrr3XUAGz8aZzlIC65slYAEm9nAaZpTgo7NiJl9\n7V5S/6K+DGkV1C8BYEolhYvUKadLcO6Pi8zKHxEXGjRn6yEASrtTCMVDoJJg6nHOWgsAUQlg9ShT\nzdLp6tdHPc25xpB7/+bqeXSnnxhVGp/eedm1hW5XSaEjfr5beJ7MMNWZaaZJeThb9AfYA40/lqNZ\nwiv3WOaPTjtChoDKvhErDQKEBgk7mrtPMK9GxxYIe8Ovmjwg+4Nu7aAIACZIJevVpVtUBk9G+WiS\n/DGkNED3/2KqeAQDxRlJpZtwTy/fdAgswK+MxlSrVFUMUpGUANpp8uCWHFc8+6Q+AFetOedQEQgX\nlfaCInCWybNBbsRU5cV9P3Z/UB1Hss98xtC0Zw02GQ6DUdjYbxSY0+IVj52UhzOH355uAqCBXBmK\nSaFPl1xlZWEV+YDSXNyzDx8vnUYAkIYMsOzvcPCbltdVUm8GiFIgeG6XUlUTqXD12efM5NbcKSIQ\nvT2Bh0QzAlg3Llc/klxPFc/SJYzb0/vlcx9MF1FUShRAzCpRaUpxTJQNyvayzCDSbopPzp49C099\nZHQ43K8b9VcpUYXcTBkm82g0zKxSb8whKVdmNVxK00zMqOZ0PRngtMTgpISicIsuIVBQ1iC6NBn5\n9177Evg62D3poS17cutEOFYQOJO9h0DTItDQ+6M9H0wXIWpQIJo63DGnHYYAEZm50f7izJWWhRcS\nhLMJP3RBYJk8Jqeqwkr9b5TfXqASnEzGmq4gq/A25kgF+Olmj6kMdfWbVBUPzICXb+kbX3dxj4cJ\n6YEtu4GK9+2BQMYM5iaE2WFnEj3zPMapGQrnE1bS+6M9f5TnhyQy6ZRZQxOHs9EKwmtALwAI90wp\nmLIks0gzRKChSrtOOM+IbXoIwKiUVOSKPhSOAGafMyroKllatWkZYAE/lXDqca4UcppT3IPc8s63\nTNu3PFn4lcjGZHdnX12kgALSil+/C3RNTEW3Wx0tIsjeMxbf9q4Nt978QzA4NWXbGwi+M9tOZCQs\nv7XrazyvINwT9H6l9OHjMCaE0xGOHIGevKLH4MiL9ezmbRhZk8HWOUEAiOJSkIq9ilEsq1o/JYFD\nxFs3mv4ihBuvvxzAU88+M+1sWKDTDX7oPSuiNxVAW8JwdyEiRG9BF5hlWr98ZXkWRTf69XddtvJD\nDxZEHAprsFogTv+4zwcIFcSeqq5vsqkfBhTvfGTyynWuN8wCAkMm6BqRQD4I07eyMbQy3b95yh6b\n5305SnthI2INl4XxkKjdsyxugT72jl8zk+JmQmHw5/7S3sOH3xFSmeUW26x0AMN90xroEHqXQeC+\nVnvfwT3THPmeTzDw1Id+S2LZyX/2DXtbtgM1wWXHgpdOe13tqINw1xT3TgNyRCxxhjTlkghaqnRK\n5Cm0ffrlRAO4f2ve/0a5MwAiwxhN8sWeUOxJ1fis53Gru3Sy//baSwHMEIHlZDAehy8Y9o6EMvZU\nClzn7Ct1O3taBAI4ZXjDU2M/jG/4ePKpdz757rOBrdnl2Vbb9g8TlJ+rpqMIwl1TMx2zDwOHdz5S\nXYwSKKQYJWp6GPRiO5QqwM5bDa6VXybcv2WqaEENj5E2wXB2L5lPQ0xUMZW24mmm2e8fgrLkagDw\n8d9888xZH4CtW3d0u92pJ3hX/POUkf75oErsMQA+efTUjuJtz01X08ZcRkYrhzdgGNtv+HjyqXdm\n1/HykYGiyI/8XQBxVEA4c/h5OmzRlH3Mio9aCRu6twboiBy/om6Mi3DftryDMryLJCCoh1HguOwe\nLwnqk/ndPfFW8mkCoGbuGvamN163AcATu7aVzw1WsubdsqVrb1t0wgiQDd3VCCz15t6pso9pGBNW\njq7ed3DPAbuuy5oc5SUOVilFNU7TZSsv3n7Dx/GpVwL4xU1XM3DKR+6wxwTSqUegadTWXsNsbXm2\nF95POHMqBa4ABciVyWuMXdDYFXUB3be9BeoyiJrk9mZXOMuR8lAz1lQRZL6x/r2sSCBR9qUp9ydb\naQIAhcw6kvK/Xrch2DCNhrzNSZ6iyu9/XMD94JBDotxJioNsjWoc7LAPHngmaxQfoZv06NHK0dPy\nIqiodgc5cG7dulOeOE+rjogbnCbLVl78JABAYbvEss03Xn3Kh+8osESrKDo/RYFmCsJ1p1ZkrXvk\niYnyxsNgg55CubQMucpveOf941eeOzT9pUv2Gxorjc2lXnLf9iZgBfwqxgIQKEhGzOFVCEQiONPy\nPceTpFsluIhqCv7PftzprSBF77XrV38VAHDdpedsHZs6ad70OQW3bd0JgISslIqOO36kvLEup6/R\n2dFtwwPLX4cLQZGMDts2JyqlQ2OAddHzffSphMAeJEDYtmUHgX59x6OfXb5Opy2GoLrtfvENH+e/\nuQzyms03XQ0ghKJliRSMUu5FW8/tKYJw3amD1CyGt3GXbEIWmYG34JEtXVW13uQvkSpt4o9n/hHu\nvH8cwIyg6IjGk96fmYfjBza3qM+JWJT9tc1IAlp7TNni2zrXh3L/59GVO0qzY2COrwcgf9Ul56GQ\najWgwagB0DMTVVVx8hQft8QvJzoVY9YCetzikcrjw6DIwg73MAygJvoq9gIo+/0IdRfaQq5cariX\nczw+M3EGT2Gyp84OPleOnjZUa2zds33mp4QWrCgWClorrVViBJBlp71sG1JSt0FeA2DzTVef8uE7\nAGubCQ02RDkWY9G1bu0wDHMoIRBACMsMkFWJw9adNLAuWL1jUwWrtNcJr38okOtGM2SJND5dym0i\nDMUPbWk7gY1yTeYLrGg23CyTh02tX3OEwZ1mz/uIQn7qwEsgbUXIK9af3tfoB8GEX0cyJhHeNCc9\n1mPb9fv755sRukcLdpJiuG0EoGHbajyUI/PkAz6SNGHWEFjUCKPa7V9TYzSMDiGGqzucv65bq0f1\n3D0ZHpAijtwVKpxsvsRStouEPb1SXelCR4hAALImiaBSJtU2znoIsfzDEYi33XgbgEqWCHjRyj4/\nUSCOVohnVVTgk0VzYp6uXuvFpJyycMemiR7NdRjGUiYQcOcD4y87vYRDd6eOUf9KulDGfQgk8PCO\nDnYrkwO7zL7IMC4CSeEEfSKvfBtjJRE0EwjStLjTG8mKqJees6a/bwBAkqYg1KIawQcZithBLmCi\nAkAtbrgnyF6hVh9wfLKixcwl67Uhv66VErJY3Slc66St4jwvoF7XpgNNIauiw6YilD1KG87F0Ena\nCWrTAsS2emSoMssQaRoAsWCwjCN7JJkYGgpOZAB9Desy8TGY/fWiE4WzR7Q3aLYnQ/65cvS0vXt2\n7i01Vw8qz59882P339q/KD7xhGzWqNYURTpNl39EbrtRGZbIVSyxsXC0tfe5rDVMeosX6UV6kY6Q\nrvpISysYqymYQbztRsUAy2sAdNJvnf6XNSCzw93xrgaAS35/21H2kr9IL9K/G5I1KWNAdQBACDAt\n/4gEQOo2AmrRtZtvutpqumEVbS+O/umbvnB4Ny66U8yfQ89qPj3lbf6dNP3Dz70ewP9861fsRnIW\n1UC2y2widtXJhGTESAIASUT0+K4ERnMTREKYv2RUaQ0iEiRIQJC45Nx1A41hEkJBaU5jWScQCQGC\ngASBhCQgabWJuBYPQECQBAEkjbmfhAQgTDlhIQVJQgckSYBICiEJ9jlAEEQgIQhG9xP2P7nuFQ8A\nePT280YH5oGwd2rSSqoEYiwYGbYZSFP93PiUH30BANrV3NXOkKThNEOSUZY+jDVc7RxtqkppMBTY\nTIDStsQja7BiUz9aK2ZorcDKTK3SSqV6ihnQioGX/8cWgO98ImZWxKamnwZzX2OeP4ZZgf2vFoI0\nE1i7ovDcSqfAeN27hgF86cP7zExZBtiVvrL5O9jHmrKz8+iOSZjNOpYxgI5OTu6reY3Uv7kVkiEe\nenq3vwCA+cRffyzTJL1qumPdumj1Wi1YEWultQJFsU7TFR+RALbeeBvJaxj4xU1Xp+m3Tv3Lmhen\nmR0Iu6l2lW60auBhtrFHxaVmux3ZDJnk3Vwf+MfXzeZNZ0AfzRaj0kw2HfwKAD/+0okgIYQQQhJB\niIgoFRQLASIhhICIJAkSQhCRjEiIuN6QwhSXlMZ5SKbSpMBQox8aE502kQAeAHDiyWf0NQYImB85\nCyqJbKIQgYQYMTozkYvod8W42ZTjteqc7GuAoZvNZrMFh0DT9zRrjwFmGKSBlTYWEQ3NSNotpVLW\nDNZKK9aatfk/ZYZWWnMCBvAwgAWLVoGV1tqYF6GVZqW1IgNgnTK7W2jFnMb1QdbKQ3Qwjhlk2nlo\n4DhmzWDW2lSkdpjkTqepzTKbmkoMyLpRiV1odZ3k0x1TYRe+a8e1BtgatPr7B5rNKZj89Yxv/myn\nEIKdMcp30mWPPIpHHp1645tIaJUoItYqEXGNkxTgFR+RW2+8jQCW10TRtVtvwooPW59+Y+Ho/wcP\nleGU18HiZAAAAABJRU5ErkJggg==\n","text/plain":["<PIL.Image.Image image mode=RGB size=300x300 at 0x7F586FFD6518>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ls4QXHkNQpLP","colab_type":"code","outputId":"e08b9aaf-a27a-4c38-b715-85daf92b5792","executionInfo":{"status":"ok","timestamp":1579472105747,"user_tz":360,"elapsed":1574,"user":{"displayName":"Kailash Subramanian","photoUrl":"","userId":"07824963897350544691"}},"colab":{"base_uri":"https://localhost:8080/","height":351}},"source":["###  ----------------\t###\n","###  | OLD FROM GFG |\t###\n","###  ----------------\t###\n","\n","# Write Python3 code here \n","import os \n","import cv2 \n","import numpy as np \n","import tensorflow as tf \n","import sys \n","\n","# This is needed since the notebook is stored in the object_detection folder. \n","# sys.path.append(\"..\") \n","\n","%cd /content/models/research/\n","\n","# Import utilites \n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util \n","\n","# Name of the directory containing the object detection module we're using \n","MODEL_NAME = 'inference_graph' # The path to the directory where frozen_inference_graph is stored. \n","IMAGE_NAME = 'test/j_110-4.png' # The path to the image in which the object has to be detected. \n","\n","# Grab path to current working directory \n","CWD_PATH = \"/content/drive/My Drive/Colab Notebooks/EnemyDetection\" #os.getcwd() \n","\n","# Path to frozen detection graph .pb file, which contains the model that is used \n","# for object detection. \n","PATH_TO_CKPT = os.path.join(CWD_PATH, MODEL_NAME, 'frozen_inference_graph.pb') \n","\n","# Path to label map file \n","PATH_TO_LABELS = os.path.join(CWD_PATH, 'training', 'labelmap.pbtxt') \n","\n","# Path to image \n","PATH_TO_IMAGE = os.path.join(CWD_PATH, 'images', IMAGE_NAME) \n","\n","# Number of classes the object detector can identify \n","NUM_CLASSES = 1\n","\n","# Load the label map. \n","# Label maps map indices to category names, so that when our convolution \n","# network predicts `5`, we know that this corresponds to `king`. \n","# Here we use internal utility functions, but anything that returns a \n","# dictionary mapping integers to appropriate string labels would be fine \n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS) \n","categories = label_map_util.convert_label_map_to_categories( \n","\t\tlabel_map, max_num_classes = NUM_CLASSES, use_display_name = True) \n","category_index = label_map_util.create_category_index(categories) \n","\n","# Load the Tensorflow model into memory. \n","detection_graph = tf.Graph() \n","with detection_graph.as_default(): \n","\tod_graph_def = tf.GraphDef() \n","\twith tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid: \n","\t\tserialized_graph = fid.read() \n","\t\tod_graph_def.ParseFromString(serialized_graph) \n","\t\ttf.import_graph_def(od_graph_def, name ='') \n","\n","\tsess = tf.Session(graph = detection_graph) \n","\n","# Define input and output tensors (i.e. data) for the object detection classifier \n","\n","# Input tensor is the image \n","image_tensor = detection_graph.get_tensor_by_name('image_tensor:0') \n","\n","# Output tensors are the detection boxes, scores, and classes \n","# Each box represents a part of the image where a particular object was detected \n","detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0') \n","\n","# Each score represents level of confidence for each of the objects. \n","# The score is shown on the result image, together with the class label. \n","detection_scores = detection_graph.get_tensor_by_name('detection_scores:0') \n","detection_classes = detection_graph.get_tensor_by_name('detection_classes:0') \n","\n","# Number of objects detected \n","num_detections = detection_graph.get_tensor_by_name('num_detections:0') \n","\n","# Load image using OpenCV and \n","# expand image dimensions to have shape: [1, None, None, 3] \n","# i.e. a single-column array, where each item in the column has the pixel RGB value \n","image = cv2.imread(PATH_TO_IMAGE) \n","\n","alpha = 1.5 # Contrast control (1.0-3.0)\n","beta = 25 # Brightness control (0-100)\n","# image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n","\n","image_expanded = np.expand_dims(image, axis = 0) \n","\n","# Perform the actual detection by running the model with the image as input \n","(boxes, scores, classes, num) = sess.run( \n","\t[detection_boxes, detection_scores, detection_classes, num_detections], \n","\tfeed_dict ={image_tensor: image_expanded}) \n","\n","# Draw the results of the detection (aka 'visualize the results') \n","# print(classes)\n","\n","vis_util.visualize_boxes_and_labels_on_image_array( \n","\timage, \n","\tnp.squeeze(boxes), \n","\tnp.squeeze(classes).astype(np.int32), \n","\tnp.squeeze(scores), \n","\tcategory_index, \n","\tuse_normalized_coordinates = True, \n","\tline_thickness = 2, \n","\tmax_boxes_to_draw= 10, #https://stats.stackexchange.com/questions/297796/faster-r-cnn-how-to-avoid-multiple-detection-in-same-area\n","\tmin_score_thresh = 0.0) \n","\n","from google.colab.patches import cv2_imshow\n","%matplotlib inline\n","# All the results have been drawn on the image. Now display the image. \n","cv2_imshow(image) \n","\n","# Press any key to close the image \n","cv2.waitKey(0) \n","\n","# Clean up \n","cv2.destroyAllWindows() \n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/content/models/research\n","Loading...\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAADIdUlEQVR4nOx9Z4AkR3n2U9Vp8ubd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\ndoZSOdoAAAAASUVORK5CYII=\n","text/plain":["<PIL.Image.Image image mode=RGB size=300x300 at 0x7F85A01FE780>"]},"metadata":{"tags":[]}}]}]}